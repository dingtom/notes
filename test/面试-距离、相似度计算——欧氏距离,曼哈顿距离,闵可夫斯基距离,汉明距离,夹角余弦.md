---
    # 文章标题
    title: 面试-距离、相似度计算——欧氏距离,曼哈顿距离,闵可夫斯基距离,汉明距离,夹角余弦.md
    # 分类
    categories: 面试
    # 标签
    #tags:
    # 文章内容摘要
    #description: "{{ .Name }}"
    
    # 发表日期
    #date: {{ .Date }}
    # 最后修改日期
    #lastmod: {{ .Date }}
    # 文章内容关键字
    #keywords: "{{replace .Name "-" ","}}"
    # 原文作者
    #author:
    # 原文链接
    #link:
    # 图片链接，用在open graph和twitter卡片上
    #imgs:
    # 在首页展开内容
    #expand: true
    # 外部链接地址，访问时直接跳转
    #extlink:
    # 在当前页面关闭评论功能
    #comment:
    # enable: false
    # 关闭当前页面目录功能
    # 注意：正常情况下文章中有H2-H4标题会自动生成目录，无需额外配置
    #toc: false
    # 绝对访问路径
    #url: "{{ lower .Name }}.html"
    # 开启文章置顶，数字越小越靠前
    #weight: 1
    #开启数学公式渲染，可选值： mathjax, katex
    #math: mathjax
    # 开启各种图渲染，如流程图、时序图、类图等
    #mermaid: true
--- 




在机器学习领域，被俗称为距离，却不满足三条距离公理的不仅仅有余弦距离（满足正定性和对称性，但是不满足三角不等式)，还有~~KL距离（ Kulback- Leibler Divergence),也叫作相对熵（不满足对称性和三角不等式），它常用于计算两个分布之间的差异~~

# 闵可夫斯基距离(Minkowski Distance)
$d_{1,2}=\sqrt[p]{\sum_{k=1}^{n}\left|x_{k}-x_{k+1}\right|^{p}}$
其中p是一个变参数。
当p=1时，就是曼哈顿距离
当p=2时，就是欧氏距离
当p→∞时，就是切比雪夫距离

# 曼哈顿(Manhattan)距离
等于两个点在坐标系上绝对轴距总和。

$d_{1，2}=\left|x_{1}-x_{2}\right|+\left|y_{1}-y_{2}\right|$

# 欧氏距离
在二维空间中，两点的欧式距离就是：
欧氏距离：$\|A-B\|_2=\sqrt{\left(x_{2}-x_{1}\right)^{2}+\left(y_{2}-y_{1}\right)^{2}}$
同理，我们也可以求得两点在n维空间中的距离：
![](https://upload-images.jianshu.io/upload_images/18339009-455560748c6639aa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


# 切比雪夫距离 ( Chebyshev Distance )

两个点坐标数值差的绝对值的最大值
$d_{1,2}=max( | x_2-x_1 | , | y_2-y_1 | ) $




# 马氏距离
马氏距离又称为**数据的协方差距离**，它是一种有效的计算两个未知**样本集的相似度**的方法。马氏距离的结果也是**将数据投影到N(0,1)区间并求其欧式距离**，与标准化欧氏距离不同的是它认为各个维度之间不是独立分布的，所以马氏距离考虑到各种特性之间的联系。**尺度无关，考虑数据之间的联系**
![](https://upload-images.jianshu.io/upload_images/18339009-83fdfa54f83c2147.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

最典型的就是根据距离作判别问题，即假设有n个总体，计算某个样品X归属于哪一类的问题。此时虽然样品X离某个总体的欧氏距离最近，但是未必归属它，**比如该总体的方差很小，说明需要非常近才能归为该类。对于这种情况，马氏距离比欧氏距离更适合作判别。**

# 夹角余弦距离
欧氏距离体现数值上的绝对差异，而余弦距离体现**方向上的相对差异。**

在机器学习问题中，通常将特征表示为向量的形式，所以在分析两个特征向量之间的相似性时，常使用余弦相似度来表示。**余弦相似度的取值范围是「-1,1]**，相同的两个向量之间的相似度为1。如果希望得到类似于距离的表示，**将1減去余弦相似度即为余弦距离**。因此，**余弦距离的取值范围为[0,2]**，相同的两个向量余弦距离为0

对于两个向量A和B，其余弦相似度定义为:
$cos (A, B)=\frac{A \cdot B}{\|A\|_{2}\|B\|_{2}}$

在兴趣相关性比较上，角度关系比距离的绝对值更重要，因此余弦距离可以用于**衡量用户对内容兴趣的区分度**。

如果使用词频或词向量作为特征，它们在特征空间中的的欧氏距离通常很大；而如果使用余弦相似度的话，它们之间的夹角可能很小，因而相似度高。此外，在文本、图像、视频等领域，

余弦相似度在高维情况下依然保持“相同时为1,正交时为0,相反时为-1"”的性质，而欧氏距离的数值则受维度的影响，范围不固定，并且含义也比较模糊。



# 汉明距离
两个等长字符串s1与s2之间的汉明距离定义为~~将其中一个变为另外一个所需要作的最小替换次数~~。例如字符串“1111”与“1001”之间的汉明距离为2。

应用：信息编码（为了增强容错性，应使得编码间的最小汉明距离尽可能大）。













