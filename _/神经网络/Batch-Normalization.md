Batch Normalization是2015年一篇论文中提出的~~数据归一化方法~~，往往用在深度神经网络中~~激活层之前~~。其作用可以加快模型训练时的~~收敛速度~~，使得模型训练过程更加~~稳定，避免梯度爆炸或者梯度消失~~。并且起到一定的~~正则~~化作用，几乎代替了Dropout。
![](https://upload-images.jianshu.io/upload_images/18339009-1c25636bb274fd23.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
![](https://upload-images.jianshu.io/upload_images/18339009-dec3475527ea74e8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
