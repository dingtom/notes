
![](https://upload-images.jianshu.io/upload_images/18339009-fe44341e8e74201c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
我们建议将现有的单变量时间序列分类模型，长-短期记忆完全卷积网络（LSTM-FCN）和注意LSTM-FCN（ALSTM-FCN）转换为一个多变量时间序列分类模型，通过使用压缩和激励块来扩充完全卷积块，进一步提高分类精度。我们提出的模型优于大多数最先进的模型，同时需要最少的预处理。该模型能有效地处理各种复杂的多变量时间序列分类任务，如活动识别或动作识别。此外，所提出的模型在测试时效率很高，并且足够小，可以部署在内存受限的系统上。

根据数据集的不同，对完全卷积块和LSTM块的输入会有所不同。完全卷积块的输入是一个多变量时间序列，其中Q个时间步每个时间步有M个不同的变量。如果存在一个具有M个变量和Q个时间步长的时间序列，则完全卷积块将接收这样的数据。变量被定义为互联数据流的通道。
此外，LSTM的输入可以根据维度打乱的应用而变化。维度打乱转换输入数据的时间维度。如果维打乱操作没有应用到LSTM这条路径，那么LSTM将需要Q个时间步来在每个时间步处理M个变量。但是，如果应用了维打乱，那么LSTM将需要M个时间步来处理每个时间步的Q变量。换言之，当变量数M小于时间步长Q时，维数打乱提高了模型的效率。
在维度打乱之后，在每个时间步t，其中1≤t≤M，M是变量的数量，输入向LSTM提供该变量的整个历史（该变量在所有Q时间步上的数据）。因此，LSTM一次获得每个变量的全局时间信息。因此，对于时间序列分类问题，**维数打乱操作在不损失精度的前提下，减少了训练和推理的计算时间。**
进行烧蚀试验，以显示具有维度打乱操作的模型的性能在统计学上与未使用维度打乱操作的模型的性能相同（在第4.4节中进一步讨论）。


MLSTM-FCN和MALSTM-FCN在第4.2节的35个数据集上进行了测试。通过对8、64或128三个不同的选择进行网格搜索，找到每个数据集的最佳LSTM单元数，并且所有其他超参数保持不变。FCN块由3块128-256-128滤波器组成，用于所有模型，内核大小分别为8、5和3，与Wang等人提出的原始模型相当[34]。此外，前两个FCN块由挤压和激励块接替。正如Hu等人[32]所建议的，我们一直选择16作为所有挤压块和激发块的还原比r。在训练阶段，除非明确说明，否则我们将训练时段的总数设置为250，并将退出率设置为80%，以减轻过度拟合。每一个提出的模型都使用128的批量大小进行训练。卷积核由He等人[35]提出的均匀He初始化方案初始化，该方案从均匀分布U∈−q 6 d，q 6 d中采样，其中d是权重张量的输入单位数。针对类不平衡的数据集，提出了一种基于King等人的类加权方案。利用[36]，通过8因子Gwi=N C×NCi来衡量每个类别Ci（1≤i≤C）对损失的贡献，其中Gwi是第i类的损失标度权重，N是数据集中的样本数，C是类别数，NCi是属于类别Ci的样本数。我们使用Adam优化器[37]，初始学习率设置为1e-3，最终学习率设置为1e-4来训练所有模型。此外，每过100个学时，学习率就会降低1/√3.2倍。对数据集进行归一化和预处理，使其具有零均值和单位方差。之后，我们将可变长度的时间序列加上零，得到一个长度为Q的时间序列数据集，其中Q是时间序列的最大长度。平均标准差归一化和零填充是所有模型的唯一预处理步骤。我们计算训练数据集的平均值和标准差，并应用这些值对训练数据集和测试数据集进行归一化。我们使用Keras[38]库和Tensorflow后端[39]来训练提议的模型
