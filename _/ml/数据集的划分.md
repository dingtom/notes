- [ Holdout检验](#head1)
- [k-fold cross validation交叉验证法](#head2)
- [ Bootstrap自助法](#head3)
# <span id="head1"> Holdout检验</span>
按一定比例划分为训练集和测试集
这种方法也称为保留法。我们通常取8-2、7-3、6-4、5-5比例切分，直接将数据随机划分为训练集和测试集，然后使用训练集来生成模型，再用测试集来测试模型的正确率和误差，以验证模型的有效性。
~~在验证集上计算出来的最后评估指标与原始分组有很大关系。~~
# <span id="head2">k-fold cross validation交叉验证法</span>
交叉验证一般采用k折交叉验证，即，往往k取为10。在这种数据集划分法中，我们将数据集划分为k个子集，~~每个子集均做一次测试集，每次将其余的作为训练集~~。在交叉验证时，我们重复训练k次，每次选择一个子集作为测试集，并将k次的平均交叉验证的正确率作为最终的结果。

**K越大，Bias越小。Variance越大**
最后，我们要说说K的选取。事实上，和开头给出的文章里的部分内容一样，K的选取是一个Bias和Variance的trade-off。
K越大，每次投入的训练集的数据越多，模型的Bias越小。但是K越大，又意味着每一次选取的训练集之前的相关性越大（考虑最极端的例子，当k=N，也就是在LOOCV里，每次都训练数据几乎是一样的）。而这种大相关性会导致最终的test error具有更大的Variance。
一般来说，根据经验我们一般选择k=5或10。

# <span id="head3"> Bootstrap自助法</span>
不管是 Holdout检验还是交叉检验，都是基于划分训练集和测试集的方法进行模型评估的。然而，当样本规模比较小时，将样本集进行划分会让训练集进一步减小，这可能会影响模型训练效果。有没有能维持训练集样本规模的验证方法呢？自助法可以比较好地解决这个问题。自助法是基于自助采样法的检验方法。对于总数为n的样本集合，~~进行n次有放回的随机抽样，得到大小为n的训练集。n次采样过程中，有的样本会被重复采样，有的样本没有被抽出过，将这些没有被抽出的样本作为验证集，进行模型验证~~，这就是自助法的验证过程。
![](https://upload-images.jianshu.io/upload_images/18339009-b82630dcdb34c575.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
