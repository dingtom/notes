- [ 标准化（Standardization）（Z-score）](#head1)
- [规范化 (normalization)\归一化：](#head2)




瘦长的椭圆，会导致趋向最值时**梯度下降的震荡**；所以需要缩放特征值，使得其取值范围相近。按经验，特征缩放到3倍或1/3是比较可以接受的。
![](https://upload-images.jianshu.io/upload_images/18339009-7b8e05b9f479e6b8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
![](https://upload-images.jianshu.io/upload_images/18339009-e94b1c23eb15233a?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)




# <span id="head1"> 标准化（Standardization）（Z-score）</span>
标准化即为概率论与数理统计中常见的Z-score标准化。在特征值的均值（mean）和标准差（standard deviation）的基础上计算得出。
处理后特征符合**标准正态分布[-1,1]**。

$z=\frac{x-\mu}{\sigma}$
```
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler().fit(x_train)  
#标准化，将特征值映射到负无穷到正无穷
x_trainScaler = scaler.transform(x_train) 
x_testScaler = scaler.transform(x_test)
```


# <span id="head2">规范化 (normalization)\归一化：</span>
归一化是**将每个样本缩放为单位范数（每个样本的范数为1）**。归一化是依照特征矩阵的行处理数据，其目的在于样本向量在点乘运算或其他核函数计算相似性时，拥有统一的标准，也就是说都**转化为“单位向量”，[0,1]**
$X_{\text {norm }}=\frac{X-X_{\min }}{X_{\max }-X_{\min }}$



```
from sklearn.preprocessing import Normalizer
scaler = Normalizer().fit(x_train)#归一化
x_trainScaler = scaler.transform(x_train)
x_testScaler = scaler.transform(x_test)  
```

在实际应用中，**通过梯度下降法求解的模型通常是需要归一化的**，包括线性回归、逻辑回归、支持向量机、神经网络等模型。

但对于決策树模型则并不适用，以C4.5为例，**决策树在进行节点分裂时主要依据数据集D关于特征x的信息增益比，而信息增益比跟特征是否经过归一化是无关的因为归ー化并不会改变样本在特征x上的信息增益**。

- 原因1：因为它们**不关心变量的值，而是关心变量的分布和变量之间的条件概率**；
- 原因2：因为**数值缩放不影响分裂点位置**，对树模型的结构不造成影响。按照**特征值进行排序的，排序的顺序不变，那么所属的分支以及分裂点就不会有不同**。而且，树模型是不能进行梯度下降的，因为构建树模型（回归树）寻找最优点时是通过寻找最优分裂点完成的，因此**树模型是阶跃的，阶跃点是不可导的**，并且求导没意义，也就不需要归一化。








