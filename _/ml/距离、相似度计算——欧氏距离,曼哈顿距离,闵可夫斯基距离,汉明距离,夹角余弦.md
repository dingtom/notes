- [闵可夫斯基距离(Minkowski Distance)](#head1)
- [ 曼哈顿(Manhattan)距离](#head2)
- [ 欧氏距离](#head3)
- [切比雪夫距离 ( Chebyshev Distance )](#head4)
- [ 马氏距离](#head5)
- [ 夹角余弦距离](#head6)
- [ 汉明距离](#head7)
在机器学习领域，被俗称为距离，却不满足三条距离公理的不仅仅有余弦距离（满足正定性和对称性，但是不满足三角不等式)，还有~~KL距离（ Kulback- Leibler Divergence),也叫作相对熵（不满足对称性和三角不等式），它常用于计算两个分布之间的差异~~

# <span id="head1">闵可夫斯基距离(Minkowski Distance)</span>
$d_{1,2}=\sqrt[p]{\sum_{k=1}^{n}\left|x_{k}-x_{k+1}\right|^{p}}$
其中p是一个变参数。
当p=1时，就是曼哈顿距离
当p=2时，就是欧氏距离
当p→∞时，就是切比雪夫距离

# <span id="head2"> 曼哈顿(Manhattan)距离</span>
等于两个点在坐标系上绝对轴距总和。

$d_{1，2}=\left|x_{1}-x_{2}\right|+\left|y_{1}-y_{2}\right|$

# <span id="head3"> 欧氏距离</span>
在二维空间中，两点的欧式距离就是：
欧氏距离：$\|A-B\|_2=\sqrt{\left(x_{2}-x_{1}\right)^{2}+\left(y_{2}-y_{1}\right)^{2}}$
同理，我们也可以求得两点在n维空间中的距离：
![](https://upload-images.jianshu.io/upload_images/18339009-455560748c6639aa.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


# <span id="head4">切比雪夫距离 ( Chebyshev Distance )</span>

两个点坐标数值差的绝对值的最大值
$d_{1,2}=max( | x_2-x_1 | , | y_2-y_1 | ) $




# <span id="head5"> 马氏距离</span>
马氏距离又称为**数据的协方差距离**，它是一种有效的计算两个未知**样本集的相似度**的方法。马氏距离的结果也是**将数据投影到N(0,1)区间并求其欧式距离**，与标准化欧氏距离不同的是它认为各个维度之间不是独立分布的，所以马氏距离考虑到各种特性之间的联系。**尺度无关，考虑数据之间的联系**
![](https://upload-images.jianshu.io/upload_images/18339009-83fdfa54f83c2147.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

最典型的就是根据距离作判别问题，即假设有n个总体，计算某个样品X归属于哪一类的问题。此时虽然样品X离某个总体的欧氏距离最近，但是未必归属它，**比如该总体的方差很小，说明需要非常近才能归为该类。对于这种情况，马氏距离比欧氏距离更适合作判别。**

# <span id="head6"> 夹角余弦距离</span>
欧氏距离体现数值上的绝对差异，而余弦距离体现**方向上的相对差异。**

在机器学习问题中，通常将特征表示为向量的形式，所以在分析两个特征向量之间的相似性时，常使用余弦相似度来表示。**余弦相似度的取值范围是「-1,1]**，相同的两个向量之间的相似度为1。如果希望得到类似于距离的表示，**将1減去余弦相似度即为余弦距离**。因此，**余弦距离的取值范围为[0,2]**，相同的两个向量余弦距离为0

对于两个向量A和B，其余弦相似度定义为:
$cos (A, B)=\frac{A \cdot B}{\|A\|_{2}\|B\|_{2}}$

在兴趣相关性比较上，角度关系比距离的绝对值更重要，因此余弦距离可以用于**衡量用户对内容兴趣的区分度**。

如果使用词频或词向量作为特征，它们在特征空间中的的欧氏距离通常很大；而如果使用余弦相似度的话，它们之间的夹角可能很小，因而相似度高。此外，在文本、图像、视频等领域，

余弦相似度在高维情况下依然保持“相同时为1,正交时为0,相反时为-1"”的性质，而欧氏距离的数值则受维度的影响，范围不固定，并且含义也比较模糊。



# <span id="head7"> 汉明距离</span>
两个等长字符串s1与s2之间的汉明距离定义为~~将其中一个变为另外一个所需要作的最小替换次数~~。例如字符串“1111”与“1001”之间的汉明距离为2。

应用：信息编码（为了增强容错性，应使得编码间的最小汉明距离尽可能大）。













