

# 异常值检测特征分为类别特征和数字特征
## 数字特征
相关性分析、查看特征的偏度和峰度、数字特征相互之间的关系可视化、多变量互相回归关系可视化、数字特征的频数可视化      
## 类别特征
ounique分布、箱形图可视化、小提琴图可视化、类别柱形图可视化

# 异常值处理

## 箱线图(没有对数据作任何限制性要求)
## 3-$\sigma$(Sigma)(符合正态分布）
## BOX-COX转换（处理有偏分布）
## 长尾截断

聚类、k近邻、One Class SVM、Isolation Forest

>关于高势集特征model，也就是类别中取值个数非常多的， 一般可以使用聚类的方式，然后独热

# 很多模型假设数据服从正态分布
数据整体**服从正态分布，样本均值和方差则相互独立**。当样本不服从正态分布时，可以做如下转换：

- 线性变化z-scores：基于原始数据的均值（mean）和标准差（standard deviation）进行数据的标准化。将A的原始值x使用z-score标准化到x’
   


- yeo-johnson变换：是幂变换（power transformation）的方法之一，通过构建一组单调函数对随机变量进行数据变换。


- Boxcox变换：一种广义幂变换方法，是统计建模中常用的一种数据变换，用于连续的响应变量不满足正态分布的情况。在做线性回归的过程中，一般需要做线性模型假定。

关于box-cox转换，一般是用于连续的变量不满足正态的时候，在做线性回归的过程中，一般线性模型假定:   $Y=X\beta + \epsilon$

其中$\epsilon$满足正态分布，但是利用实际数据建立回归模型时，个别变量的系数通不过。例如往往不可观测的误差$\epsilon$可能是和预测变量相关的，不服从正态分布，于是给线性回归的最小二乘估计系数的结果带来误差，为了使模型满足线性性、独立性、方差齐性以及正态性，需改变数据形式，故应用BOX-COX转换。具体详情这里不做过多介绍，当然还有很多转换非正态数据分布的方式：
![](https://upload-images.jianshu.io/upload_images/18339009-03d35f2ce4fcf3bb.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
在一些情况下（P值<0.003）上述方法很难实现正态化处理，所以优先使用BOX-COX转换，但是当P值>0.003时两种方法均可，优先考虑普通的平方变换。
BOX-COX的变换公式：
![](https://upload-images.jianshu.io/upload_images/18339009-b259d819c0b52fe5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

# 类别不平衡
1. 尝试其他评价指标：AUC等![](https://upload-images.jianshu.io/upload_images/18339009-ad7a1a95d3fc3930.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)![](https://upload-images.jianshu.io/upload_images/18339009-e8164d86267b6091.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


3. 将大类分解成多个小类
7. 数据多的欠采样（删除，原型生成（k-means中心点代替整个簇）），数据少的过采样（复制）
5. 合成样本： SMOTE![](https://upload-images.jianshu.io/upload_images/18339009-c4614c1a6ecfa106.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)![](https://upload-images.jianshu.io/upload_images/18339009-a849793b5b2cabf0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)![](https://upload-images.jianshu.io/upload_images/18339009-32440d787b58ea3f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
6. 改造模型：决策树等加权少类别的样本错分代价（Cost Sensitive算法代价敏感）![](https://upload-images.jianshu.io/upload_images/18339009-32d21a377f8a4a03.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)![](https://upload-images.jianshu.io/upload_images/18339009-549fda99dd596244.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)![](https://upload-images.jianshu.io/upload_images/18339009-1db1be1cea7e4a11.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)![](https://upload-images.jianshu.io/upload_images/18339009-9a77fbecdd31e60a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)




# 训练数据不足
迁移学习（ Transfer Learning)微调
生成对抗网络
图像处理（变换角度（旋转、平移、缩放、裁剪），添加噪声扰动，颜色变换。改变图像的亮度、清晰度）
上采样技术，数据合成SMOTE (Synthetic Minority Over-sampling Technique）


# 数据转换的方式有：
数据归一化(MinMaxScaler)；
标准化(StandardScaler)；
对数变换(log1p)；
转换数据类型(astype)；
独热编码(OneHotEncoder)；
标签编码(LabelEncoder)；
修复偏斜特征(boxcox1p)等。

## 使用独热编码需要注意以下问题
(1)使用稀疏向量来**节省空间**。在独热编码下，特征向量只有某一维取值为1,其他位置取值均为0.因此可以利用向量的稀疏表示有效地节省空间，并且目前大部分的算法均接受稀疏向量形式的输入。
（2)**配合特征选择来降低维度**。高维度特征会带来几方面的问题。一是在K近邻算法中，**高维空间下两点之间的距离很难得到有效的衡量**；二是在逻辑回归模型中，**参数的数量会随着维度的增高而增加**，容易引起过拟合问题；三是通常只有**部分维度是对分类、预测有帮助，因此可以考虑配合特征选择来降低维度。**

