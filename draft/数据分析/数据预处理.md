```

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as msno  # 用于可视化缺失值分布
import scipy.stats as st
```
# 预览数据：
- 读入外部数据
```data = pd.read_excel(io=r'C:\Users\Administrator\Desktop\datas\data.xlsx')```
```dataset = pd.read_csv('../datasets/Data.csv')```
- 查看数据的规模
```data.shape```
- 预览数据
```data.head().append(data.tail())```
edu各种值个数,**每列都看一下防止数据倾斜，可以直接删掉**
```data['edu'].value_counts()```
edu列值排序
```data['edu'].sort_values(ascending=False)```
数据类型,是否存在除了nan以外的特殊符号异常。
```data.info()```
相关统计量
```data.describe(include='all')```
- 查看表中各变量的数据类型
当数据集变大时，需要转换数据类型来节省内存。
```data.dtypes```
- 数值型转字符型
```data['id'] = data['id'].astype(str)```
- 字符型转数值型
```data['custom_amt'] = data['custom_amt'].str[1:].astype(float)```
- 字符型转日期型
```data['order_date'] = pd.to_datetime(data['order_date'], format = '%Y年%m月%d日')```
-  字符整理
删除列- col 1中&#后面的所有字符(包括&#)
```df[ col_1 ].replace(&#.* , , regex=True, inplace=True)```

- 预测值分布
机器学习中很多model都假设数据或参数服从正态分布。当样本不服从正态分布时，可以做如下转换：
线性变化z-scores
使用Boxcox变换
使用yeo-johnson变换

盲目假设变量服从正态分布可能导致不准确的结果，要结合分析。例如：不能假设股票价格服从正态分布，因为价格不能为负，故我们可以将股票价格假设为服从对数正态分布，以确保其值≥0；而股票收益可能是负数，因此收益可以假设服从正态分布。当样本数据表明质量特征的分布为非正态时，应用基于正态分布的方法会作出不正确的判决。约翰逊分布族即为经约翰(yeo-johnson)变换后服从正态分布的随机变量的概率分布，约翰逊分布体系建立了三族分布，分别为有界SB 、对数正态SL和无界SU。

本案例的预测值为价格，显然不符合正态分布，故分别采用无界约翰逊分布Johnson SU、正态分布normal、对数正态分布lognormal，综合来看无界约翰逊分布对price的拟合效果更好。
```
import seaborn as sns
import scipy.stats as st
y = Train_data['price']
plt.figure(1); plt.title('Johnson SU')
sns.distplot(y, kde=False, fit=st.johnsonsu)
plt.figure(2); plt.title('Normal')
sns.distplot(y, kde=False, fit=st.norm)
plt.figure(3); plt.title('Log Normal')
sns.distplot(y, kde=False, fit=st.lognorm)
```
![](https://upload-images.jianshu.io/upload_images/18339009-f8cd7b2d7cd02d4d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

- 偏度和峰度

![](https://upload-images.jianshu.io/upload_images/18339009-c9aad32eedb6adf7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
```
print("Skewness: %f" % data['age'].skew())
print("Kurtosis: %f" % data['age'].kurt())
sns.distplot(data['age'],color='orange')
```
![](https://upload-images.jianshu.io/upload_images/18339009-dc6715ec1db23026.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
**大的值很少，其实该处可将其当作异常值处理填充或删除，本文中经过log变换之后，分布较均匀，可据此进行预测，这也是预测问题常用的技巧**




# 第1步：处理重复、丢失数据

- 判断数据中是否存在重复观测
```data.duplicated().any()```
使用any“方法”（即序列中只要存在一个True，则返回True）。
- 将冗余信息删除。
```data.drop_duplicates()```
**如需使drop_duplicates“方法”的删除功能作用在原始数据中，必须将inplace参数设置为True。**
```data.drop_duplicates(subset=['name','age'])```
用户的姓名和年龄相同就认为是重复数据

 - 统计各类空值的个数
```data.isnull().sum()```
- 可视化缺省值
```
import missingno as msno  
msno.matrix(data.sample(250))
msno.bar(data.sample(250))
```
![](https://upload-images.jianshu.io/upload_images/18339009-72cfbfcd77a30e39.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
![](https://upload-images.jianshu.io/upload_images/18339009-89da4536c78bb98f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

- 补全空值
sklearn.preprocesing.imputer
```
from sklearn.preprocessing import Imputer
# 这里我们需要使用pandas的iloc(区分于loc根据index来索引，iloc利用行号来索引)方法来对数据进行处理
X = data.iloc[ : , :-1].values
imputer = Imputer(missing_values="NaN", strategy="mean", axis=0)
imputer = imputer.fit(X[ : , 1:3])
X[ : , 1:3] = imputer.transform(X[ : , 1:3])
```
pandas
```
data['gender'].fillna(data['gender'].mode()[0], inplace = True)
data['age'].fillna(data['age'].median(), inplace = True)
data['edu'].fillna(data['edu'].mode()[0], inplace = True)
```
- 删除空的列。
```
data1.isnull().sum()
drop_column = ['gender','age', 'edu']
data1.drop(drop_column, axis=1, inplace = True)
```

- 增加一列 
```
data['FamilySize'] = data['SibSp'] + data['Parch'] + 1
# 满足条件(condition)，输出x，不满足输出y。
data['IsAlone'] = np.where(data['FamilySize'] > 1,0,1)
# expand，这个参数取True时，会把切割出来的内容当做一列
data1['Title'] = data1['Name'].str.split(", ", expand=True)[1].str.split(".", expand=True)[0]
```


# 第2步：类别转为数字
sklearn.preprocesing.LabelEncoder
```
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
labelencoder_X = LabelEncoder()
X[ : , 0] = labelencoder_X.fit_transform(X[ : , 0])
#Creating a dummy variable
onehotencoder = OneHotEncoder(categorical_features = [0])
X = onehotencoder.fit_transform(X).toarray()
labelencoder_Y = LabelEncoder()
Y =  labelencoder_Y.fit_transform(Y)
```
pandas
```
num_encode = {'gender' : { 'male' :1, 'female' :0}}  
data.replace(num_encode, inplace=True) 
```



# 第3步：拆分数据集为测试集合和训练集合
sklearn.crossvalidation.rain_test_split
```
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split( X , Y , test_size = 0.2, random_state = 0)
```
# 第4步：特征缩放

sklearn.preprocessing.StandardScalar
```
from sklearn.preprocessing import StandardScaler
sc_X = StandardScaler()
X_train = sc_X.fit_transform(X_train)
X_test = sc_X.transform(X_test)
```


如图所示，通过6步完成数据预处理。

此例用到的[数据](https://github.com/Avik-Jain/100-Days-Of-ML-Code/blob/master/datasets/Data.csv)，[代码](https://github.com/MLEveryday/100-Days-Of-ML-Code/blob/master/Code/Day%201_Data_Preprocessing.py)。

