<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>cv on Tomding's Blog</title><link>/categories/cv/</link><description>Recent content in cv on Tomding's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Sun, 18 Dec 2022 15:39:56 +0800</lastBuildDate><atom:link href="/categories/cv/rss.xml" rel="self" type="application/rss+xml"/><item><title>cv-标注工具和数据集</title><link>/post/cv-%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86/</link><pubDate>Sun, 18 Dec 2022 15:39:56 +0800</pubDate><guid>/post/cv-%E6%A0%87%E6%B3%A8%E5%B7%A5%E5%85%B7%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86/</guid><description>标注工具 EISeg PaddleSeg pip install paddlepaddle pip install eiseg eiseg 启动EISeg后，在右上角选择模型类型。 这里以下载针对通用场景的高精度模型为例hrnet18_ocr64_coco</description></item><item><title>cv-枝剪量化</title><link>/post/cv-%E6%9E%9D%E5%89%AA%E9%87%8F%E5%8C%96/</link><pubDate>Thu, 08 Dec 2022 09:49:29 +0800</pubDate><guid>/post/cv-%E6%9E%9D%E5%89%AA%E9%87%8F%E5%8C%96/</guid><description>MIPS：Million Instructions executed Per Second,每秒执行百万条指令，用来计算同一秒内系统的处理能力，即每秒执行了多少百万条指令。 DMIPS：Dh</description></item><item><title>cv-车道线检测</title><link>/post/cv-%E8%BD%A6%E9%81%93%E7%BA%BF%E6%A3%80%E6%B5%8B/</link><pubDate>Sat, 03 Dec 2022 01:30:21 +0800</pubDate><guid>/post/cv-%E8%BD%A6%E9%81%93%E7%BA%BF%E6%A3%80%E6%B5%8B/</guid><description>摄像头主要指标 FOV视场角 视场角越大，信息越多，畸变越大，视场角越小，信息越少，畸变越小 分辨率 一般指像素数，分辨率越高，信息越多，计算速度越</description></item><item><title>cv-CNN</title><link>/post/cv-cnn/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-cnn/</guid><description>卷积层 卷积提取底层特征减少神经网络中参数个数 局部连接。⽐起全连接，局部连接会⼤⼤减少⽹络的参数。在⼆维图像中，局部像素的关联性很强， 设计局部</description></item><item><title>cv-CTPN</title><link>/post/cv-ctpn/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-ctpn/</guid><description>CTPN算法 文本通常都是从左往右写的（水平），并且字之间的宽度都大致相同 固定宽度，来检测文本高度即可，但是如何应对变长序列呢？ 本质上还是RP</description></item><item><title>cv-Deeplab</title><link>/post/cv-deeplab/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-deeplab/</guid><description>DeeplabV1 原论文名称：Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs 论文下载地址：https://arxiv.org/abs/1412.7062 参考源码：ht</description></item><item><title>cv-Inception、Xception</title><link>/post/cv-inceptionxception/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-inceptionxception/</guid><description>如果 ResNet 是为了更深，那么 Inception 家族就是为了更宽。Inception 的作者对训练更大型网络的计算效率尤其感兴趣。换句话说：我们怎样在不增加计算成本的</description></item><item><title>cv-OpenCV</title><link>/post/cv-opencv/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-opencv/</guid><description>图像处理中的坐标系，水平向右为x轴正方向，竖直向下为y轴正方向。 #找源码 grep &amp;#39;COLOR_BGR2RGBA&amp;#39; * -rn | grep &amp;#39;\.hpp&amp;#39; 安装OpenCV-Python, pip install opencv-python==3.4.2.17 要利用SIFT和</description></item><item><title>cv-RCNN</title><link>/post/cv-rcnn/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-rcnn/</guid><description>RCNN Rich feature hierarchies for accurate object detection and semantic segmentation R-CNN存在的问题： 测试速度慢： 测试一张图片约53s(CPU)。用Selective Search:算法提取候选框用时</description></item><item><title>cv-SSD</title><link>/post/cv-ssd/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-ssd/</guid><description>原理 让图片经过卷积神经网络（VGG）提取特征，生成feature map 抽取其中六层的feature map，然后分别在这些feature map层上</description></item><item><title>cv-Swin-Transformer</title><link>/post/cv-swin-transformer/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-swin-transformer/</guid><description>网络整体框架 层次化构建方法（Hierarchical feature maps），比如特征图尺寸中有对图像下采样4倍的，8倍的以及16倍的，这样的backb</description></item><item><title>cv-TensorRT</title><link>/post/cv-tensorrt/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-tensorrt/</guid><description>TensorRT TensorRT支持几乎所有主流深度学习框架，将python框架转换成C++的TensorRT，从而可以加速推理。 算子融合(层与张量融合)</description></item><item><title>cv-Vision Transformer(ViT)</title><link>/post/cv-vision-transformervit/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-vision-transformervit/</guid><description>下图是原论文中给出的关于Vision Transformer(ViT)的模型框架。简单而言，模型由三个模块组成： Linear Projection of Flattened Patches(Emb</description></item><item><title>cv-yolo</title><link>/post/cv-yolo/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-yolo/</guid><description>YOLO vs Faster R-CNN Faster R-CNN将检测结果分为两部分求解：物体类别（分类问题）、物体位置即bounding box（回归问题），YOLO统一为一个回归问题</description></item><item><title>cv-卡号识别</title><link>/post/cv-%E5%8D%A1%E5%8F%B7%E8%AF%86%E5%88%AB/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-%E5%8D%A1%E5%8F%B7%E8%AF%86%E5%88%AB/</guid><description># 导入工具包 from imutils import contours # 也可以用自己写的方法 import numpy as np import argparse import cv2 # 设置参数 ap = argparse.ArgumentParser() ap.add_argument(&amp;#34;-i&amp;#34;, &amp;#34;--image&amp;#34;, default=&amp;#39;./images/1.png&amp;#39;, help=&amp;#34;path to input image&amp;#34;) ap.add_argument(&amp;#34;-t&amp;#34;, &amp;#34;--template&amp;#34;, default=&amp;#39;./images/template.png&amp;#39;, help=&amp;#34;path to template OCR-A image&amp;#34;) ap.add_argument(&amp;#34;-s&amp;#34;, &amp;#34;--save&amp;#34;, default=True, help=&amp;#34;save every image&amp;#34;) args = vars(ap.parse_args()) def cv_show(name, image): cv2.imshow(name, image) cv2.waitKey(0) cv2.destroyAllWindows() # 轮</description></item><item><title>cv-语义分割</title><link>/post/cv-%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/</guid><description>分割、检测 图像分类：图像中的气球是一个类别。 语义分割：分割出气球和背景。 目标检测：图像中有7个目标气球，并且检测出每个气球的坐标位置。 实例分</description></item></channel></rss>