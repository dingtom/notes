<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>非线性模型 on Tomding's Blog</title><link>/categories/%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</link><description>Recent content in 非线性模型 on Tomding's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Sun, 01 Jan 2023 14:28:53 +0800</lastBuildDate><atom:link href="/categories/%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/rss.xml" rel="self" type="application/rss+xml"/><item><title>非线性模型-K近邻算法</title><link>/post/%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B-k%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/</link><pubDate>Sun, 01 Jan 2023 14:28:53 +0800</pubDate><guid>/post/%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B-k%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/</guid><description>K-Nearest Neighbor 作为一种没有显式训练和学习过程的分类和回归算法，k 近邻在众多有监督机器学习算法中算是一种比较独特的方法。说它独特，是因为 k 近邻不像其他模</description></item><item><title>非线性模型-朴素贝叶斯</title><link>/post/%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</link><pubDate>Sun, 01 Jan 2023 14:28:53 +0800</pubDate><guid>/post/%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</guid><description>贝叶斯定理 条件概率： A 在另外一个事件 B 已经发生条件下的发生概率 $P(A|B) = \frac{P(A B)}{P(B)} $ 贝叶斯公式： #####后验概率（新信息出现后的A概率） ＝ 先验概率（A</description></item></channel></rss>