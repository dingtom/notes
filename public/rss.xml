<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Tomding's Blog</title><link>/</link><description>Recent content on Tomding's Blog</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Mon, 05 Dec 2022 20:43:26 +0800</lastBuildDate><atom:link href="/rss.xml" rel="self" type="application/rss+xml"/><item><title>linux-wsl、深度学习环境安装</title><link>/post/linux-wsl%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/</link><pubDate>Mon, 05 Dec 2022 20:43:26 +0800</pubDate><guid>/post/linux-wsl%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/</guid><description>wsl wsl -l #列出所有已安装虚拟机 wsl -l -o #列出网上可用的系统 wsl -t ubuntu #关闭ubuntu wsl --shutdown #关闭所有系统及虚拟机引擎 wsl -d ubuntu #启动ubuntu并进行终</description></item><item><title>linux-wsl、深度学习环境安装</title><link>/post/linux-wsl%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/</link><pubDate>Mon, 05 Dec 2022 20:43:26 +0800</pubDate><guid>/post/linux-wsl%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85/</guid><description>wsl wsl -l #列出所有已安装虚拟机 wsl -l -o #列出网上可用的系统 wsl -t ubuntu #关闭ubuntu wsl --shutdown #关闭所有系统及虚拟机引擎 wsl -d ubuntu #启动ubuntu并进行终</description></item><item><title>cv-车道线检测</title><link>/post/cv-%E8%BD%A6%E9%81%93%E7%BA%BF%E6%A3%80%E6%B5%8B/</link><pubDate>Sat, 03 Dec 2022 01:30:21 +0800</pubDate><guid>/post/cv-%E8%BD%A6%E9%81%93%E7%BA%BF%E6%A3%80%E6%B5%8B/</guid><description>摄像头主要指标 FOV视场角 视场角越大，信息越多，畸变越大，视场角越小，信息越少，畸变越小 分辨率 一般指像素数，分辨率越高，信息越多，计算速度越</description></item><item><title>dcoker-Docker安装Hadoop</title><link>/post/docker-docker%E5%AE%89%E8%A3%85hadoop/</link><pubDate>Fri, 02 Dec 2022 03:11:14 +0800</pubDate><guid>/post/docker-docker%E5%AE%89%E8%A3%85hadoop/</guid><description>Docker、Java、Scala、Hadoop、 Hbase、Spark。 集群共有5台机器，主机名分别为 h01、h02、h03、h04、h0</description></item><item><title>linux-Linux命令</title><link>/post/linux-linux%E5%91%BD%E4%BB%A4/</link><pubDate>Fri, 02 Dec 2022 03:11:14 +0800</pubDate><guid>/post/linux-linux%E5%91%BD%E4%BB%A4/</guid><description>Ctrl+c 强制中断程序的执行 Ctrl+z 将程序挂起，fg/bg继续任务 Ctrl+d 键盘输入结束或退出终端 Ctrl+s 中断控制台输出 ctrl+q 恢复控制台输出 ctrl+l 清屏 ctrl+左右键 在单词之间</description></item><item><title>linux-shell</title><link>/post/linux-shell/</link><pubDate>Fri, 02 Dec 2022 03:11:14 +0800</pubDate><guid>/post/linux-shell/</guid><description>#!/bin/bash ! 是一个约定的标记，它告诉系统这个脚本需要什么解释器来执行，即使用哪一种 Shell。 chmod +x ./test.sh 使脚本具有执行权限 ./test.sh 执行脚本 注意，一定要写成 ./test.sh ，</description></item><item><title>linux-ssh登录提醒</title><link>/post/linux-ssh%E7%99%BB%E5%BD%95%E6%8F%90%E9%86%92/</link><pubDate>Fri, 02 Dec 2022 03:11:14 +0800</pubDate><guid>/post/linux-ssh%E7%99%BB%E5%BD%95%E6%8F%90%E9%86%92/</guid><description>sudo apt install heirloom-mailx sudo vim /etc/nail.rc set from=178@sina.cn //发信人邮箱 set smtp=smtps://smtp.sina.com //发信人邮箱的SMTP地址 set smtp-auth-user=178@sina.cn //发信人邮箱登陆账号 set smtp-auth-password=9f8f7149d10d0b1f //发信人邮箱的授权密码 set smtp-auth=login //认证方式 set ssl-verify=ignore /</description></item><item><title>linux-ubuntu软件安装</title><link>/post/linux-ubuntu%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/</link><pubDate>Fri, 02 Dec 2022 03:11:14 +0800</pubDate><guid>/post/linux-ubuntu%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/</guid><description>分区大小 /boot：这个目录下存放的是Ubuntu的引导项，Ubuntu的启动从这里开始，这里我分配了500MB空间，之后我们的EasyBC</description></item><item><title>linux-vim</title><link>/post/linux-vim/</link><pubDate>Fri, 02 Dec 2022 03:11:14 +0800</pubDate><guid>/post/linux-vim/</guid><description>搜索 /</description></item><item><title>linux-windows-远程控制ubuntu</title><link>/post/linux-windows-%E8%BF%9C%E7%A8%8B%E6%8E%A7%E5%88%B6ubuntu/</link><pubDate>Fri, 02 Dec 2022 03:11:14 +0800</pubDate><guid>/post/linux-windows-%E8%BF%9C%E7%A8%8B%E6%8E%A7%E5%88%B6ubuntu/</guid><description>使用Xshell连接Ubuntu Ubuntu主机没有开启SSH服务，需要开启openssh-server： sudo apt-get install openssh-server 使用 ps -e | grep ssh 如果只有ss</description></item><item><title>linux-定时任务</title><link>/post/linux-%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/</link><pubDate>Fri, 02 Dec 2022 03:11:14 +0800</pubDate><guid>/post/linux-%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1/</guid><description>python import os, time while 1: timing = time.strftime(&amp;#39;%H_%M&amp;#39;, time.localtime(time.time())) # print(time.strftime(&amp;#34;%Y-%m-%d %H:%M:%S&amp;#34;, time.localtime()) ) if timing == &amp;#39;12_00&amp;#39;: print(&amp;#34;开始运行脚本:&amp;#34;) # runner.run(alltestnames) # 执行测试用例 print(&amp;#34;运行完成退出&amp;</description></item><item><title>linux-微信推送IP地址</title><link>/post/linux-%E5%BE%AE%E4%BF%A1%E6%8E%A8%E9%80%81ip%E5%9C%B0%E5%9D%80/</link><pubDate>Fri, 02 Dec 2022 03:11:14 +0800</pubDate><guid>/post/linux-%E5%BE%AE%E4%BF%A1%E6%8E%A8%E9%80%81ip%E5%9C%B0%E5%9D%80/</guid><description>为了使树莓派能够方便的移动到不同的地方，我们设置了动态IP, 而有时需要快速SSH链接树莓派，我们除了可以通过VNC远程桌面查看IP, 还可以通</description></item><item><title>linux-远程主机ip变更邮箱提醒</title><link>/post/linux-%E8%BF%9C%E7%A8%8B%E4%B8%BB%E6%9C%BAip%E5%8F%98%E6%9B%B4%E9%82%AE%E7%AE%B1%E6%8F%90%E9%86%92/</link><pubDate>Fri, 02 Dec 2022 03:11:14 +0800</pubDate><guid>/post/linux-%E8%BF%9C%E7%A8%8B%E4%B8%BB%E6%9C%BAip%E5%8F%98%E6%9B%B4%E9%82%AE%E7%AE%B1%E6%8F%90%E9%86%92/</guid><description>import socket import smtplib from email.header import Header from email.mime.multipart import MIMEMultipart from email.mime.text import MIMEText from time import asctime def send_an_email(email_content): # email_content是一个字符串 mail_host = &amp;#34;smtp.sina.com&amp;#34; # 这个去邮箱找，这里用的sina邮箱 mail_user = &amp;#39;17839906091@sina.cn&amp;#39; mail_auth_code = &amp;#39;9f8f7149d10d0b1f&amp;#39; mail_sender</description></item><item><title>cv-CNN</title><link>/post/cv-cnn/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-cnn/</guid><description>卷积层 卷积提取底层特征减少神经网络中参数个数 局部连接。⽐起全连接，局部连接会⼤⼤减少⽹络的参数。在⼆维图像中，局部像素的关联性很强， 设计局部</description></item><item><title>cv-CTPN</title><link>/post/cv-ctpn/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-ctpn/</guid><description>CTPN算法 文本通常都是从左往右写的（水平），并且字之间的宽度都大致相同 固定宽度，来检测文本高度即可，但是如何应对变长序列呢？ 本质上还是RP</description></item><item><title>cv-Deeplab</title><link>/post/cv-deeplab/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-deeplab/</guid><description>DeeplabV1 原论文名称：Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs 论文下载地址：https://arxiv.org/abs/1412.7062 参考源码：ht</description></item><item><title>cv-Inception、Xception</title><link>/post/cv-inceptionxception/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-inceptionxception/</guid><description>如果 ResNet 是为了更深，那么 Inception 家族就是为了更宽。Inception 的作者对训练更大型网络的计算效率尤其感兴趣。换句话说：我们怎样在不增加计算成本的</description></item><item><title>cv-OpenCV</title><link>/post/cv-opencv/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-opencv/</guid><description>图像处理中的坐标系，水平向右为x轴正方向，竖直向下为y轴正方向。 安装OpenCV-Python, pip install opencv-python==3.4.2.17 要利用SIFT和SURF等进行特征提取</description></item><item><title>cv-RCNN</title><link>/post/cv-rcnn/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-rcnn/</guid><description>RCNN Rich feature hierarchies for accurate object detection and semantic segmentation R-CNN存在的问题： 测试速度慢： 测试一张图片约53s(CPU)。用Selective Search:算法提取候选框用时</description></item><item><title>cv-SSD</title><link>/post/cv-ssd/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-ssd/</guid><description>原理 让图片经过卷积神经网络（VGG）提取特征，生成feature map 抽取其中六层的feature map，然后分别在这些feature map层上</description></item><item><title>cv-Swin-Transformer</title><link>/post/cv-swin-transformer/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-swin-transformer/</guid><description>网络整体框架 层次化构建方法（Hierarchical feature maps），比如特征图尺寸中有对图像下采样4倍的，8倍的以及16倍的，这样的backb</description></item><item><title>cv-TensorRT</title><link>/post/cv-tensorrt/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-tensorrt/</guid><description>TensorRT TensorRT支持几乎所有主流深度学习框架，将python框架转换成C++的TensorRT，从而可以加速推理。 算子融合(层与张量融合)</description></item><item><title>cv-Vision Transformer(ViT)</title><link>/post/cv-vision-transformervit/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-vision-transformervit/</guid><description>下图是原论文中给出的关于Vision Transformer(ViT)的模型框架。简单而言，模型由三个模块组成： Linear Projection of Flattened Patches(Emb</description></item><item><title>cv-yolo</title><link>/post/cv-yolo/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-yolo/</guid><description>YOLO vs Faster R-CNN Faster R-CNN将检测结果分为两部分求解：物体类别（分类问题）、物体位置即bounding box（回归问题），YOLO统一为一个回归问题</description></item><item><title>cv-残差网络(ResNet)</title><link>/post/cv-%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9Cresnet/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-%E6%AE%8B%E5%B7%AE%E7%BD%91%E7%BB%9Cresnet/</guid><description>残差操作这一思想起源于论文《Deep Residual Learning for Image Recognition》。如果存在某个K层的网络f是当前最优的网络，那么可以构造一个更深的网络，</description></item><item><title>cv-卷积神经网络（CNN)</title><link>/post/cv-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Ccnn/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Ccnn/</guid><description>卷积层 卷积提取底层特征减少神经网络中参数个数 为了避免尺寸的变化可以在当前层的矩阵的边界加入全０填充（zero-padding）．否则中间的像</description></item><item><title>cv-卡号识别</title><link>/post/cv-%E5%8D%A1%E5%8F%B7%E8%AF%86%E5%88%AB/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-%E5%8D%A1%E5%8F%B7%E8%AF%86%E5%88%AB/</guid><description># 导入工具包 from imutils import contours # 也可以用自己写的方法 import numpy as np import argparse import cv2 # 设置参数 ap = argparse.ArgumentParser() ap.add_argument(&amp;#34;-i&amp;#34;, &amp;#34;--image&amp;#34;, default=&amp;#39;./images/1.png&amp;#39;, help=&amp;#34;path to input image&amp;#34;) ap.add_argument(&amp;#34;-t&amp;#34;, &amp;#34;--template&amp;#34;, default=&amp;#39;./images/template.png&amp;#39;, help=&amp;#34;path to template OCR-A image&amp;#34;) ap.add_argument(&amp;#34;-s&amp;#34;, &amp;#34;--save&amp;#34;, default=True, help=&amp;#34;save every image&amp;#34;) args = vars(ap.parse_args()) def cv_show(name, image): cv2.imshow(name, image) cv2.waitKey(0) cv2.destroyAllWindows() # 轮</description></item><item><title>cv-语义分割</title><link>/post/cv-%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/cv-%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/</guid><description>标注工具 Labelme 支持目标检测、语义分割、实例分割等任务。今天针对分割任务的数据标注进行简单的介绍。开源项目地址： https://github.com/wkentaro/labelme 安装非常简单，直接使用pip安装</description></item><item><title>linux-Hadoop环境</title><link>/post/linux-hadoop%E7%8E%AF%E5%A2%83/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/linux-hadoop%E7%8E%AF%E5%A2%83/</guid><description>wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel62-3.4.3.tgz tar -xf mongodb-linux-x86_64-rhel62-3.4.3.tgz -C ~/ mv mongodb-linux-x86_64-rhel62-3.4.3/ /usr/local/mongodb // 在安装目录下创建 data 文件夹用于存放数据和日志 mkdir /usr/local/mongodb/data/ // 在 data 文件夹下创建 db 文件夹，用于存放数据 mkdir /usr/local/mongodb/data/db/ // 在 data 文件夹下创建 logs 文件夹，</description></item><item><title>linux-显卡安装驱动</title><link>/post/ml-gpu%E7%89%88pytorch%E5%AE%89%E8%A3%85/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/ml-gpu%E7%89%88pytorch%E5%AE%89%E8%A3%85/</guid><description>驱动安装 #https://www.nvidia.cn/geforce/drivers/ #查看显卡型号 lspci | grep -i nvidia #安装驱动 sudo bash NVIDIA-Linux-x86_64-455.23.04.run #查看显卡信息 nvidia-smi 卸载显卡驱动重新安装 #命令行界面 Ctrl+Alt+F1 sudo apt-get --purge remove nvidia* sudo apt autoremove # To remove CUDA Toolkit: sudo apt-get --purge remove &amp;#34;*cublas*&amp;#34; &amp;#34;cuda*&amp;#34; #</description></item><item><title>ml-Attention机制</title><link>/post/ml-attention%E6%9C%BA%E5%88%B6/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/ml-attention%E6%9C%BA%E5%88%B6/</guid><description>https://github.com/CyberZHG/keras-self-attention/blob/master/README.zh-CN.md https://github.com/CyberZHG/keras-self-attention/blob/master/keras_self_attention/seq_self_attention.py 用Attention机制的原因是考虑到RNN（或者LSTM，GRU等）的计算限制为是顺序的，也就是说RNN相关算法只能从左向右依次计算或</description></item><item><title>ml-gpu版pytorch安装</title><link>/post/linux-%E6%98%BE%E5%8D%A1%E5%AE%89%E8%A3%85%E9%A9%B1%E5%8A%A8/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/linux-%E6%98%BE%E5%8D%A1%E5%AE%89%E8%A3%85%E9%A9%B1%E5%8A%A8/</guid><description>驱动安装 #https://www.nvidia.cn/geforce/drivers/ #查看显卡型号 lspci | grep -i nvidia #安装驱动 sudo bash NVIDIA-Linux-x86_64-455.23.04.run #查看显卡信息 nvidia-smi 卸载显卡驱动重新安装 #命令行界面 Ctrl+Alt+F1 sudo apt-get --purge remove nvidia* sudo apt autoremove # To remove CUDA Toolkit: sudo apt-get --purge remove &amp;#34;*cublas*&amp;#34; &amp;#34;cuda*&amp;#34; #</description></item><item><title>ml-infoGAN</title><link>/post/ml-infogan/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/ml-infogan/</guid><description>InfoGAN的发布时间应该在是DCGAN之后没多久，可以算是在大部分的GAN模型的前面的。时间上看，InfoGAN应该是在Semi-GAN</description></item><item><title>ml-Jupyter-Notebook</title><link>/post/ml-jupyter-notebook/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/ml-jupyter-notebook/</guid><description>安装 jupyter conda install ipython conda install jupyter 换主题 pip install jupyterthemes 查看可用的 Jupyter 主题 jt -l 更换 Jupyter 主题 jt -t onedork -f fira -fs 13 -cellw 90% -ofs 11 -dfs 11 -T -T -m 10 -t 主题 -f(字体) -fs(字体大小) -cell</description></item><item><title>ml-keras</title><link>/post/ml-keras/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/ml-keras/</guid><description>tensorboard writer=tf.summary.FileWriter(&amp;#39;/path/to/logs&amp;#39;, tf.get_default_graph()) writer.close() 在上面程序的8、9行中，创建一个writer，将tensorboard summary写入文件夹/path/to/logs， 然后运行上</description></item><item><title>ml-keras-utils-plot_model报错</title><link>/post/ml-keras-utils-plot_model%E6%8A%A5%E9%94%99/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/ml-keras-utils-plot_model%E6%8A%A5%E9%94%99/</guid><description>OSError: pydot failed to call GraphViz.Please install GraphViz ( https://www.graphviz.org/ ) and ensure that its executables are in the $PATH. 或 Failed to import pydot. You must install pydot and graphviz win10 ####1.安装 GraphViz 下载msi文件安装 与python关联 pip install graphviz ####2.添加</description></item><item><title>ml-pytorch</title><link>/post/ml-pytorch/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/ml-pytorch/</guid><description>1.安装 https://pytorch.org pip3 config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple # ２.基础 创建一个 5x3 矩阵, 但是未初始化: torch.empty(5, 3) 创建一个随机初始化的矩阵: torch.rand(5, 3) 创建一个0填充的矩阵，数据类型为long torch.zeros(5, 3, dtype=torch.long)</description></item><item><title>ml-Seq2Seq-模型及-Attention-机制</title><link>/post/ml-seq2seq-%E6%A8%A1%E5%9E%8B%E5%8F%8A-attention-%E6%9C%BA%E5%88%B6/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/ml-seq2seq-%E6%A8%A1%E5%9E%8B%E5%8F%8A-attention-%E6%9C%BA%E5%88%B6/</guid><description>什么是 Seq2Seq ？ Seq2Seq 任务指的是输入和输出都是序列的任务。例如说英语翻译成中文。 Seq2Seq任务最常见的是使用Encoder+Decoder的模式。</description></item><item><title>ml-sklearn</title><link>/post/ml-sklearn/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/ml-sklearn/</guid><description>中文手册 英文手册 在Sklearn当中有三大模型：Transformer 转换器、Estimator 估计器、Pipeline 管道 估计器 (estimator) 可以基于</description></item><item><title>ml-Tensorflow官方debug--tfdbg</title><link>/post/ml-tensorflow%E5%AE%98%E6%96%B9debug--tfdbg/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/ml-tensorflow%E5%AE%98%E6%96%B9debug--tfdbg/</guid><description>example code： import numpy as np import tensorflow as tf from tensorflow.python import debug as tf_debug xs = np.linspace(-0.5, 0.49, 100) x = tf.placeholder(tf.float32, shape=[None], name=&amp;#34;x&amp;#34;) y = tf.placeholder(tf.float32, shape=[None], name=&amp;#34;y&amp;#34;) k = tf.Variable([0.0], name=&amp;#34;k&amp;#34;) y_hat = tf.multiply(k, x, name=&amp;#34;y_hat&amp;#34;) sse = tf.reduce_sum((y - y_hat) * (y - y_hat), name=&amp;#34;sse&amp;#34;) train_op = tf.train.GradientDescentOptimizer(learning_rate=0.02).minimize(sse) sess = tf.Session() sess.run(tf.global_variables_initializer()) sess = tf_debug.LocalCLIDebugWrapperSession(sess,ui_type=&amp;#34;readline&amp;#34;) for _ in range(10): sess.run(y_hat,feed_dict={x:xs,y:10*xs}) sess.run(train_op,</description></item><item><title>ml-插值</title><link>/post/ml-%E6%8F%92%E5%80%BC/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/ml-%E6%8F%92%E5%80%BC/</guid><description>一维插值 插值不同于拟合。插值函数经过样本点，拟合函数一般基于最小二乘法尽量靠近所有样本点穿过。常见插值方法有拉格朗日插值法、分段插值法、样条</description></item><item><title>ml-迁移学习(Transfer-Learning)</title><link>/post/ml-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0transfer-learning/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/ml-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0transfer-learning/</guid><description>训练复杂的卷积神经网络需要非常多的标注数据。 所谓迁移学习，就是讲一个问题上训练好的模型通过简单的调整使其适用于一个新的问题。 根据论文DeCA</description></item><item><title>ml-生成对抗网络(GAN)</title><link>/post/ml-%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9Cgan/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/ml-%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9Cgan/</guid><description>Goodfellow的Generative Adversarial Networks https://arxiv.org/abs/1406.2661 本质上， GAN 目标是训练出一个好的生成模型，来模拟训练集中的数据。不同的是， 一般的生成模型，必须</description></item><item><title>ml-循环神经网络(RNN)</title><link>/post/ml-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Crnn/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/ml-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Crnn/</guid><description>RNN 神经网络只能单独的取处理一个个的输入，前一个输入和后一个输入是完全没有关系的。但是，某些任务需要能够更好的处理序列的信息，即前面的输入和后</description></item><item><title>ml-自动机器学习</title><link>/post/ml-%E8%87%AA%E5%8A%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/ml-%E8%87%AA%E5%8A%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</guid><description>AutoKeras是一个开源的，基于 Keras 的新型 AutoML 库。AutoKeras 是一个用于自动化机器学习的开源软件库，提供自动搜索深度学习模型的架构和超</description></item><item><title>面试-leetcode 热题100</title><link>/post/%E9%9D%A2%E8%AF%95-leetcode-%E7%83%AD%E9%A2%98100/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-leetcode-%E7%83%AD%E9%A2%98100/</guid><description>leetcode 热题100 第一周，链表、栈、队列 第一天：链表（周三） 1、 链表的基础知识：单链表 2、 反转链表（ LeetCode 206 ） 3、 相交链表（ LeetCode 160 ） 4、 合并两个有序链表</description></item><item><title>面试-leetcode分类</title><link>/post/%E9%9D%A2%E8%AF%95-leetcode%E5%88%86%E7%B1%BB/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-leetcode%E5%88%86%E7%B1%BB/</guid><description>数据结构与算法简介、LeetCode 入门及攻略（1 天） 数据结构与算法 算法复杂度 LeetCode 入门与攻略 0001. 两数之和 1929. 数组串联 0771. 宝石与石头 数组基础（2 天） 数</description></item><item><title>面试-leetcode面试top100</title><link>/post/%E9%9D%A2%E8%AF%95-leetcode%E9%9D%A2%E8%AF%95top100/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-leetcode%E9%9D%A2%E8%AF%95top100/</guid><description>汇总 (10 封私信) 互联网公司最常见的面试算法题有哪些？ - 知乎 (zhihu.com) 模拟 134. 加油站 在一条环路上有 N 个加油站，其中第 i 个加油站有汽油 gas[i] 升。 你有一辆油箱容量</description></item><item><title>面试-ML</title><link>/post/%E9%9D%A2%E8%AF%95-ml/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-ml/</guid><description>激活函数 需要激活函数来引入非线性因素，使得神经网络可以任意逼近任何非线性函数。 softmax函数，又称归一化指数函数。它是二分类函数sigm</description></item><item><title>面试-mysql</title><link>/post/%E9%9D%A2%E8%AF%95-mysql/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-mysql/</guid><description>[TOC] 安装 win https://dev.mysql.com/downloads/mysql/ http://mirrors.sohu.com/mysql/MySQL-8.0/ 配置环境变量path 新建一个my.ini 用记事本打开 [mysqld] # 设置mysql的安装目录 basedir=D:\\software\\java\\mysql-5.7.28-winx64 # 切记此处一定要用双斜杠\\，单斜杠这里会出错</description></item><item><title>面试-MySQL题</title><link>/post/%E9%9D%A2%E8%AF%95-mysql%E9%A2%98/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-mysql%E9%A2%98/</guid><description>数据库事务ACID四大特性 “一致性”为最终目标，其他特性都是为达到这个目标而采取的措施和手段。 原子性：事务中包括的所有操作要么都做，要么都不</description></item><item><title>面试-Normalize</title><link>/post/%E9%9D%A2%E8%AF%95-normalize/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-normalize/</guid><description>Batch Normalization（BN，2015年） Layer Normalization（LN，2016年） Instance Normalization（IN，2017</description></item><item><title>面试-标准化、归一化、正则化</title><link>/post/%E9%9D%A2%E8%AF%95-%E6%A0%87%E5%87%86%E5%8C%96%E5%BD%92%E4%B8%80%E5%8C%96%E6%AD%A3%E5%88%99%E5%8C%96/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E6%A0%87%E5%87%86%E5%8C%96%E5%BD%92%E4%B8%80%E5%8C%96%E6%AD%A3%E5%88%99%E5%8C%96/</guid><description>瘦长的椭圆，会导致趋向最值时梯度下降的震荡；所以需要缩放特征值，使得其取值范围相近。按经验，特征缩放到3倍或1/3是比较可以接受的。 标准化（</description></item><item><title>面试-方差、偏差、过拟合与欠拟合</title><link>/post/%E9%9D%A2%E8%AF%95-%E6%96%B9%E5%B7%AE%E5%81%8F%E5%B7%AE%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E6%96%B9%E5%B7%AE%E5%81%8F%E5%B7%AE%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88/</guid><description>过拟合是指模型对于训练数据拟合呈过当的情况，反映到评估指标上，就是模型在训练集上的表现很好，但在测试集和新数据上的表现较差。欠拟合指的是模型</description></item><item><title>面试-激活、损失函数</title><link>/post/%E9%9D%A2%E8%AF%95-%E6%BF%80%E6%B4%BB%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E6%BF%80%E6%B4%BB%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</guid><description>激活函数 如果不用激励函数（其实相当于激励函数是f(x) = x），在这种情况下你每一层节点的输入都是上层输出的线性函数，很容易验证，无论你神经网</description></item><item><title>面试-技术问题</title><link>/post/%E9%9D%A2%E8%AF%95-%E6%8A%80%E6%9C%AF%E9%97%AE%E9%A2%98/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E6%8A%80%E6%9C%AF%E9%97%AE%E9%A2%98/</guid><description>排序算法 不稳定：快选堆希 O(n*log2n) 快归堆希 1.插入排序 ： 从第二个元素开始，每轮，已排序后面的元素向前比较，找到比他小或相等的元素，放到其后面 2.冒泡</description></item><item><title>面试-距离、相似度计算——欧氏距离,曼哈顿距离,闵可夫斯基距离,汉明距离,夹角余弦</title><link>/post/%E9%9D%A2%E8%AF%95-%E8%B7%9D%E7%A6%BB%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%E6%AC%A7%E6%B0%8F%E8%B7%9D%E7%A6%BB%E6%9B%BC%E5%93%88%E9%A1%BF%E8%B7%9D%E7%A6%BB%E9%97%B5%E5%8F%AF%E5%A4%AB%E6%96%AF%E5%9F%BA%E8%B7%9D%E7%A6%BB%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB%E5%A4%B9%E8%A7%92%E4%BD%99%E5%BC%A6/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E8%B7%9D%E7%A6%BB%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%E6%AC%A7%E6%B0%8F%E8%B7%9D%E7%A6%BB%E6%9B%BC%E5%93%88%E9%A1%BF%E8%B7%9D%E7%A6%BB%E9%97%B5%E5%8F%AF%E5%A4%AB%E6%96%AF%E5%9F%BA%E8%B7%9D%E7%A6%BB%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB%E5%A4%B9%E8%A7%92%E4%BD%99%E5%BC%A6/</guid><description>在机器学习领域，被俗称为距离，却不满足三条距离公理的不仅仅有余弦距离（满足正定性和对称性，但是不满足三角不等式)，还有KL距离（ Kulback- Leibler Dive</description></item><item><title>面试-面试3（计算机基础）</title><link>/post/%E9%9D%A2%E8%AF%95-%E9%9D%A2%E8%AF%953%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E9%9D%A2%E8%AF%953%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/</guid><description>顺序表（线性表）可随机存储，存储密度大（无指针）。 单链表（线性表）顺序存储，非连续存储空间，更容易表示逻辑结构。 n个元素进栈，共有$\fra</description></item><item><title>面试-面试问题</title><link>/post/%E9%9D%A2%E8%AF%95-%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98/</guid><description>别说自己有什么，说你能给公司带来什么 表达对岗位特别感兴趣，甚至直接说要你你就去 每次面试一定要录音！！！ 之后再把自己的回答整理出QA,不断的修</description></item><item><title>面试-模型调参</title><link>/post/%E9%9D%A2%E8%AF%95-%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E6%A8%A1%E5%9E%8B%E8%B0%83%E5%8F%82/</guid><description>贪心调参 （坐标下降） 所谓贪心算法是指，在对问题求解时，总是做出在当前看来是最好的选择。也就是说，不从整体最优上加以考虑，它所做出的仅仅是在某</description></item><item><title>面试-模型评估指标</title><link>/post/%E9%9D%A2%E8%AF%95-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/</guid><description>回归 RMSE（Root Mean Square Error）均方根误差 衡量观测值与真实值之间的偏差。常用来作为机器学习模型预测结果衡量的标准。如果存在个别偏离程度</description></item><item><title>面试-模型融合</title><link>/post/%E9%9D%A2%E8%AF%95-%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/</guid><description>简单加权融合 回归： 算术平均融合（Arithmetic mean） 加权算术平均法 几何平均融合（Geometric mean） 分类： 投票（Votin</description></item><item><title>面试-排序算法</title><link>/post/%E9%9D%A2%E8%AF%95-%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</guid><description>排序算法 平均时间复杂度 最好/差时间复杂度 空间复杂度 数据对象稳定性 冒泡排序 O(n2) O(n)/O(n2) O(1) 稳定 选择排序 O(n2) O(n2)/O(n2) O(1) 不稳定 插入排序 O(n2) O(n)/O(n2) O(1) 稳定 希尔排序 O(n^(1.3-2)) O(1) 不稳定 快</description></item><item><title>面试-缺失值处理</title><link>/post/%E9%9D%A2%E8%AF%95-%E7%BC%BA%E5%A4%B1%E5%80%BC%E5%A4%84%E7%90%86/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E7%BC%BA%E5%A4%B1%E5%80%BC%E5%A4%84%E7%90%86/</guid><description>删除 样本数据量十分大且缺失值不多的情况下非常有效，但如果样本量本身不大且缺失也不少，那么不建议使用。 #删除数据表中含有空值的行 df.dropna(how=&amp;#39;any&amp;#39;) 不处理 补齐处</description></item><item><title>面试-神经网络的计算量和参数量</title><link>/post/%E9%9D%A2%E8%AF%95-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E9%87%8F%E5%92%8C%E5%8F%82%E6%95%B0%E9%87%8F/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%AE%A1%E7%AE%97%E9%87%8F%E5%92%8C%E5%8F%82%E6%95%B0%E9%87%8F/</guid><description>FLOPS，即每秒浮点操作次数FLoating point OPerations per Second这个指标来衡量GPU的运算能力。 MACC，即乘加数Multiply-ACCu</description></item><item><title>面试-数据分析指标</title><link>/post/%E9%9D%A2%E8%AF%95-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8C%87%E6%A0%87/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8C%87%E6%A0%87/</guid><description>DAU(Daily Active Users) DNU(Daily New Users) ARPU(Average Revenue per User) ARPPU(Average Revenue per Paying User) APA (Active Payment Account) ROI(投资回报率） = $（收入－成本）／投入＊100% $ 它所表达的是 收回了多少，而非利润，更准确点说就</description></item><item><title>面试-数据集的划分</title><link>/post/%E9%9D%A2%E8%AF%95-%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%88%92%E5%88%86/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%88%92%E5%88%86/</guid><description>Holdout检验 按一定比例划分为训练集和测试集 这种方法也称为保留法。我们通常取8-2、7-3、6-4、5-5比例切分，直接将数据随机划分为</description></item><item><title>面试-数据结构算法</title><link>/post/%E9%9D%A2%E8%AF%95-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AE%97%E6%B3%95/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AE%97%E6%B3%95/</guid><description>数组 优点：找到某一下下标（index)的元素所需时间O(1) 缺点：需要分配连续空间；查询需要遍历整个数组时间为 O(n)；删除添加时间O(n)</description></item><item><title>面试-数据挖掘步骤</title><link>/post/%E9%9D%A2%E8%AF%95-%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E6%AD%A5%E9%AA%A4/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E6%AD%A5%E9%AA%A4/</guid><description/></item><item><title>面试-数据预处理</title><link>/post/%E9%9D%A2%E8%AF%95-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/</guid><description>import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns import missingno as msno # 用于可视化缺失值分布 import scipy.stats as st 预览数据： 读入外部数据 data = pd.read_excel(io=r'C:\Users\Administrator\Desktop\datas\data.xlsx') dataset = pd.read_csv('../datasets/Data.csv') 查看数据的规模 data.shape 预览数据 data.head().append(data.tail()) edu各种</description></item><item><title>面试-特征构造、选择</title><link>/post/%E9%9D%A2%E8%AF%95-%E7%89%B9%E5%BE%81%E6%9E%84%E9%80%A0%E9%80%89%E6%8B%A9/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E7%89%B9%E5%BE%81%E6%9E%84%E9%80%A0%E9%80%89%E6%8B%A9/</guid><description>特征构造 统计量特征：计数、求和、比例、标准差等 时间特征：相对时间、绝对时间，节假日，双休日等 地理信息：分桶 非线性变换：取log、平方、根号 数</description></item><item><title>面试-异常处理</title><link>/post/%E9%9D%A2%E8%AF%95-%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</guid><description>异常值检测特征分为类别特征和数字特征 数字特征 相关性分析、查看特征的偏度和峰度、数字特征相互之间的关系可视化、多变量互相回归关系可视化、数字特</description></item><item><title>面试-异常值检测</title><link>/post/%E9%9D%A2%E8%AF%95-%E5%BC%82%E5%B8%B8%E5%80%BC%E6%A3%80%E6%B5%8B/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E5%BC%82%E5%B8%B8%E5%80%BC%E6%A3%80%E6%B5%8B/</guid><description>简单统计 df.describe() 散点图 3∂原则 这个原则有个条件：数据需要服从正态分布。在3∂原则下，异常值如超过3倍标准差，那么可以将其视为异常值。正负3∂的概率</description></item><item><title>面试-优化算法</title><link>/post/%E9%9D%A2%E8%AF%95-%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/</link><pubDate>Thu, 01 Dec 2022 19:59:47 +0800</pubDate><guid>/post/%E9%9D%A2%E8%AF%95-%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/</guid><description>主要有三大类： 基本梯度下降法，包括 GD，BGD，SGD； 动量优化法，包括 Momentum，NAG 等； 自适应学习率优化法，包括 Adam，Ada</description></item><item><title>关于 Hugo NexT 组织</title><link>/about.html</link><pubDate>Thu, 09 Jun 2022 20:12:52 +0800</pubDate><guid>/about.html</guid><description>Hugo NexT 组织是由众多喜爱 NexT 主题及风格的世界各地友人共同组建而成，为的就是让这个主题继续在 Hugo 引擎中也能得到发扬光大，在此也欢迎你的加入！ 我们的愿景</description></item><item><title>站点示例</title><link>/flinks.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>/flinks.html</guid><description>如想交换本站友情链接，请在评论区留下你的站点信息，格式参考如下： - name: Hugo-NexT desc: Hugo NexT 官方预览网站。 avatar: https://hugo-next.eu.org/imgs/hugo_next_avatar.png link: https://hugo-next.eu.org</description></item></channel></rss>