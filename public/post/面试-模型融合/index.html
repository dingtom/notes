<!doctype html><html lang=zh-cn data-theme=dark><head><meta charset=utf-8><meta name=viewport content="width=device-width"><meta name=theme-color content="#222" media="(prefers-color-scheme: dark)"><meta name=generator content="Hugo 0.107.0"><link rel="shortcut icon" type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=/imgs/icons/favicon_16x16_next.png><link rel=icon type=image/png sizes=32x32 href=/imgs/icons/favicon_32_32_next.png><link rel=apple-touch-icon sizes=180x180 href=/imgs/icons/apple_touch_icon_next.png><meta itemprop=name content="面试-模型融合"><meta itemprop=description content="Love and Peace"><meta itemprop=datePublished zgotmplz><meta itemprop=dateModified zgotmplz><meta itemprop=image content="/imgs/hugo_next_avatar.png"><meta itemprop=keywords content="Hugo,NexT,主题,简单,强大"><meta property="og:type" content="article"><meta property="og:title" content="面试-模型融合"><meta property="og:description" content="Love and Peace"><meta property="og:image" content="/imgs/hugo_next_avatar.png"><meta property="og:image:width" content="312"><meta property="og:image:height" content="312"><meta property="og:image:type" content="image/jpeg/png/svg/jpg"><meta property="og:url" content="/post/%E9%9D%A2%E8%AF%95-%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/"><meta property="og:site_name" content="Tomding's Blog"><meta property="og:locale" content="zh-CN"><meta property="article:author" content="Tomding"><meta property="article:published_time" content="2022-12-01 19:59:47 +0800 CST"><meta property="article:modified_time" content="2022-12-01 19:59:47 +0800 CST"><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/font-awesome/6.1.2/css/all.min.css><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/animate.css/3.1.1/animate.min.css><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/viewerjs/1.11.0/viewer.min.css><link rel=stylesheet href=/css/main.min.0ca97083b39f4eda7430d39b99194aa738d8f8db4090f00bc7e814013df699cb.css><style type=text/css>.post-footer,.flinks-list-footer hr:after{content:"~ 我可是有底线的哟 ~"}</style><script type=text/javascript>(function(){localDB={set:function(e,t,n){if(n===0)return;const s=new Date,o=n*864e5,i={value:t,expiry:s.getTime()+o};localStorage.setItem(e,JSON.stringify(i))},get:function(e){const t=localStorage.getItem(e);if(!t)return void 0;const n=JSON.parse(t),s=new Date;return s.getTime()>n.expiry?(localStorage.removeItem(e),void 0):n.value}},theme={active:function(){const e=localDB.get("theme");if(e==null)return;theme.toggle(e),window.matchMedia("(prefers-color-scheme: dark)").addListener(function(e){theme.toggle(e.matches?"dark":"light")})},toggle:function(e){document.documentElement.setAttribute("data-theme",e),localDB.set("theme",e,2);const t=document.querySelector("iframe.giscus-frame");if(t){const n={setConfig:{theme:e}};t.contentWindow.postMessage({giscus:n},"https://giscus.app")}}},theme.active()})(window)</script><script class=next-config data-name=page type=application/json>{"comments":false,"isHome":false,"isPage":true,"path":"%E9%9D%A2%E8%AF%95-%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88","permalink":"/post/%E9%9D%A2%E8%AF%95-%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/","title":"面试-模型融合","waline":{"js":[{"alias":"waline","alias_name":"@waline/client","file":"dist/pageview.js","name":"pageview","version":"2.13.0"},{"alias":"waline","alias_name":"@waline/client","file":"dist/comment.js","name":"comment","version":"2.13.0"}]}}</script><script type=text/javascript>document.addEventListener("DOMContentLoaded",()=>{var e=document.createElement("script");e.charset="UTF-8",e.src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js",e.async=!1,e.defer=!0,document.head.appendChild(e),e.onload=function(){NexT.utils.fmtBusuanzi()}})</script><title>面试-模型融合 - Tomding's Blog</title><noscript><link rel=stylesheet href=/css/noscript.css></noscript></head><body itemscope itemtype=http://schema.org/WebPage class=use-motion><div class=headband></div><main class=main><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle aria-label=切换导航栏 role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div></div><div class=site-meta><a href=/ class=brand rel=start><i class=logo-line></i><h1 class=site-title>Tomding's Blog</h1><i class=logo-line></i></a><p class=site-subtitle itemprop=description>Just do it!</p></div><div class=site-nav-right><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href=/ class=hvr-icon-pulse rel=section><i class="fa fa-home hvr-icon"></i>首页</a></li><li class="menu-item menu-item-about"><a href=/about.html class=hvr-icon-pulse rel=section><i class="fa fa-user hvr-icon"></i>关于</a></li><li class="menu-item menu-item-archives"><a href=/archives/ class=hvr-icon-pulse rel=section><i class="fa fa-archive hvr-icon"></i>归档
<span class=badge>74</span></a></li><li class="menu-item menu-item-search"><a role=button class="popup-trigger hvr-icon-pulse"><i class="fa fa-search fa-fw hvr-icon"></i>搜索</a></li></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon><i class="fa fa-search"></i></span><div class=search-input-container><input autocomplete=off autocapitalize=off maxlength=80 placeholder=搜索... spellcheck=false type=search class=search-input></div><span class=popup-btn-close role=button><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class=search-result-icon><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></div><div class="toggle sidebar-toggle" role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div><aside class=sidebar><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>文章目录</li><li class=sidebar-nav-overview>站点概览</li></ul><div class=sidebar-panel-container><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><nav id=TableOfContents><ul><li><a href=#回归>回归：</a></li><li><a href=#分类-投票voting>分类： 投票（Voting）</a></li><li><a href=#综合>综合：</a></li></ul><ul><li><a href=#stacking>Stacking</a></li><li><a href=#blending>Blending</a></li></ul></nav></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author site-overview-item animated" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image alt=Tomding src=/imgs/img-lazy-loading.gif data-src=/imgs/hugo_next_avatar.png><p class=site-author-name itemprop=name>Tomding</p><div class=site-description itemprop=description>Love and Peace</div></div><div class="site-state-wrap site-overview-item animated"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/><span class=site-state-item-count>74</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>5</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>0</span>
<span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-social site-overview-item animated"><span class=links-of-social-item><a href=https://github.com/ title="Github → https://github.com/" rel=noopener class=hvr-icon-pulse target=_blank><i class="fab fa-github fa-fw hvr-icon"></i>Github</a></span>
<span class=links-of-social-item><a href=https://www.zhihu.com/hot title="知乎 → https://www.zhihu.com/hot" rel=noopener class=hvr-icon-pulse target=_blank><i class="fa fa-book fa-fw hvr-icon"></i>知乎</a></span></div><div class="cc-license animated" itemprop=license><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh class=cc-opacity rel=noopener target=_blank title=共享知识><img src=/imgs/img-lazy-loading.gif data-src=/imgs/cc/big/by_nc_sa.svg alt=共享知识></a></div><div class="links-of-blogroll site-overview-item animated"><div class=links-of-blogroll-title><i class="fa fa-globe fa-fw"></i>友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://gitee.com/hugo-next/hugo-theme-next title=https://gitee.com/hugo-next/hugo-theme-next target=_blank>Hugo-NexT</a></li><li class=links-of-blogroll-item><a href=https://lisenhui.cn title=https://lisenhui.cn target=_blank>凡梦星尘空间站</a></li></ul></div></div></div></div><div id=siteinfo-card-widget class=sidebar-card-widget><div class=item-headline><i class="fas fa-chart-line"></i>
<span>网站资讯</span></div><div class=siteinfo><div class=siteinfo-item><div class=item-name><i class="fa-solid fa-calendar-check"></i>已运行：</div><div class=item-count id=runTimes data-publishdate=2022-12-01T19:59:47+08:00></div></div><div class=siteinfo-item><div class=item-name><i class="fas fa fa-user"></i>总访客数：</div><div class=item-count id=busuanzi_value_site_uv><i class="fa fa-sync fa-spin"></i></div></div><div class=siteinfo-item><div class=item-name><i class="fas fa fa-eye"></i>页面浏览：</div><div class=item-count id=busuanzi_value_site_pv><i class="fa fa-sync fa-spin"></i></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-font"></i>总字数：</div><div class=item-count id=wordsCount data-count=273427></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-mug-hot"></i>阅读约：</div><div class=item-count id=readTimes data-times=584></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-clock-rotate-left"></i>最后更新于：</div><div class=item-count id=last-push-date data-lastpushdate=2022-12-05T20:43:26+08:00></div></div></div></div></aside><div class=sidebar-dimmer></div></header><div class=tool-buttons><div id=toggle-theme class=button title=深浅模式切换><i class="fas fa-adjust"></i></div><div class=back-to-top role=button title=返回顶部><i class="fa fa-arrow-up"></i>
<span>0%</span></div></div><div class=reading-progress-bar></div><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><div class="main-inner post posts-expand"><div class=post-block><article itemscope itemtype=http://schema.org/Article class=post-content lang><link itemprop=mainEntityOfPage href=/post/%E9%9D%A2%E8%AF%95-%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/><span hidden itemprop=author itemscope itemtype=http://schema.org/Person><meta itemprop=image content="/imgs/hugo_next_avatar.png"><meta itemprop=name content="Tomding"></span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization><meta itemprop=name content="Tomding"><meta itemprop=description content="Love and Peace"></span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork><meta itemprop=name content="面试-模型融合"><meta itemprop=description content="简单加权融合 回归： 算术平均融合（Arithmetic mean） 加权算术平均法 几何平均融合（Geometric mean） 分类： 投票（Votin"></span><header class=post-header><h1 class=post-title itemprop="name headline">面试-模型融合
<a href=https://github.com/user-name/repo-name/tree/branch-name/subdirectory-name/post/%e9%9d%a2%e8%af%95-%e6%a8%a1%e5%9e%8b%e8%9e%8d%e5%90%88.md rel="noopener external nofollow noreferrer" target=_blank class="exturl post-edit-link" title=编辑><i class="fa fa-pen-nib"></i></a></h1><div class=post-meta-container><div class=post-meta-items><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-calendar"></i></span>
<span class=post-meta-item-text>发表于：</span>
<time title="发表于：2022-12-01 19:59:47 +0800 CST" itemprop="dateCreated datePublished" datetime="2022-12-01 19:59:47 +0800 CST">2022-12-01</time></span>
<span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-folder-open"></i></span>
<span class=post-meta-item-text>分类于：</span>
<span itemprop=about itemscope itemtype=http://schema.org/Thing><a href=/categories/%E9%9D%A2%E8%AF%95 itemprop=url rel=index><span itemprop=name>面试</span></a></span></span></div><div class=post-meta-items><span class=post-meta-item title=字数><span class=post-meta-item-icon><i class="far fa-file-word"></i></span>
<span class=post-meta-item-text>字数：</span><span>1400</span></span>
<span class=post-meta-item title=阅读><span class=post-meta-item-icon><i class="far fa-clock"></i></span>
<span class=post-meta-item-text>阅读：&ap;</span>
<span>3分钟</span></span>
<span class=post-meta-item title=浏览><span class=post-meta-item-icon><i class="far fa-eye"></i></span>
<span class=post-meta-item-text>浏览：</span>
<span id=busuanzi_value_page_pv class=waline-pageview-count data-path=/post/%E9%9D%A2%E8%AF%95-%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/><i class="fa fa-sync fa-spin"></i></span></span></div></div></header><div class="post-body autonumber" itemprop=articleBody><h1 id=简单加权融合>简单加权融合</h1><h2 id=回归>回归：</h2><ul><li>算术平均融合（Arithmetic mean）</li><li>加权算术平均法</li><li>几何平均融合（Geometric mean）</li></ul><h2 id=分类-投票voting>分类： 投票（Voting）</h2><ul><li>绝对多数投票法：最终结果必须在投票中占一半以上。</li><li>相对多数投票法：最终结果在投票中票数最多。</li><li>硬投票：对多个模型直接进行投票，不区分模型结果的相对重要度，最终投票数最多的类为最终被预测的类。</li><li>软投票：增加了设置权重的功能，可以<del>为不同模型设置不同权重，进而区别模型不同的重要度。</del></li></ul><h2 id=综合>综合：</h2><ul><li>排序融合（Rank averaging）</li><li>log融合</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>
</span></span><span style=display:flex><span>from sklearn import datasets
</span></span><span style=display:flex><span>from sklearn.ensemble import RandomForestClassifier
</span></span><span style=display:flex><span>from sklearn.ensemble import VotingClassifier
</span></span><span style=display:flex><span>from sklearn.model_selection import train_test_split
</span></span><span style=display:flex><span>from xgboost.sklearn import XGBClassifier
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>iris = datasets.load_iris()
</span></span><span style=display:flex><span>x=iris.data
</span></span><span style=display:flex><span>y=iris.target
</span></span><span style=display:flex><span>x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>clf1 = XGBClassifier(learning_rate=0.1, n_estimators=150, max_depth=3, min_child_weight=2, subsample=0.7,
</span></span><span style=display:flex><span>                     colsample_bytree=0.6, objective=&#39;binary:logistic&#39;)
</span></span><span style=display:flex><span>clf2 = RandomForestClassifier(n_estimators=50, max_depth=1, min_samples_split=4,
</span></span><span style=display:flex><span>                              min_samples_leaf=63, oob_score=True)
</span></span><span style=display:flex><span>clf3 = SVC(C=0.1)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># 硬投票
</span></span><span style=display:flex><span>eclf = VotingClassifier(estimators=[(&#39;xgb&#39;, clf1), (&#39;rf&#39;, clf2), (&#39;svc&#39;, clf3)], 
</span></span><span style=display:flex><span>                        voting=&#39;hard&#39;, n_jobs=-1)
</span></span><span style=display:flex><span># 软
</span></span><span style=display:flex><span># eclf = VotingClassifier(estimators=[(&#39;xgb&#39;, clf1), (&#39;rf&#39;, clf2), (&#39;svc&#39;, clf3)], voting=&#39;soft&#39;, weights=[2, 1, 1])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>for clf, label in zip([clf1, clf2, clf3, eclf], [&#39;XGBBoosting&#39;, &#39;Random Forest&#39;, &#39;SVM&#39;, &#39;Ensemble&#39;]):
</span></span><span style=display:flex><span>    scores = cross_val_score(clf, x, y, cv=5, scoring=&#39;accuracy&#39;)
</span></span><span style=display:flex><span>    print(&#34;Accuracy: %0.2f (+/- %0.2f) [%s]&#34; % (scores.mean(), scores.std(), label))
</span></span></code></pre></div><h1 id=boostingbagging>boosting/bagging</h1><p>（在xgboost，Adaboost，GBDT中已经用到多树的提升方法）</p><h1 id=stackingblending>stacking/blending</h1><h2 id=stacking>Stacking</h2><p>Stacking本质上就是这么直接的思路，但是直接这样有时对于如果训练集和测试集分布不那么一致的情况下是有一点问题的，其问题在于用初始模型训练的标签再利用真实标签进行再训练，毫无疑问会导致一定的模型过拟合训练集，这样或许模型在测试集上的泛化能力或者说效果会有一定的下降，因此现在的问题变成了如何降低再训练的过拟合性，这里我们一般有两种方法。</p><ul><li>次级模型尽量选择简单的线性模型</li><li>利用K折交叉验证</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span># ---------------------------------------Stacking
</span></span><span style=display:flex><span># ___________________________train,val(作为test)
</span></span><span style=display:flex><span>base_models_stacking = [LinearRegression(`parm_lr),
</span></span><span style=display:flex><span>                        SVR(),
</span></span><span style=display:flex><span>                        DecisionTreeRegressor(),
</span></span><span style=display:flex><span>                        RandomForestRegressor(),
</span></span><span style=display:flex><span>                        GradientBoostingRegressor(),
</span></span><span style=display:flex><span>                        BaggingRegressor()]
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>train_pre_stacking = np.zeros((len(x_train_tree), len(base_models_stacking)))
</span></span><span style=display:flex><span>val_pre_stacking = np.zeros((len(x_val_tree), len(base_models_stacking)))
</span></span><span style=display:flex><span># 5折stacking
</span></span><span style=display:flex><span>n_splits = 5
</span></span><span style=display:flex><span>skf = KFold(n_splits=n_splits).split(x_train_tree, y_train_tree)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>for i, model in enumerate(base_models_stacking):
</span></span><span style=display:flex><span>    #依次训练各个单模型
</span></span><span style=display:flex><span>    val_pre_skf = np.zeros((len(x_val_tree), n_splits))
</span></span><span style=display:flex><span>    for j, (train_train_index, train_val_index) in enumerate(skf):
</span></span><span style=display:flex><span>        #5-Fold交叉训练，使用第i个部分作为预测，剩余的部分来训练模型，获得其预测的输出作为第i部分的新特征。
</span></span><span style=display:flex><span>        x_train, y_train = x_train_tree[train_train_index], y_train_tree[train_train_index]
</span></span><span style=display:flex><span>        x_val, y_val = x_train_tree[train_val_index], y_train_tree[train_val_index]
</span></span><span style=display:flex><span>        model.fit(x_train, y_train)
</span></span><span style=display:flex><span>        print(x_train.shape)
</span></span><span style=display:flex><span>        train_pre_stacking[train_val_index, i] = model.predict(x_val)  # 训练集预测结果
</span></span><span style=display:flex><span>        val_pre_skf[:, j] = model.predict(x_val_tree)    # 验证集预测结果i
</span></span><span style=display:flex><span>    val_pre_stacking[:, i] = val_pre_skf.mean()  # 验证集预测结果
</span></span><span style=display:flex><span>    print(&#34;{} MAE Score: {}&#34;.format(str(model).split(&#39;(&#39;)[0], 
</span></span><span style=display:flex><span>                                    mean_absolute_error(y_val_tree, val_pre_stacking[:, i])))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>stack_model = LinearRegression(`parm_lr)
</span></span><span style=display:flex><span>stack_model.fit(train_pre_stacking, y_train_tree)   # (len_train, num_models), len_train
</span></span><span style=display:flex><span>print(&#39;Stacking Model MAE Score: {} &#39;.format(mean_absolute_error(y_val_tree, 
</span></span><span style=display:flex><span>                                                                stack_model.predict(val_pre_stacking))))
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>import warnings
</span></span><span style=display:flex><span>warnings.filterwarnings(&#39;ignore&#39;)
</span></span><span style=display:flex><span>import itertools
</span></span><span style=display:flex><span>import numpy as np
</span></span><span style=display:flex><span>import seaborn as sns
</span></span><span style=display:flex><span>import matplotlib.pyplot as plt
</span></span><span style=display:flex><span>import matplotlib.gridspec as gridspec
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>from sklearn import datasets
</span></span><span style=display:flex><span>from sklearn.linear_model import LogisticRegression
</span></span><span style=display:flex><span>from sklearn.neighbors import KNeighborsClassifier
</span></span><span style=display:flex><span>from sklearn.naive_bayes import GaussianNB 
</span></span><span style=display:flex><span>from sklearn.ensemble import RandomForestClassifier
</span></span><span style=display:flex><span>from mlxtend.classifier import StackingClassifier
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>from sklearn.model_selection import cross_val_score
</span></span><span style=display:flex><span>from mlxtend.plotting import plot_learning_curves
</span></span><span style=display:flex><span>from mlxtend.plotting import plot_decision_regions
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>iris = datasets.load_iris()
</span></span><span style=display:flex><span>X, y = iris.data[:, 1:3], iris.target
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>clf1 = KNeighborsClassifier(n_neighbors=1)
</span></span><span style=display:flex><span>clf2 = RandomForestClassifier(random_state=1)
</span></span><span style=display:flex><span>clf3 = GaussianNB()
</span></span><span style=display:flex><span>lr = LogisticRegression()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], 
</span></span><span style=display:flex><span>                          meta_classifier=lr)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>label = [&#39;KNN&#39;, &#39;Random Forest&#39;, &#39;Naive Bayes&#39;, &#39;Stacking Classifier&#39;]
</span></span><span style=display:flex><span>clf_list = [clf1, clf2, clf3, sclf]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>fig, ax = plt.subplots(2, 2, figsize=(20, 20), dpi=100)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>clf_cv_mean = []
</span></span><span style=display:flex><span>clf_cv_std = []
</span></span><span style=display:flex><span>for i in range(len(clf_list)):
</span></span><span style=display:flex><span>    clf = clf_list[i]
</span></span><span style=display:flex><span>    label = labels[i]
</span></span><span style=display:flex><span>    scores = cross_val_score(clf, X, y, cv=3, scoring=&#39;accuracy&#39;)
</span></span><span style=display:flex><span>    print(&#34;Accuracy: %.2f (+/- %.2f) [%s]&#34; %(scores.mean(), scores.std(), label))
</span></span><span style=display:flex><span>    clf_cv_mean.append(scores.mean())
</span></span><span style=display:flex><span>    clf_cv_std.append(scores.std())  
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    clf.fit(X, y)
</span></span><span style=display:flex><span>    fig = plot_decision_regions(X=X, y=y, clf=clf, ax=ax[i//2, i%2])
</span></span><span style=display:flex><span>    plt.title(label)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt.show()
</span></span></code></pre></div><h2 id=blending>Blending</h2><p>采用了和stacking同样的方法，不过只<code>从训练集中选择一个fold的结果，再和原始特征进行concat作为元学习器meta learner的特征</code>，测试集上进行同样的操作。</p><p>在第一层，70%的数据上训练多个模型，预测30%数据、测试集。
在第二层，用第一层30%数据预测的结果作为训练集继续训练，用第一层预测的测试集结果作为测试集</p><p>其优点在于：</p><ol><li>比stacking简单（因为不用进行k次的交叉验证来获得stacker feature）</li><li>避开了一个信息泄露问题：generlizers和stacker使用了不一样的数据集
缺点在于：</li><li>使用了很少的数据（第二阶段的blender只使用training set10%的量）</li><li>blender可能会过拟合，stacking使用多次的交叉验证会比较稳健</li></ol><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>#------------------------------------blending
</span></span><span style=display:flex><span># ___________________________train, val(作为test)
</span></span><span style=display:flex><span>base_models_blending = [LinearRegression(`parm_lr),
</span></span><span style=display:flex><span>                        SVR(),
</span></span><span style=display:flex><span>                        DecisionTreeRegressor(),
</span></span><span style=display:flex><span>                        RandomForestRegressor(),
</span></span><span style=display:flex><span>                        GradientBoostingRegressor(),
</span></span><span style=display:flex><span>                        BaggingRegressor()]
</span></span><span style=display:flex><span>x_train_70, x_train_30, y_train_70, y_train_30 = train_test_split(x_train_tree, y_train_tree, test_size=0.3, random_state=2020)
</span></span><span style=display:flex><span>train_30_pre_blending = np.zeros((len(x_train_30), len(base_models_blending)))
</span></span><span style=display:flex><span>val_pre_blending = np.zeros((len(x_val_tree), len(base_models_blending)))
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>for i, model in enumerate(base_models_blending):
</span></span><span style=display:flex><span>    #依次训练各个单模型
</span></span><span style=display:flex><span>    model.fit(x_train_70, y_train_70)
</span></span><span style=display:flex><span>    train_30_pre_blending[:, i] = model.predict(x_train_30)
</span></span><span style=display:flex><span>    # 对于测试集，直接用这k个模型的预测值作为新的特征。
</span></span><span style=display:flex><span>    val_pre_blending[:, i] = model.predict(x_val_tree)
</span></span><span style=display:flex><span>    print(&#39;{} MAE Score: {}&#39;.format(str(model).split(&#39;(&#39;)[0], 
</span></span><span style=display:flex><span>                                    mean_absolute_error(y_val_tree, val_pre_blending[:, i])))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>blend_model = GradientBoostingClassifier(learning_rate=0.02, subsample=0.5, max_depth=6, n_estimators=30)
</span></span><span style=display:flex><span>blend_model.fit(train_30_pre_blending, y_train_30)
</span></span><span style=display:flex><span>print(&#39;Blending Model MAE Score: {} &#39;.format(mean_absolute_error(y_val_tree, 
</span></span><span style=display:flex><span>                                                                 blend_model.predict(val_pre_blending))))
</span></span></code></pre></div></div><footer class=post-footer><div class=addthis_inline_share_toolbox style=text-align:center></div><hr><div class=post-copyright><img src=/imgs/cc/cc.svg width=75 height=75 align=right><ul><li class=post-copyright-title><strong>文章标题：</strong>
面试-模型融合</li><li class=post-copyright-author><strong>本文作者：</strong>
Tomding</li><li class=post-copyright-link><strong>本文链接：</strong>
<a id=post-cr-link href=/post/%E9%9D%A2%E8%AF%95-%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/ title=面试-模型融合>/post/%E9%9D%A2%E8%AF%95-%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/</a></li><li class=post-copyright-license><strong>版权声明：</strong>
本博客所有文章除特别声明外，均采用 <i class="fab fa-fw fa-creative-commons"></i><a target=_blank href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class=followme><span>欢迎关注我的其它发布渠道</span><div class=social-list><div class=social-item><a target=_blank class=social-link href=/images/wechat_channel.jpg><span class=icon><i class="fab fa-weixin"></i></span>
<span class=label>WeChat</span></a></div><div class=social-item><a target=_blank class=social-link href=/atom.xml><span class=icon><i class="fa fa-rss"></i></span>
<span class=label>RSS</span></a></div></div></div><div class=post-nav><div class="post-nav-next post-nav-item"><a href=/post/%E9%9D%A2%E8%AF%95-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/ rel=next title=面试-模型评估指标><i class="fa fa-chevron-left"></i> 面试-模型评估指标</a></div><div class="post-nav-prev post-nav-item"><a href=/post/%E9%9D%A2%E8%AF%95-%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/ rel=prev title=面试-排序算法>面试-排序算法
<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div></main><footer class=footer><div class=footer-inner><div class=copyright>&copy;
<span itemprop=copyrightYear>2010 - 2022</span>
<span class=with-love><i class="fa fa-heart"></i></span>
<span class=author itemprop=copyrightHolder>Tomding</span></div></div></footer><script type=text/javascript src=https://cdn.staticfile.org/animejs/3.2.1/anime.min.js defer></script>
<script type=text/javascript src=https://cdn.staticfile.org/viewerjs/1.11.0/viewer.min.js defer></script>
<script class=next-config data-name=main type=application/json>{"bookmark":{"color":"#222","enable":false,"save":"manual"},"busuanzi":{"pageview":true},"copybtn":true,"darkmode":true,"giscus":{"cfg":{"category":"Comments","categoryid":null,"emit":false,"inputposition":"top","mapping":"title","reactions":false,"repo":"username/repo-name","repoid":null,"theme":"preferred_color_scheme"},"js":"https://giscus.app/client.js"},"hostname":"/","i18n":{"ds_day":" 天前","ds_days":" 天 ","ds_hour":" 小时前","ds_hours":" 小时 ","ds_just":"刚刚","ds_min":" 分钟前","ds_mins":" 分钟","ds_month":" 个月前","ds_years":" 年 ","empty":"没有找到任何搜索结果：${query}","hits":"","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","placeholder":"搜索..."},"lang":"zh-CN","lazyload":false,"localSearch":{"enable":true,"path":"/searchindexes.xml","preload":false,"topnperarticle":-1,"trigger":"auto","unescape":false},"motion":{"async":true,"enable":true,"transition":{"collheader":"fadeInLeft","postblock":"fadeIn","postbody":"fadeInDown","postheader":"fadeInDown","sidebar":"fadeInUp"}},"root":"/","scheme":"Gemini","sidebar":{"display":"post","offset":12,"padding":18,"position":"left","width":256},"statis":{"enable":true,"plugin":"busuanzi"},"vendor":{"plugins":"qiniu","router":"https://cdn.staticfile.org"},"version":"4.4.1","waline":{"cfg":{"comment":true,"emoji":false,"imguploader":false,"pageview":true,"placeholder":"请文明发言哟 ヾ(≧▽≦*)o","reaction":true,"reactiontext":["点赞","踩一下","得意","不屑","尴尬","睡觉"],"reactiontitle":"你认为这篇文章怎么样？","requiredmeta":["nick","mail"],"serverurl":null,"sofa":"快来发表你的意见吧 (≧∀≦)ゞ","wordlimit":200},"css":{"alias":"waline","file":"dist/waline.css","name":"@waline/client","version":"2.13.0"},"js":{"alias":"waline","file":"dist/waline.js","name":"@waline/client","version":"2.13.0"}}}</script><script type=text/javascript src=/js/main.min.e34208af37d3db3a875e6fbad04c2f1c241185af925a9c6ebf79dd1ba2730cdd.js defer></script></body></html>