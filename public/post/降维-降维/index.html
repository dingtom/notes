<!doctype html><html lang=zh-cn data-theme=dark><head><meta charset=utf-8><meta name=viewport content="width=device-width"><meta name=theme-color content="#222" media="(prefers-color-scheme: dark)"><meta name=generator content="Hugo 0.107.0"><link rel="shortcut icon" type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=/imgs/icons/favicon_16x16_next.png><link rel=icon type=image/png sizes=32x32 href=/imgs/icons/favicon_32_32_next.png><link rel=apple-touch-icon sizes=180x180 href=/imgs/icons/apple_touch_icon_next.png><meta itemprop=name content="降维-降维"><meta itemprop=description content="Love and Peace"><meta itemprop=datePublished zgotmplz><meta itemprop=dateModified zgotmplz><meta itemprop=image content="/imgs/hugo_next_avatar.png"><meta itemprop=keywords content="Hugo,NexT,主题,简单,强大"><meta property="og:type" content="article"><meta property="og:title" content="降维-降维"><meta property="og:description" content="Love and Peace"><meta property="og:image" content="/imgs/hugo_next_avatar.png"><meta property="og:image:width" content="312"><meta property="og:image:height" content="312"><meta property="og:image:type" content="image/jpeg/png/svg/jpg"><meta property="og:url" content="/post/%E9%99%8D%E7%BB%B4-%E9%99%8D%E7%BB%B4/"><meta property="og:site_name" content="Tomding's Blog"><meta property="og:locale" content="zh-CN"><meta property="article:author" content="Tomding"><meta property="article:published_time" content="2023-01-01 14:28:53 +0800 CST"><meta property="article:modified_time" content="2023-01-01 14:28:53 +0800 CST"><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/font-awesome/6.1.2/css/all.min.css><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/animate.css/3.1.1/animate.min.css><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/viewerjs/1.11.0/viewer.min.css><link rel=stylesheet href=/css/main.min.0ca97083b39f4eda7430d39b99194aa738d8f8db4090f00bc7e814013df699cb.css><style type=text/css>.post-footer,.flinks-list-footer hr:after{content:"~ 我可是有底线的哟 ~"}</style><script type=text/javascript>(function(){localDB={set:function(e,t,n){if(n===0)return;const s=new Date,o=n*864e5,i={value:t,expiry:s.getTime()+o};localStorage.setItem(e,JSON.stringify(i))},get:function(e){const t=localStorage.getItem(e);if(!t)return void 0;const n=JSON.parse(t),s=new Date;return s.getTime()>n.expiry?(localStorage.removeItem(e),void 0):n.value}},theme={active:function(){const e=localDB.get("theme");if(e==null)return;theme.toggle(e),window.matchMedia("(prefers-color-scheme: dark)").addListener(function(e){theme.toggle(e.matches?"dark":"light")})},toggle:function(e){document.documentElement.setAttribute("data-theme",e),localDB.set("theme",e,2);const t=document.querySelector("iframe.giscus-frame");if(t){const n={setConfig:{theme:e}};t.contentWindow.postMessage({giscus:n},"https://giscus.app")}}},theme.active()})(window)</script><script class=next-config data-name=page type=application/json>{"comments":false,"isHome":false,"isPage":true,"path":"%E9%99%8D%E7%BB%B4-%E9%99%8D%E7%BB%B4","permalink":"/post/%E9%99%8D%E7%BB%B4-%E9%99%8D%E7%BB%B4/","title":"降维-降维","waline":{"js":[{"alias":"waline","alias_name":"@waline/client","file":"dist/pageview.js","name":"pageview","version":"2.13.0"},{"alias":"waline","alias_name":"@waline/client","file":"dist/comment.js","name":"comment","version":"2.13.0"}]}}</script><script type=text/javascript>document.addEventListener("DOMContentLoaded",()=>{var e=document.createElement("script");e.charset="UTF-8",e.src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js",e.async=!1,e.defer=!0,document.head.appendChild(e),e.onload=function(){NexT.utils.fmtBusuanzi()}})</script><title>降维-降维 - Tomding's Blog</title><noscript><link rel=stylesheet href=/css/noscript.css></noscript></head><body itemscope itemtype=http://schema.org/WebPage class=use-motion><div class=headband></div><main class=main><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle aria-label=切换导航栏 role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div></div><div class=site-meta><a href=/ class=brand rel=start><i class=logo-line></i><h1 class=site-title>Tomding's Blog</h1><i class=logo-line></i></a><p class=site-subtitle itemprop=description>Just do it!</p></div><div class=site-nav-right><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href=/ class=hvr-icon-pulse rel=section><i class="fa fa-home hvr-icon"></i>首页</a></li><li class="menu-item menu-item-about"><a href=/about.html class=hvr-icon-pulse rel=section><i class="fa fa-user hvr-icon"></i>关于</a></li><li class="menu-item menu-item-archives"><a href=/archives/ class=hvr-icon-pulse rel=section><i class="fa fa-archive hvr-icon"></i>归档
<span class=badge>126</span></a></li><li class="menu-item menu-item-search"><a role=button class="popup-trigger hvr-icon-pulse"><i class="fa fa-search fa-fw hvr-icon"></i>搜索</a></li></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon><i class="fa fa-search"></i></span><div class=search-input-container><input autocomplete=off autocapitalize=off maxlength=80 placeholder=搜索... spellcheck=false type=search class=search-input></div><span class=popup-btn-close role=button><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class=search-result-icon><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></div><div class="toggle sidebar-toggle" role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div><aside class=sidebar><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>文章目录</li><li class=sidebar-nav-overview>站点概览</li></ul><div class=sidebar-panel-container><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><nav id=TableOfContents><ul><li><ul><li><ul><li></li><li><a href=#随机映射>随机映射</a></li><li><a href=#pca>PCA</a></li><li><a href=#lda>LDA</a></li><li><a href=#isomap>Isomap</a></li><li><a href=#standard-lle>standard LLE</a></li><li><a href=#modified-lle>modified LLE</a></li><li><a href=#hlle>HLLE</a></li><li><a href=#ltsa>LTSA</a></li><li><a href=#mds>MDS</a></li><li><a href=#random-trees>Random Trees</a></li><li><a href=#spectral>Spectral</a></li><li><a href=#t-sne>t-SNE</a></li></ul></li></ul></li></ul></nav></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author site-overview-item animated" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image alt=Tomding src=/imgs/img-lazy-loading.gif data-src=/imgs/hugo_next_avatar.png><p class=site-author-name itemprop=name>Tomding</p><div class=site-description itemprop=description>Love and Peace</div></div><div class="site-state-wrap site-overview-item animated"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/><span class=site-state-item-count>126</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>10</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>0</span>
<span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-social site-overview-item animated"><span class=links-of-social-item><a href=https://github.com/ title="Github → https://github.com/" rel=noopener class=hvr-icon-pulse target=_blank><i class="fab fa-github fa-fw hvr-icon"></i>Github</a></span>
<span class=links-of-social-item><a href=https://www.zhihu.com/hot title="知乎 → https://www.zhihu.com/hot" rel=noopener class=hvr-icon-pulse target=_blank><i class="fa fa-book fa-fw hvr-icon"></i>知乎</a></span></div><div class="cc-license animated" itemprop=license><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh class=cc-opacity rel=noopener target=_blank title=共享知识><img src=/imgs/img-lazy-loading.gif data-src=/imgs/cc/big/by_nc_sa.svg alt=共享知识></a></div><div class="links-of-blogroll site-overview-item animated"><div class=links-of-blogroll-title><i class="fa fa-globe fa-fw"></i>友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://gitee.com/hugo-next/hugo-theme-next title=https://gitee.com/hugo-next/hugo-theme-next target=_blank>Hugo-NexT</a></li><li class=links-of-blogroll-item><a href=https://lisenhui.cn title=https://lisenhui.cn target=_blank>凡梦星尘空间站</a></li></ul></div></div></div></div><div id=siteinfo-card-widget class=sidebar-card-widget><div class=item-headline><i class="fas fa-chart-line"></i>
<span>网站资讯</span></div><div class=siteinfo><div class=siteinfo-item><div class=item-name><i class="fa-solid fa-calendar-check"></i>已运行：</div><div class=item-count id=runTimes data-publishdate=2022-12-01T19:59:47+08:00></div></div><div class=siteinfo-item><div class=item-name><i class="fas fa fa-user"></i>总访客数：</div><div class=item-count id=busuanzi_value_site_uv><i class="fa fa-sync fa-spin"></i></div></div><div class=siteinfo-item><div class=item-name><i class="fas fa fa-eye"></i>页面浏览：</div><div class=item-count id=busuanzi_value_site_pv><i class="fa fa-sync fa-spin"></i></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-font"></i>总字数：</div><div class=item-count id=wordsCount data-count=446699></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-mug-hot"></i>阅读约：</div><div class=item-count id=readTimes data-times=958></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-clock-rotate-left"></i>最后更新于：</div><div class=item-count id=last-push-date data-lastpushdate=2023-01-01T14:28:53+08:00></div></div></div></div></aside><div class=sidebar-dimmer></div></header><div class=tool-buttons><div id=toggle-theme class=button title=深浅模式切换><i class="fas fa-adjust"></i></div><div class=back-to-top role=button title=返回顶部><i class="fa fa-arrow-up"></i>
<span>0%</span></div></div><div class=reading-progress-bar></div><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><div class="main-inner post posts-expand"><div class=post-block><article itemscope itemtype=http://schema.org/Article class=post-content lang><link itemprop=mainEntityOfPage href=/post/%E9%99%8D%E7%BB%B4-%E9%99%8D%E7%BB%B4/><span hidden itemprop=author itemscope itemtype=http://schema.org/Person><meta itemprop=image content="/imgs/hugo_next_avatar.png"><meta itemprop=name content="Tomding"></span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization><meta itemprop=name content="Tomding"><meta itemprop=description content="Love and Peace"></span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork><meta itemprop=name content="降维-降维"><meta itemprop=description content="1. 主成分分析（线性） 2. t-SNE（非参数/非线性） 3.萨蒙映射（非线性） 4.等距映射（非线性） 5.局部线性嵌入(非线性) 6.规范相关分析（非"></span><header class=post-header><h1 class=post-title itemprop="name headline">降维-降维
<a href=https://github.com/user-name/repo-name/tree/branch-name/subdirectory-name/post/%e9%99%8d%e7%bb%b4-%e9%99%8d%e7%bb%b4.md rel="noopener external nofollow noreferrer" target=_blank class="exturl post-edit-link" title=编辑><i class="fa fa-pen-nib"></i></a></h1><div class=post-meta-container><div class=post-meta-items><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-calendar"></i></span>
<span class=post-meta-item-text>发表于：</span>
<time title="发表于：2023-01-01 14:28:53 +0800 CST" itemprop="dateCreated datePublished" datetime="2023-01-01 14:28:53 +0800 CST">2023-01-01</time></span>
<span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-folder-open"></i></span>
<span class=post-meta-item-text>分类于：</span>
<span itemprop=about itemscope itemtype=http://schema.org/Thing><a href=/categories/%E9%99%8D%E7%BB%B4 itemprop=url rel=index><span itemprop=name>降维</span></a></span></span></div><div class=post-meta-items><span class=post-meta-item title=字数><span class=post-meta-item-icon><i class="far fa-file-word"></i></span>
<span class=post-meta-item-text>字数：</span><span>2110</span></span>
<span class=post-meta-item title=阅读><span class=post-meta-item-icon><i class="far fa-clock"></i></span>
<span class=post-meta-item-text>阅读：&ap;</span>
<span>5分钟</span></span>
<span class=post-meta-item title=浏览><span class=post-meta-item-icon><i class="far fa-eye"></i></span>
<span class=post-meta-item-text>浏览：</span>
<span id=busuanzi_value_page_pv class=waline-pageview-count data-path=/post/%E9%99%8D%E7%BB%B4-%E9%99%8D%E7%BB%B4/><i class="fa fa-sync fa-spin"></i></span></span></div></div></header><div class="post-body autonumber" itemprop=articleBody><p>1.
<a href=https://www.jianshu.com/writer#/notebooks/39383212/notes/63867607/preview title=主成分分析（线性） rel="noopener external nofollow noreferrer" target=_blank class=exturl>主成分分析（线性）
<i class="fa fa-external-link-alt"></i></a>
2.
<a href=https://www.jianshu.com/writer#/notebooks/39383212/notes/66858400 title=t-SNE（非参数/非线性） rel="noopener external nofollow noreferrer" target=_blank class=exturl>t-SNE（非参数/非线性）
<i class="fa fa-external-link-alt"></i></a></p><p>3.萨蒙映射（非线性）
4.等距映射（非线性）
5.局部线性嵌入(非线性)
6.规范相关分析（非线性）
7.SNE(非线性)
8.最小方差无偏估计（非线性）
9.拉普拉斯特征图（非线性）</p><p>线性降维算法的一个主要问题是它们集中将不相似的数据点放置在较低维度区域时，数据点相距甚远。 但是为了在低维、非线性流型上表示高维数据，我们也需要把相似的数据点靠近在一起展示，这并不是线性降维算法所能做的。</p><p>局部方法寻求将流型上的附近点映射到低维表示中的附近点。</p><p>全局方法试图保留所有尺度的几何形状，即将附近的点映射到附近的点，将远处的点映射到远处的点</p><p><strong>除t-SNE之外的大多数非线性技术都不能同时保留数据的局部和全局结构。</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>from time import time
</span></span><span style=display:flex><span>import numpy as np
</span></span><span style=display:flex><span>import matplotlib.pyplot as plt
</span></span><span style=display:flex><span>from mpl_toolkits.mplot3d.axes3d import Axes3D
</span></span><span style=display:flex><span>from sklearn import manifold, datasets, decomposition, ensemble, random_projection
</span></span><span style=display:flex><span>from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as lda
</span></span></code></pre></div><h6 id=加载数据显示数据>加载数据，显示数据</h6><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>digits = datasets.load_digits(n_class=5)  # 只加载0-4
</span></span><span style=display:flex><span>X = digits.data
</span></span><span style=display:flex><span>y = digits.target
</span></span><span style=display:flex><span>(901, 64) (901,)
</span></span><span style=display:flex><span>n_img_per_row = 20
</span></span><span style=display:flex><span>img = np.zeros((10 * n_img_per_row, 10 * n_img_per_row))
</span></span><span style=display:flex><span>for i in range(n_img_per_row):
</span></span><span style=display:flex><span>    ix = 10 * i + 1
</span></span><span style=display:flex><span>    for j in range(n_img_per_row):
</span></span><span style=display:flex><span>        iy = 10 * j + 1
</span></span><span style=display:flex><span>        img[ix:ix + 8, iy:iy + 8] = X[i * n_img_per_row + j].reshape((8, 8))
</span></span><span style=display:flex><span>plt.imshow(img, cmap=plt.cm.binary)
</span></span><span style=display:flex><span>plt.title(&#39;A selection from the 64-dimensional digits dataset&#39;)
</span></span></code></pre></div><p><img src=/imgs/img-lazy-loading.gif data-src=https://upload-images.jianshu.io/upload_images/18339009-7534ae6cd87e4b87.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 alt></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span># LLE,Isomap,LTSA需要设置n_neighbors这个参数
</span></span><span style=display:flex><span>n_neighbors = 30
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># 将降维后的数据可视化,2维
</span></span><span style=display:flex><span>def plot_embedding_2d(X, title=None):
</span></span><span style=display:flex><span>    #坐标缩放到[0,1]区间
</span></span><span style=display:flex><span>    x_min, x_max = np.min(X,axis=0), np.max(X,axis=0)
</span></span><span style=display:flex><span>    X = (X - x_min) / (x_max - x_min)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    #降维后的坐标为（X[i, 0], X[i, 1]），在该位置画出对应的digits
</span></span><span style=display:flex><span>    fig = plt.figure()
</span></span><span style=display:flex><span>    ax = fig.add_subplot(1, 1, 1)
</span></span><span style=display:flex><span>    for i in range(X.shape[0]):
</span></span><span style=display:flex><span>        ax.text(X[i, 0], X[i, 1],str(digits.target[i]),
</span></span><span style=display:flex><span>                 color=plt.cm.Set1(y[i] / 10.),
</span></span><span style=display:flex><span>                 fontdict={&#39;weight&#39;: &#39;bold&#39;, &#39;size&#39;: 9})
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    if title is not None:
</span></span><span style=display:flex><span>        plt.title(title)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>#将降维后的数据可视化,3维
</span></span><span style=display:flex><span>def plot_embedding_3d(X, title=None):
</span></span><span style=display:flex><span>    #坐标缩放到[0,1]区间
</span></span><span style=display:flex><span>    x_min, x_max = np.min(X,axis=0), np.max(X,axis=0)
</span></span><span style=display:flex><span>    X = (X - x_min) / (x_max - x_min)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    #降维后的坐标为（X[i, 0], X[i, 1],X[i,2]），在该位置画出对应的digits
</span></span><span style=display:flex><span>    fig = plt.figure()
</span></span><span style=display:flex><span>    ax = fig.add_subplot(1, 1, 1, projection=&#39;3d&#39;)
</span></span><span style=display:flex><span>    for i in range(X.shape[0]):
</span></span><span style=display:flex><span>        ax.text(X[i, 0], X[i, 1], X[i,2],str(digits.target[i]),
</span></span><span style=display:flex><span>                 color=plt.cm.Set1(y[i] / 10.),
</span></span><span style=display:flex><span>                 fontdict={&#39;weight&#39;: &#39;bold&#39;, &#39;size&#39;: 9})
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    if title is not None:
</span></span><span style=display:flex><span>        plt.title(title)
</span></span></code></pre></div><h4 id=随机映射>随机映射</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>print(&#34;Computing random projection&#34;)
</span></span><span style=display:flex><span>rp = random_projection.SparseRandomProjection(n_components=2, random_state=42)  # n_components降到几维
</span></span><span style=display:flex><span>X_projected = rp.fit_transform(X)
</span></span><span style=display:flex><span>print(X_projected.shape)
</span></span><span style=display:flex><span>plot_embedding_2d(X_projected, &#34;Random Projection&#34;)
</span></span><span style=display:flex><span>plt.show()
</span></span></code></pre></div><p><img src=/imgs/img-lazy-loading.gif data-src=https://upload-images.jianshu.io/upload_images/18339009-8ad2c178ba9e6498.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 alt></p><h4 id=pca>PCA</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>t0 = time()
</span></span><span style=display:flex><span>X_pca = decomposition.TruncatedSVD(n_components=3).fit_transform(X)
</span></span><span style=display:flex><span>print(X_pca.shape)
</span></span><span style=display:flex><span>plot_embedding_2d(X_pca[:,0:2],&#34;PCA 2D&#34;)
</span></span><span style=display:flex><span>plot_embedding_3d(X_pca,&#34;PCA 3D (time %.2fs)&#34; %(time() - t0))
</span></span><span style=display:flex><span>plt.show()
</span></span></code></pre></div><p><img src=/imgs/img-lazy-loading.gif data-src=https://upload-images.jianshu.io/upload_images/18339009-cef6dd020967f8d5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 alt>
<img src=/imgs/img-lazy-loading.gif data-src=https://upload-images.jianshu.io/upload_images/18339009-8622eea35f4ae676.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 alt></p><h4 id=lda>LDA</h4><blockquote><p>LDA是一种监督学习的降维技术，也就是说它的数据集的每个样本是有类别输出的。
这点和PCA不同。PCA是不考虑样本类别输出的无监督降维技术。LDA的思想可以用一句话概括，就是“投影后类内方差最小，类间方差最大”。</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>X2 = X.copy()
</span></span><span style=display:flex><span>X2.flat[::X.shape[1] + 1] += 0.01  # Make X invertible
</span></span><span style=display:flex><span>t0 = time()
</span></span><span style=display:flex><span>X_lda = lda(n_components=3).fit_transform(X2, y)
</span></span><span style=display:flex><span>plot_embedding_2d(X_lda[:,0:2],&#34;LDA 2D&#34; )
</span></span><span style=display:flex><span>plot_embedding_3d(X_lda,&#34;LDA 3D (time %.2fs)&#34; %(time() - t0))
</span></span><span style=display:flex><span>plt.show()
</span></span></code></pre></div><p><img src=/imgs/img-lazy-loading.gif data-src=https://upload-images.jianshu.io/upload_images/18339009-bfdf8188d45e19fc.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 alt>
<img src=/imgs/img-lazy-loading.gif data-src=https://upload-images.jianshu.io/upload_images/18339009-6ea03a4d911e82a2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 alt></p><h4 id=isomap>Isomap</h4><blockquote><p>流形学习的最早方法之一是 Isomap 算法，等距映射（Isometric Mapping）的缩写。
Isomap 可以被视为多维缩放（Multi-dimensional Scaling：MDS）或核主成分分析（Kernel PCA）的扩展。
Isomap 寻求一个较低维度的嵌入( 译注：嵌入(embedding)，在此处，可以理解为高维数据到低维数据的一种映射转换，数据间的固有结构不变化 )，
它保持了所有点之间的原有的测地距离( 译注:测地距离（geodesic distance）是指在图中连接某两个顶点的最短距离(shortest path) )。
<a href=https://sklearn.apachecn.org/docs/0.21.3/21.html title=https://sklearn.apachecn.org/docs/0.21.3/21.html rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://sklearn.apachecn.org/docs/0.21.3/21.html
<i class="fa fa-external-link-alt"></i></a></p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>t0 = time()
</span></span><span style=display:flex><span>X_iso = manifold.Isomap(n_neighbors, n_components=2).fit_transform(X)
</span></span><span style=display:flex><span>plot_embedding_2d(X_iso,&#34;Isomap (time %.2fs)&#34; %(time() - t0))
</span></span><span style=display:flex><span>plt.show()
</span></span></code></pre></div><p><img src=/imgs/img-lazy-loading.gif data-src=https://upload-images.jianshu.io/upload_images/18339009-022293a062500a37.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 alt></p><h4 id=standard-lle>standard LLE</h4><blockquote><p>局部线性嵌入（LLE）通过保留局部邻域内的距离来寻求数据的低维投影。
它可以被认为是一系列的局部主成分分析在全局范围内的相互比较，找到最优的局部非线性嵌入。</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>clf = manifold.LocallyLinearEmbedding(n_neighbors, n_components=2,method=&#39;standard&#39;)
</span></span><span style=display:flex><span>t0 = time()
</span></span><span style=display:flex><span>X_lle = clf.fit_transform(X)
</span></span><span style=display:flex><span>print(&#34;Done. Reconstruction error: %g&#34; % clf.reconstruction_error_)
</span></span><span style=display:flex><span>plot_embedding_2d(X_lle,&#34;Locally Linear Embedding (time %.2fs)&#34; %(time() - t0))
</span></span><span style=display:flex><span>plt.show()
</span></span></code></pre></div><p><img src=/imgs/img-lazy-loading.gif data-src=https://upload-images.jianshu.io/upload_images/18339009-0fe233ed15881df6.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 alt></p><h4 id=modified-lle>modified LLE</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>clf = manifold.LocallyLinearEmbedding(n_neighbors, n_components=2,method=&#39;modified&#39;)
</span></span><span style=display:flex><span>t0 = time()
</span></span><span style=display:flex><span>X_mlle = clf.fit_transform(X)
</span></span><span style=display:flex><span>print(&#34;Done. Reconstruction error: %g&#34; % clf.reconstruction_error_)
</span></span><span style=display:flex><span>plot_embedding_2d(X_mlle,&#34;Modified Locally Linear Embedding (time %.2fs)&#34; %(time() - t0))
</span></span><span style=display:flex><span>plt.show()
</span></span></code></pre></div><p><img src=/imgs/img-lazy-loading.gif data-src=https://upload-images.jianshu.io/upload_images/18339009-9cb53355d27ba39a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 alt></p><h4 id=hlle>HLLE</h4><blockquote><p>黑塞特征映射 (也称作基于黑塞的 LLE: HLLE ）是解决 LLE 正则化问题的另一种方法。
在每个用于恢复局部线性结构的邻域内，它会围绕一个基于黑塞的二次型展开。虽然其它的实现表明它对数据大小进行缩放的能力较差，
但是 sklearn 实现了一些算法改进，使得在输出低维度时它的损耗可与其他 LLE 变体相媲美。</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>clf = manifold.LocallyLinearEmbedding(n_neighbors, n_components=2,method=&#39;hessian&#39;)
</span></span><span style=display:flex><span>t0 = time()
</span></span><span style=display:flex><span>X_hlle = clf.fit_transform(X)
</span></span><span style=display:flex><span>print(&#34;Done. Reconstruction error: %g&#34; % clf.reconstruction_error_)
</span></span><span style=display:flex><span>plot_embedding_2d(X_hlle,&#34;Hessian Locally Linear Embedding (time %.2fs)&#34; %(time() - t0))
</span></span><span style=display:flex><span>plt.show()
</span></span></code></pre></div><p><img src=/imgs/img-lazy-loading.gif data-src=https://upload-images.jianshu.io/upload_images/18339009-14b146408d7e8493.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 alt></p><h4 id=ltsa>LTSA</h4><blockquote><p>尽管，严格意义上来说，局部切空间对齐(LTSA) 并不是LLE的变体，
但是，从算法角度来说，它们俩又是足够接近的，所以把它放在该目录下。
与 LLE 算法关注于保持临点距离不同，LTSA 寻求通过切空间来描述局部几何形状，
并（通过）实现全局最优化来对其这些局部切空间，从而得知对应的嵌入。</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>clf = manifold.LocallyLinearEmbedding(n_neighbors, n_components=2,method=&#39;ltsa&#39;)
</span></span><span style=display:flex><span>t0 = time()
</span></span><span style=display:flex><span>X_ltsa = clf.fit_transform(X)
</span></span><span style=display:flex><span>print(&#34;Done. Reconstruction error: %g&#34; % clf.reconstruction_error_)
</span></span><span style=display:flex><span>plot_embedding_2d(X_ltsa,&#34;Local Tangent Space Alignment (time %.2fs)&#34; %(time() - t0))
</span></span><span style=display:flex><span>plt.show()
</span></span></code></pre></div><p><img src=/imgs/img-lazy-loading.gif data-src=https://upload-images.jianshu.io/upload_images/18339009-c1f4e5c7be3fd693.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 alt></p><h4 id=mds>MDS</h4><blockquote><p>寻求数据的低维表示，而这些低维数据间的距离保持了它们在初始高维空间中的距离。
一般来说，（MDS）是一种用来分析在几何空间距离相似或相异数据的技术。
MDS 尝试在几何空间上将相似或相异的数据进行建模。这些数据可以是物体间的相似等级，也可是分子的作用频率，还可以是国家简单贸易指数。
MDS算法有2类：度量和非度量。在 scikit-learn 中， MDS 类具有上述两者的实现。
在度量 MDS 中，输入相似度矩阵源自度量(并因此遵从三角形不等式)，输出两点之间的距离被设置为尽可能接近相似度或相异度的数据。
在非度量版本中，算法尝试保持距离的控制，并因此寻找在所嵌入空间中的距离和相似/相异之间的单调关系。</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>clf = manifold.MDS(n_components=2, n_init=1, max_iter=100)
</span></span><span style=display:flex><span>t0 = time()
</span></span><span style=display:flex><span>X_mds = clf.fit_transform(X)
</span></span><span style=display:flex><span>print(&#34;Done. Stress: %f&#34; % clf.stress_)
</span></span><span style=display:flex><span>plot_embedding_2d(X_mds,&#34;MDS (time %.2fs)&#34; %(time() - t0))
</span></span><span style=display:flex><span>plt.show()
</span></span></code></pre></div><p><img src=/imgs/img-lazy-loading.gif data-src=https://upload-images.jianshu.io/upload_images/18339009-71da454c5152fa17.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 alt></p><h4 id=random-trees>Random Trees</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>hasher = ensemble.RandomTreesEmbedding(n_estimators=200, random_state=0,max_depth=5)
</span></span><span style=display:flex><span>t0 = time()
</span></span><span style=display:flex><span>X_transformed = hasher.fit_transform(X)
</span></span><span style=display:flex><span>pca = decomposition.TruncatedSVD(n_components=2)
</span></span><span style=display:flex><span>X_reduced = pca.fit_transform(X_transformed)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plot_embedding_2d(X_reduced,&#34;Random Trees (time %.2fs)&#34; %(time() - t0))
</span></span><span style=display:flex><span>plt.show()
</span></span></code></pre></div><p><img src=/imgs/img-lazy-loading.gif data-src=https://upload-images.jianshu.io/upload_images/18339009-d903e3856df0aeec.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 alt></p><h4 id=spectral>Spectral</h4><blockquote><p>谱嵌入是计算非线性嵌入的一种方法。scikit-learn 执行拉普拉斯特征映射，该映射是用图拉普拉斯的谱分解的方法把数据进行低维表达。
这个生成的图可认为是低维流形在高维空间里的离散近似值。基于图的代价函数最小化确保了流形上彼此临近的点被映射后在低维空间也彼此临近，
低维空间保持了局部距离。</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>embedder = manifold.SpectralEmbedding(n_components=2, random_state=0,eigen_solver=&#34;arpack&#34;)
</span></span><span style=display:flex><span>t0 = time()
</span></span><span style=display:flex><span>X_se = embedder.fit_transform(X)
</span></span><span style=display:flex><span>plot_embedding_2d(X_se,&#34;Spectral (time %.2fs)&#34; %(time() - t0))
</span></span><span style=display:flex><span>plt.show()
</span></span></code></pre></div><p><img src=/imgs/img-lazy-loading.gif data-src=https://upload-images.jianshu.io/upload_images/18339009-02e77bac0b38492c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 alt></p><h4 id=t-sne>t-SNE</h4><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>tsne = manifold.TSNE(n_components=3, init=&#39;pca&#39;, random_state=0)
</span></span><span style=display:flex><span>t0 = time()
</span></span><span style=display:flex><span>X_tsne = tsne.fit_transform(X)
</span></span><span style=display:flex><span>print(X_tsne.shape)
</span></span><span style=display:flex><span>plot_embedding_2d(X_tsne[:,0:2],&#34;t-SNE 2D&#34;)
</span></span><span style=display:flex><span>plot_embedding_3d(X_tsne,&#34;t-SNE 3D (time %.2fs)&#34; %(time() - t0))
</span></span><span style=display:flex><span>plt.show()
</span></span></code></pre></div><p><img src=/imgs/img-lazy-loading.gif data-src=https://upload-images.jianshu.io/upload_images/18339009-e863bdfd142741e2.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 alt>
<img src=/imgs/img-lazy-loading.gif data-src=https://upload-images.jianshu.io/upload_images/18339009-59dbf9c800d2b56c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 alt></p></div><footer class=post-footer><div class=addthis_inline_share_toolbox style=text-align:center></div><hr><div class=post-copyright><img src=/imgs/cc/cc.svg width=75 height=75 align=right><ul><li class=post-copyright-title><strong>文章标题：</strong>
降维-降维</li><li class=post-copyright-author><strong>本文作者：</strong>
Tomding</li><li class=post-copyright-link><strong>本文链接：</strong>
<a id=post-cr-link href=/post/%E9%99%8D%E7%BB%B4-%E9%99%8D%E7%BB%B4/ title=降维-降维>/post/%E9%99%8D%E7%BB%B4-%E9%99%8D%E7%BB%B4/</a></li><li class=post-copyright-license><strong>版权声明：</strong>
本博客所有文章除特别声明外，均采用 <i class="fab fa-fw fa-creative-commons"></i><a target=_blank href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class=followme><span>欢迎关注我的其它发布渠道</span><div class=social-list><div class=social-item><a target=_blank class=social-link href=/images/wechat_channel.jpg><span class=icon><i class="fab fa-weixin"></i></span>
<span class=label>WeChat</span></a></div><div class=social-item><a target=_blank class=social-link href=/atom.xml><span class=icon><i class="fa fa-rss"></i></span>
<span class=label>RSS</span></a></div></div></div><div class=post-nav><div class="post-nav-next post-nav-item"><a href=/post/%E9%99%8D%E7%BB%B4-tsnet-%E5%88%86%E5%B8%83%E5%BC%8F%E9%9A%8F%E6%9C%BA%E9%82%BB%E5%9F%9F%E5%B5%8C%E5%85%A5/ rel=next title=降维-tSNE(t-分布式随机邻域嵌入)><i class="fa fa-chevron-left"></i> 降维-tSNE(t-分布式随机邻域嵌入)</a></div><div class="post-nav-prev post-nav-item"><a href=/post/%E8%81%9A%E7%B1%BB-em%E8%81%9A%E7%B1%BB/ rel=prev title=聚类-EM聚类>聚类-EM聚类
<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div></main><footer class=footer><div class=footer-inner><div class=copyright>&copy;
<span itemprop=copyrightYear>2010 - 2023</span>
<span class=with-love><i class="fa fa-heart"></i></span>
<span class=author itemprop=copyrightHolder>Tomding</span></div></div></footer><script type=text/javascript src=https://cdn.staticfile.org/animejs/3.2.1/anime.min.js defer></script>
<script type=text/javascript src=https://cdn.staticfile.org/viewerjs/1.11.0/viewer.min.js defer></script>
<script class=next-config data-name=main type=application/json>{"bookmark":{"color":"#222","enable":false,"save":"manual"},"busuanzi":{"pageview":true},"copybtn":true,"darkmode":true,"giscus":{"cfg":{"category":"Comments","categoryid":null,"emit":false,"inputposition":"top","mapping":"title","reactions":false,"repo":"username/repo-name","repoid":null,"theme":"preferred_color_scheme"},"js":"https://giscus.app/client.js"},"hostname":"/","i18n":{"ds_day":" 天前","ds_days":" 天 ","ds_hour":" 小时前","ds_hours":" 小时 ","ds_just":"刚刚","ds_min":" 分钟前","ds_mins":" 分钟","ds_month":" 个月前","ds_years":" 年 ","empty":"没有找到任何搜索结果：${query}","hits":"","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","placeholder":"搜索..."},"lang":"zh-CN","lazyload":false,"localSearch":{"enable":true,"path":"/searchindexes.xml","preload":false,"topnperarticle":-1,"trigger":"auto","unescape":false},"motion":{"async":true,"enable":true,"transition":{"collheader":"fadeInLeft","postblock":"fadeIn","postbody":"fadeInDown","postheader":"fadeInDown","sidebar":"fadeInUp"}},"root":"/","scheme":"Gemini","sidebar":{"display":"post","offset":12,"padding":18,"position":"left","width":256},"statis":{"enable":true,"plugin":"busuanzi"},"vendor":{"plugins":"qiniu","router":"https://cdn.staticfile.org"},"version":"4.4.1","waline":{"cfg":{"comment":true,"emoji":false,"imguploader":false,"pageview":true,"placeholder":"请文明发言哟 ヾ(≧▽≦*)o","reaction":true,"reactiontext":["点赞","踩一下","得意","不屑","尴尬","睡觉"],"reactiontitle":"你认为这篇文章怎么样？","requiredmeta":["nick","mail"],"serverurl":null,"sofa":"快来发表你的意见吧 (≧∀≦)ゞ","wordlimit":200},"css":{"alias":"waline","file":"dist/waline.css","name":"@waline/client","version":"2.13.0"},"js":{"alias":"waline","file":"dist/waline.js","name":"@waline/client","version":"2.13.0"}}}</script><script type=text/javascript src=/js/main.min.e34208af37d3db3a875e6fbad04c2f1c241185af925a9c6ebf79dd1ba2730cdd.js defer></script></body></html>