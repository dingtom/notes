<!doctype html><html lang=zh-cn data-theme=dark><head><meta charset=utf-8><meta name=viewport content="width=device-width"><meta name=theme-color content="#222" media="(prefers-color-scheme: dark)"><meta name=generator content="Hugo 0.107.0"><link rel="shortcut icon" type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=/imgs/icons/favicon_16x16_next.png><link rel=icon type=image/png sizes=32x32 href=/imgs/icons/favicon_32_32_next.png><link rel=apple-touch-icon sizes=180x180 href=/imgs/icons/apple_touch_icon_next.png><meta itemprop=name content="面试-特征构造、选择"><meta itemprop=description content="Love and Peace"><meta itemprop=datePublished zgotmplz><meta itemprop=dateModified zgotmplz><meta itemprop=image content="/imgs/hugo_next_avatar.png"><meta itemprop=keywords content="Hugo,NexT,主题,简单,强大"><meta property="og:type" content="article"><meta property="og:title" content="面试-特征构造、选择"><meta property="og:description" content="Love and Peace"><meta property="og:image" content="/imgs/hugo_next_avatar.png"><meta property="og:image:width" content="312"><meta property="og:image:height" content="312"><meta property="og:image:type" content="image/jpeg/png/svg/jpg"><meta property="og:url" content="/post/%E9%9D%A2%E8%AF%95-%E7%89%B9%E5%BE%81%E6%9E%84%E9%80%A0%E9%80%89%E6%8B%A9/"><meta property="og:site_name" content="Tomding's Blog"><meta property="og:locale" content="zh-CN"><meta property="article:author" content="Tomding"><meta property="article:published_time" content="2022-12-01 19:59:47 +0800 CST"><meta property="article:modified_time" content="2022-12-01 19:59:47 +0800 CST"><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/font-awesome/6.1.2/css/all.min.css><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/animate.css/3.1.1/animate.min.css><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/viewerjs/1.11.0/viewer.min.css><link rel=stylesheet href=/css/main.min.0ca97083b39f4eda7430d39b99194aa738d8f8db4090f00bc7e814013df699cb.css><style type=text/css>.post-footer,.flinks-list-footer hr:after{content:"~ 我可是有底线的哟 ~"}</style><script type=text/javascript>(function(){localDB={set:function(e,t,n){if(n===0)return;const s=new Date,o=n*864e5,i={value:t,expiry:s.getTime()+o};localStorage.setItem(e,JSON.stringify(i))},get:function(e){const t=localStorage.getItem(e);if(!t)return void 0;const n=JSON.parse(t),s=new Date;return s.getTime()>n.expiry?(localStorage.removeItem(e),void 0):n.value}},theme={active:function(){const e=localDB.get("theme");if(e==null)return;theme.toggle(e),window.matchMedia("(prefers-color-scheme: dark)").addListener(function(e){theme.toggle(e.matches?"dark":"light")})},toggle:function(e){document.documentElement.setAttribute("data-theme",e),localDB.set("theme",e,2);const t=document.querySelector("iframe.giscus-frame");if(t){const n={setConfig:{theme:e}};t.contentWindow.postMessage({giscus:n},"https://giscus.app")}}},theme.active()})(window)</script><script class=next-config data-name=page type=application/json>{"comments":false,"isHome":false,"isPage":true,"path":"%E9%9D%A2%E8%AF%95-%E7%89%B9%E5%BE%81%E6%9E%84%E9%80%A0%E9%80%89%E6%8B%A9","permalink":"/post/%E9%9D%A2%E8%AF%95-%E7%89%B9%E5%BE%81%E6%9E%84%E9%80%A0%E9%80%89%E6%8B%A9/","title":"面试-特征构造、选择","waline":{"js":[{"alias":"waline","alias_name":"@waline/client","file":"dist/pageview.js","name":"pageview","version":"2.13.0"},{"alias":"waline","alias_name":"@waline/client","file":"dist/comment.js","name":"comment","version":"2.13.0"}]}}</script><script type=text/javascript>document.addEventListener("DOMContentLoaded",()=>{var e=document.createElement("script");e.charset="UTF-8",e.src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js",e.async=!1,e.defer=!0,document.head.appendChild(e),e.onload=function(){NexT.utils.fmtBusuanzi()}})</script><title>面试-特征构造、选择 - Tomding's Blog</title><noscript><link rel=stylesheet href=/css/noscript.css></noscript></head><body itemscope itemtype=http://schema.org/WebPage class=use-motion><div class=headband></div><main class=main><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle aria-label=切换导航栏 role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div></div><div class=site-meta><a href=/ class=brand rel=start><i class=logo-line></i><h1 class=site-title>Tomding's Blog</h1><i class=logo-line></i></a><p class=site-subtitle itemprop=description>Just do it!</p></div><div class=site-nav-right><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href=/ class=hvr-icon-pulse rel=section><i class="fa fa-home hvr-icon"></i>首页</a></li><li class="menu-item menu-item-about"><a href=/about.html class=hvr-icon-pulse rel=section><i class="fa fa-user hvr-icon"></i>关于</a></li><li class="menu-item menu-item-archives"><a href=/archives/ class=hvr-icon-pulse rel=section><i class="fa fa-archive hvr-icon"></i>归档
<span class=badge>109</span></a></li><li class="menu-item menu-item-search"><a role=button class="popup-trigger hvr-icon-pulse"><i class="fa fa-search fa-fw hvr-icon"></i>搜索</a></li></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon><i class="fa fa-search"></i></span><div class=search-input-container><input autocomplete=off autocapitalize=off maxlength=80 placeholder=搜索... spellcheck=false type=search class=search-input></div><span class=popup-btn-close role=button><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class=search-result-icon><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></div><div class="toggle sidebar-toggle" role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div><aside class=sidebar><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>文章目录</li><li class=sidebar-nav-overview>站点概览</li></ul><div class=sidebar-panel-container><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><nav id=TableOfContents><ul><li><a href=#特征选择主要有两个功能>特征选择主要有两个功能：</a></li><li><a href=#从两个方面考虑来选择特征>从两个方面考虑来选择特征：</a></li></ul><ul><li><a href=#包裹式wrapper>包裹式（wrapper）</a><ul><li><a href=#方法lvmlas-vegas-wrapper递归特征消除算法基于机器学习模型的特征排序>方法：LVM（Las Vegas Wrapper）、递归特征消除算法、基于机器学习模型的特征排序</a></li><li><a href=#主要思想>主要思想：</a></li><li><a href=#优缺点>优缺点：</a></li><li><a href=#递归特征消除recursive-feature-elimination>递归特征消除(Recursive feature elimination)</a></li></ul></li><li><a href=#嵌入式embedding>嵌入式（embedding）：</a><ul><li><a href=#方法lrl1决策树lasso回归>方法：LR+L1、决策树、lasso回归</a></li><li><a href=#主要思想-1>主要思想：</a></li></ul></li></ul></nav></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author site-overview-item animated" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image alt=Tomding src=/imgs/img-lazy-loading.gif data-src=/imgs/hugo_next_avatar.png><p class=site-author-name itemprop=name>Tomding</p><div class=site-description itemprop=description>Love and Peace</div></div><div class="site-state-wrap site-overview-item animated"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/><span class=site-state-item-count>109</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>7</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>0</span>
<span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-social site-overview-item animated"><span class=links-of-social-item><a href=https://github.com/ title="Github → https://github.com/" rel=noopener class=hvr-icon-pulse target=_blank><i class="fab fa-github fa-fw hvr-icon"></i>Github</a></span>
<span class=links-of-social-item><a href=https://www.zhihu.com/hot title="知乎 → https://www.zhihu.com/hot" rel=noopener class=hvr-icon-pulse target=_blank><i class="fa fa-book fa-fw hvr-icon"></i>知乎</a></span></div><div class="cc-license animated" itemprop=license><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh class=cc-opacity rel=noopener target=_blank title=共享知识><img src=/imgs/img-lazy-loading.gif data-src=/imgs/cc/big/by_nc_sa.svg alt=共享知识></a></div><div class="links-of-blogroll site-overview-item animated"><div class=links-of-blogroll-title><i class="fa fa-globe fa-fw"></i>友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://gitee.com/hugo-next/hugo-theme-next title=https://gitee.com/hugo-next/hugo-theme-next target=_blank>Hugo-NexT</a></li><li class=links-of-blogroll-item><a href=https://lisenhui.cn title=https://lisenhui.cn target=_blank>凡梦星尘空间站</a></li></ul></div></div></div></div><div id=siteinfo-card-widget class=sidebar-card-widget><div class=item-headline><i class="fas fa-chart-line"></i>
<span>网站资讯</span></div><div class=siteinfo><div class=siteinfo-item><div class=item-name><i class="fa-solid fa-calendar-check"></i>已运行：</div><div class=item-count id=runTimes data-publishdate=2022-12-01T19:59:47+08:00></div></div><div class=siteinfo-item><div class=item-name><i class="fas fa fa-user"></i>总访客数：</div><div class=item-count id=busuanzi_value_site_uv><i class="fa fa-sync fa-spin"></i></div></div><div class=siteinfo-item><div class=item-name><i class="fas fa fa-eye"></i>页面浏览：</div><div class=item-count id=busuanzi_value_site_pv><i class="fa fa-sync fa-spin"></i></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-font"></i>总字数：</div><div class=item-count id=wordsCount data-count=412496></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-mug-hot"></i>阅读约：</div><div class=item-count id=readTimes data-times=882></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-clock-rotate-left"></i>最后更新于：</div><div class=item-count id=last-push-date data-lastpushdate=2023-01-01T14:28:53+08:00></div></div></div></div></aside><div class=sidebar-dimmer></div></header><div class=tool-buttons><div id=toggle-theme class=button title=深浅模式切换><i class="fas fa-adjust"></i></div><div class=back-to-top role=button title=返回顶部><i class="fa fa-arrow-up"></i>
<span>0%</span></div></div><div class=reading-progress-bar></div><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><div class="main-inner post posts-expand"><div class=post-block><article itemscope itemtype=http://schema.org/Article class=post-content lang><link itemprop=mainEntityOfPage href=/post/%E9%9D%A2%E8%AF%95-%E7%89%B9%E5%BE%81%E6%9E%84%E9%80%A0%E9%80%89%E6%8B%A9/><span hidden itemprop=author itemscope itemtype=http://schema.org/Person><meta itemprop=image content="/imgs/hugo_next_avatar.png"><meta itemprop=name content="Tomding"></span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization><meta itemprop=name content="Tomding"><meta itemprop=description content="Love and Peace"></span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork><meta itemprop=name content="面试-特征构造、选择"><meta itemprop=description content="特征构造 统计量特征：计数、求和、比例、标准差等 时间特征：相对时间、绝对时间，节假日，双休日等 地理信息：分桶 非线性变换：取log、平方、根号 数"></span><header class=post-header><h1 class=post-title itemprop="name headline">面试-特征构造、选择
<a href=https://github.com/user-name/repo-name/tree/branch-name/subdirectory-name/post/%e9%9d%a2%e8%af%95-%e7%89%b9%e5%be%81%e6%9e%84%e9%80%a0%e3%80%81%e9%80%89%e6%8b%a9.md rel="noopener external nofollow noreferrer" target=_blank class="exturl post-edit-link" title=编辑><i class="fa fa-pen-nib"></i></a></h1><div class=post-meta-container><div class=post-meta-items><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-calendar"></i></span>
<span class=post-meta-item-text>发表于：</span>
<time title="发表于：2022-12-01 19:59:47 +0800 CST" itemprop="dateCreated datePublished" datetime="2022-12-01 19:59:47 +0800 CST">2022-12-01</time></span>
<span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-folder-open"></i></span>
<span class=post-meta-item-text>分类于：</span>
<span itemprop=about itemscope itemtype=http://schema.org/Thing><a href=/categories/%E9%9D%A2%E8%AF%95 itemprop=url rel=index><span itemprop=name>面试</span></a></span></span></div><div class=post-meta-items><span class=post-meta-item title=字数><span class=post-meta-item-icon><i class="far fa-file-word"></i></span>
<span class=post-meta-item-text>字数：</span><span>3254</span></span>
<span class=post-meta-item title=阅读><span class=post-meta-item-icon><i class="far fa-clock"></i></span>
<span class=post-meta-item-text>阅读：&ap;</span>
<span>7分钟</span></span>
<span class=post-meta-item title=浏览><span class=post-meta-item-icon><i class="far fa-eye"></i></span>
<span class=post-meta-item-text>浏览：</span>
<span id=busuanzi_value_page_pv class=waline-pageview-count data-path=/post/%E9%9D%A2%E8%AF%95-%E7%89%B9%E5%BE%81%E6%9E%84%E9%80%A0%E9%80%89%E6%8B%A9/><i class="fa fa-sync fa-spin"></i></span></span></div></div></header><div class="post-body autonumber" itemprop=articleBody><h1 id=特征构造>特征构造</h1><p>统计量特征：计数、求和、比例、标准差等
时间特征：相对时间、绝对时间，节假日，双休日等
地理信息：分桶
非线性变换：取log、平方、根号
数据分桶：等频、等距分桶、Dest-KS分桶、卡方分桶
特征组合、交叉：人、商品</p><blockquote><p><code>数据分桶</code>
等频分桶：区间的边界值要经过选择,使得每个区间包含大致相等的实例数量。
等距分桶：从最小值到最大值之间,均分为 N 等份；
Best-KS分桶：类似利用基尼指数进行二分类；
卡方分桶：自底向上的(即基于合并的)数据离散化方法。它依赖于卡方检验：具有最小卡方值的相邻区间合并在一起,直到满足确定的停止准则。
<code>为什么要做数据分桶呢？</code>
离散后<code>稀疏向量内积乘法运算速度更快，计算结果也方便存储</code>，容易扩展；
离散后的特征<code>对异常值更具鲁棒性</code>，如 age>30 为 1 否则为 0，对于年龄为 200 的也不会对模型造成很大的干扰；
LR 属于广义线性模型，表达能力有限，<code>经过离散化后，每个变量有单独的权重，这相当于引入了非线性，能够提升模型的表达能力，加大拟合</code>；
离散后特征<code>可以进行特征交叉，提升表达能力，由 M\+N 个变量变为 M\*N 个变量，进一步引入非线形，提升了表达能力</code>；
特征离散后模型更稳定，如用户年龄区间，不会因为用户年龄长了一岁就变化
当然还有很多原因，LightGBM 在改进 XGBoost 时就增加了数据分桶，<code>增强了模型的泛化性</code></p></blockquote><h1 id=特征选择>特征选择</h1><h2 id=特征选择主要有两个功能>特征选择主要有两个功能：</h2><p>减少特征数量、降维，使模型泛化能力更强，减少过拟合
增强对特征和特征值之间的理解</p><h2 id=从两个方面考虑来选择特征>从两个方面考虑来选择特征：</h2><p><code>特征是否发散</code>：如果一个特征不发散，例如方差接近于0，也就是说样本在这个特征上基本上没有差异，这个特征对于样本的区分并没有什么用。</p><p><code>特征与目标的相关性</code>：这点比较显见，与目标相关性高的特征，应当优选选择。</p><h1 id=过滤式filter>过滤式（filter）：</h1><p>概述：按照发散性或者相关性<code>对各个特征进行评分</code>，设定阈值或者待选择阈值的个数，<code>选择特征。然后再训练学习器。</code>特征选择过程与<code>后续学习器无关</code></p><p>方法： Relief、方差选择、相关系数、卡方检验、互信息</p><ul><li>数值型特征，方差很小的特征可不要</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>from sklearn.feature_selection import VarianceThreshold  # 默认方差为0的特征会自动删除
</span></span><span style=display:flex><span>X = [[0, 2, 0, 3], [0, 1, 4, 3], [0, 1, 1, 3]]
</span></span><span style=display:flex><span>selector = VarianceThreshold()  #  默认threshold=0.0
</span></span><span style=display:flex><span>print(selector.fit_transform(X))
</span></span><span style=display:flex><span># variances_查看样本各个特征的方差
</span></span><span style=display:flex><span># get_params(deep=True)：获取估计器参数，以字典形式返回
</span></span><span style=display:flex><span># get_support(indices=False)：参数为False，返回满足的特征的索引为True，则特征列受否满足为True或False；
</span></span><span style=display:flex><span># inverse_transform(X)：反转转换操作，返回X，剔除的特征列值用0替换的数组
</span></span></code></pre></div><p>scores按升序排序，选择排前k名所对应的特征
<code>sklearn.feature_selection.SelectKBest(score_func=&lt;function f_classif>, k=10)</code>
scores按升序排序，选择排前百分percentile所对应的特征
<code>sklearn.feature_selection.SelectPercentile(score_func=&lt;function f_classif>, percentile=10)</code></p><ul><li><p>分类特征,取值个数高度偏斜的那种可以先去掉</p></li><li><p>相关系数排序
选择相关系数大于阈值的部分特征；（当然有时候根据字段含义也可以选）
<code>连续数据，正态分布，线性关系，用pearson相关系数是最恰当，当然用spearman相关系数也可以，效率没有pearon相关系数高。上述任一条件不满足，就用spearman相关系数</code>，不能用pearson相关系数。
两个定序测量数据（顺序变量）之间也用spearman相关系数，不能用pearson相关系数。Pearson相关系数的一个明显缺陷是，作为特征排序机制，他只对线性关系敏感。如果关系是非线性的，即便两个变量具有一一对应的关系，Pearson相关性也可能会接近0。</p></li><li><p>利用假设检验得到特征与输出值之间的相关性
分类问题：chi2, f_classif, mutual_info_classif
回归问题：f_regression, mutual_info_regression
方法有比如卡方检验、t检验、F检验等。
卡方检验一般是检查离散变量与离散变量的相关性，当然离散变量的相关性信息增益和信息增益比也是不错的选择（可以通过决策树模型来评估来看）</p></li><li><p>互信息
利用互信息从信息熵的角度分析相关性</p></li></ul><h2 id=包裹式wrapper>包裹式（wrapper）</h2><p><code>确定模型和评价准则之后，对特征空间的不同子集做交叉验证，进而搜索最佳特征子集</code></p><h3 id=方法lvmlas-vegas-wrapper递归特征消除算法基于机器学习模型的特征排序>方法：LVM（Las Vegas Wrapper）、递归特征消除算法、基于机器学习模型的特征排序</h3><h3 id=主要思想>主要思想：</h3><p>包裹式从初始特征集合中不断的选择特征子集，训练学习器，根据学习器的性能来对子集进行评价，直到选择出最佳的子集。包裹式特征选择直接针对给定学习器进行优化。</p><h3 id=优缺点>优缺点：</h3><p>从最终学习器的性能来看，包裹式比过滤式更好；
计算开销通常比过滤式特征选择要大得多。</p><p>特征子集的搜索问题，最容易想到的办法是穷举法，还可以<code>在拉斯维加斯方法框架下使用随机策略进行子集搜索（Las Vegas Wrapper，LVW）。但是由于LVW算法中特征子集搜索采用了随机策略，每次特征子集评价都需要训练学习器，计算开销很</code>大，如果初始特征数很多，算法可能运行很长时间都达不到停止条件，若有运行时间限制，可能给不出解。
因此，我们<code>通常使用的是贪心算法</code>：如前向搜索（在最优的子集上逐步增加特征，直到增加特征并不能使模型性能提升为止）、后向搜索、双向搜索（将前向搜索和后向搜索相结合）。</p><h3 id=递归特征消除recursive-feature-elimination>递归特征消除(Recursive feature elimination)</h3><p><code>对特征含有权重的预测模型</code>（如线性模型的权重系数），递归特征消除（RFE）<code>通过递归考虑越来越少的特征集来选择特征。</code>
具体流程如下：首先，对估计器进行初始特征集训练，并通过coef_或feature_importances_属性获取特征的重要性；然后，<code>从当前的特征中删除最不重要的特征；最后，对以上过程进行递归重复，直至达到所需的特征数量。</code>
对手写数字图片每个像素点权重进行排名</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span># 例1：递归特征消除示例
</span></span><span style=display:flex><span>from sklearn.svm import SVC
</span></span><span style=display:flex><span>from sklearn.datasets import load_digits
</span></span><span style=display:flex><span>from sklearn.feature_selection import RFE
</span></span><span style=display:flex><span># 导入手写数字数据集
</span></span><span style=display:flex><span>digits = load_digits()
</span></span><span style=display:flex><span>print(digits.images.shape)  # (1797, 8, 8)
</span></span><span style=display:flex><span>X = digits.images.reshape((len(digits.images), -1))# (1797, 64)
</span></span><span style=display:flex><span>y = digits.target
</span></span><span style=display:flex><span># 创建RFE并
</span></span><span style=display:flex><span>svc = SVC(kernel=&#34;linear&#34;, C=1)
</span></span><span style=display:flex><span>rfe = RFE(estimator=svc, n_features_to_select=1, step=1)
</span></span><span style=display:flex><span>rfe.fit(X, y)
</span></span><span style=display:flex><span>ranking = rfe.ranking_.reshape(digits.images[0].shape)
</span></span><span style=display:flex><span>print(ranking.shape)
</span></span><span style=display:flex><span># 将排名可视化输出
</span></span><span style=display:flex><span>plt.matshow(ranking, cmap=plt.cm.Blues)
</span></span><span style=display:flex><span>plt.colorbar()
</span></span><span style=display:flex><span>plt.title(&#34;Ranking of pixels with RFE&#34;)
</span></span><span style=display:flex><span>plt.show()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># estimator,一种具有 fit 方法的监督学习估计器，它通过一个coef_属性或feature_importances_ 提供关于特征重要性的信息。
</span></span><span style=display:flex><span># n_features_to_select,要选择的特征的数量。如果没有，则选择一半的特征。
</span></span><span style=display:flex><span># step,如果大于或等于1，则对应于每次迭代中要删除的(整数)特性数。如果在(0.0,1.0)范围内，则对应于在每次迭代中要删除的特性的百分比(向下舍入)。
</span></span><span style=display:flex><span># n_features_,选择特征的数量。
</span></span><span style=display:flex><span># support_,所选特征的掩码。
</span></span><span style=display:flex><span># ranking_,特征的的排名
</span></span><span style=display:flex><span># estimator_
</span></span></code></pre></div><h2 id=嵌入式embedding>嵌入式（embedding）：</h2><p>概述：<code>结合过滤式和包裹式，学习器训练过程中自动进行了特征选择</code>。先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。</p><h3 id=方法lrl1决策树lasso回归>方法：LR+L1、决策树、lasso回归</h3><h3 id=主要思想-1>主要思想：</h3><p>在过滤式和包裹式特征选择方法中，特征选择过程与学习器训练过程有明显的分别。而嵌入式特征选择在学习器训练过程中自动地进行特征选择。</p><p>嵌入式选择最常用的是L1 正则化和L2正则化</p><blockquote><p>正则化项越大，模型越简单，系数越小，<code>当正则化项增大到一定程度时，所有的特征系数都会趋于0，在这个过程中，会有一部分特征的系数先变成0。也就实现了特征选择过程</code>。逻辑回归、线性回归、决策树都可以当作正则化选择特征的基学习器，<code>只有可以得到特征系数或者可以得到特征重要度的算法才可以作为嵌入式选择的基学习器。</code></p></blockquote><p>将LinearSVC 和SelectFromModel结合来评估特征的重要性进行特征选择，之后用RandomForestClassifier模型使用转换后的输出（即被选出的相关特征）进行训练。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>from sklearn.pipeline import Pipeline
</span></span><span style=display:flex><span>from sklearn.datasets import load_iris
</span></span><span style=display:flex><span>from sklearn.feature_selection import SelectFromModel
</span></span><span style=display:flex><span>from sklearn.svm import LinearSVC
</span></span><span style=display:flex><span>from sklearn.ensemble import RandomForestClassifier
</span></span><span style=display:flex><span>iris = load_iris()
</span></span><span style=display:flex><span>X, y = iris.data, iris.target
</span></span><span style=display:flex><span>clf = Pipeline([
</span></span><span style=display:flex><span>    (&#39;feature_selection&#39;, SelectFromModel(LinearSVC(penalty=&#34;l1&#34;, dual=False, max_iter=3000))),
</span></span><span style=display:flex><span>    (&#39;classfication&#39;, RandomForestClassifier(n_estimators=100))])
</span></span><span style=display:flex><span>clf.fit(X, y)
</span></span><span style=display:flex><span># sklearn.feature_selection.SelectFromModel(estimator, threshold=None, prefit=False, norm_order=1, max_features=None)
</span></span><span style=display:flex><span># estimator,`SelectFromModel与任何训练后有coef_或feature_importances_属性的预测模型一起使用`
</span></span><span style=display:flex><span># threshold.用于特征选择的阈值。重要性大于或等于的特征被保留,也可以设置成一些抽象的值，比如mean,median,1.25*mean等等。
</span></span><span style=display:flex><span># prefit 是否对传入的基本分类器事先进行训练。
</span></span><span style=display:flex><span># norm_order 
</span></span><span style=display:flex><span># max_features 所选特征数目
</span></span><span style=display:flex><span># threshold_
</span></span><span style=display:flex><span># estimator_
</span></span></code></pre></div></div><footer class=post-footer><div class=addthis_inline_share_toolbox style=text-align:center></div><hr><div class=post-copyright><img src=/imgs/cc/cc.svg width=75 height=75 align=right><ul><li class=post-copyright-title><strong>文章标题：</strong>
面试-特征构造、选择</li><li class=post-copyright-author><strong>本文作者：</strong>
Tomding</li><li class=post-copyright-link><strong>本文链接：</strong>
<a id=post-cr-link href=/post/%E9%9D%A2%E8%AF%95-%E7%89%B9%E5%BE%81%E6%9E%84%E9%80%A0%E9%80%89%E6%8B%A9/ title=面试-特征构造、选择>/post/%E9%9D%A2%E8%AF%95-%E7%89%B9%E5%BE%81%E6%9E%84%E9%80%A0%E9%80%89%E6%8B%A9/</a></li><li class=post-copyright-license><strong>版权声明：</strong>
本博客所有文章除特别声明外，均采用 <i class="fab fa-fw fa-creative-commons"></i><a target=_blank href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class=followme><span>欢迎关注我的其它发布渠道</span><div class=social-list><div class=social-item><a target=_blank class=social-link href=/images/wechat_channel.jpg><span class=icon><i class="fab fa-weixin"></i></span>
<span class=label>WeChat</span></a></div><div class=social-item><a target=_blank class=social-link href=/atom.xml><span class=icon><i class="fa fa-rss"></i></span>
<span class=label>RSS</span></a></div></div></div><div class=post-nav><div class="post-nav-next post-nav-item"><a href=/post/%E9%9D%A2%E8%AF%95-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/ rel=next title=面试-数据预处理><i class="fa fa-chevron-left"></i> 面试-数据预处理</a></div><div class="post-nav-prev post-nav-item"><a href=/post/%E9%9D%A2%E8%AF%95-%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/ rel=prev title=面试-异常处理>面试-异常处理
<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div></main><footer class=footer><div class=footer-inner><div class=copyright>&copy;
<span itemprop=copyrightYear>2010 - 2023</span>
<span class=with-love><i class="fa fa-heart"></i></span>
<span class=author itemprop=copyrightHolder>Tomding</span></div></div></footer><script type=text/javascript src=https://cdn.staticfile.org/animejs/3.2.1/anime.min.js defer></script>
<script type=text/javascript src=https://cdn.staticfile.org/viewerjs/1.11.0/viewer.min.js defer></script>
<script class=next-config data-name=main type=application/json>{"bookmark":{"color":"#222","enable":false,"save":"manual"},"busuanzi":{"pageview":true},"copybtn":true,"darkmode":true,"giscus":{"cfg":{"category":"Comments","categoryid":null,"emit":false,"inputposition":"top","mapping":"title","reactions":false,"repo":"username/repo-name","repoid":null,"theme":"preferred_color_scheme"},"js":"https://giscus.app/client.js"},"hostname":"/","i18n":{"ds_day":" 天前","ds_days":" 天 ","ds_hour":" 小时前","ds_hours":" 小时 ","ds_just":"刚刚","ds_min":" 分钟前","ds_mins":" 分钟","ds_month":" 个月前","ds_years":" 年 ","empty":"没有找到任何搜索结果：${query}","hits":"","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","placeholder":"搜索..."},"lang":"zh-CN","lazyload":false,"localSearch":{"enable":true,"path":"/searchindexes.xml","preload":false,"topnperarticle":-1,"trigger":"auto","unescape":false},"motion":{"async":true,"enable":true,"transition":{"collheader":"fadeInLeft","postblock":"fadeIn","postbody":"fadeInDown","postheader":"fadeInDown","sidebar":"fadeInUp"}},"root":"/","scheme":"Gemini","sidebar":{"display":"post","offset":12,"padding":18,"position":"left","width":256},"statis":{"enable":true,"plugin":"busuanzi"},"vendor":{"plugins":"qiniu","router":"https://cdn.staticfile.org"},"version":"4.4.1","waline":{"cfg":{"comment":true,"emoji":false,"imguploader":false,"pageview":true,"placeholder":"请文明发言哟 ヾ(≧▽≦*)o","reaction":true,"reactiontext":["点赞","踩一下","得意","不屑","尴尬","睡觉"],"reactiontitle":"你认为这篇文章怎么样？","requiredmeta":["nick","mail"],"serverurl":null,"sofa":"快来发表你的意见吧 (≧∀≦)ゞ","wordlimit":200},"css":{"alias":"waline","file":"dist/waline.css","name":"@waline/client","version":"2.13.0"},"js":{"alias":"waline","file":"dist/waline.js","name":"@waline/client","version":"2.13.0"}}}</script><script type=text/javascript src=/js/main.min.e34208af37d3db3a875e6fbad04c2f1c241185af925a9c6ebf79dd1ba2730cdd.js defer></script></body></html>