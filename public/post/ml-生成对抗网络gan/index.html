<!doctype html><html lang=zh-cn data-theme=dark><head><meta charset=utf-8><meta name=viewport content="width=device-width"><meta name=theme-color content="#222" media="(prefers-color-scheme: dark)"><meta name=generator content="Hugo 0.107.0"><link rel="shortcut icon" type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=/imgs/icons/favicon_16x16_next.png><link rel=icon type=image/png sizes=32x32 href=/imgs/icons/favicon_32_32_next.png><link rel=apple-touch-icon sizes=180x180 href=/imgs/icons/apple_touch_icon_next.png><meta itemprop=name content="ml-生成对抗网络(GAN)"><meta itemprop=description content="Love and Peace"><meta itemprop=datePublished zgotmplz><meta itemprop=dateModified zgotmplz><meta itemprop=image content="/imgs/hugo_next_avatar.png"><meta itemprop=keywords content="Hugo,NexT,主题,简单,强大"><meta property="og:type" content="article"><meta property="og:title" content="ml-生成对抗网络(GAN)"><meta property="og:description" content="Love and Peace"><meta property="og:image" content="/imgs/hugo_next_avatar.png"><meta property="og:image:width" content="312"><meta property="og:image:height" content="312"><meta property="og:image:type" content="image/jpeg/png/svg/jpg"><meta property="og:url" content="/post/ml-%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9Cgan/"><meta property="og:site_name" content="Tomding's Blog"><meta property="og:locale" content="zh-CN"><meta property="article:author" content="Tomding"><meta property="article:published_time" content="2022-12-01 19:59:47 +0800 CST"><meta property="article:modified_time" content="2022-12-01 19:59:47 +0800 CST"><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/font-awesome/6.1.2/css/all.min.css><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/animate.css/3.1.1/animate.min.css><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/viewerjs/1.11.0/viewer.min.css><link rel=stylesheet href=/css/main.min.0ca97083b39f4eda7430d39b99194aa738d8f8db4090f00bc7e814013df699cb.css><style type=text/css>.post-footer,.flinks-list-footer hr:after{content:"~ 我可是有底线的哟 ~"}</style><script type=text/javascript>(function(){localDB={set:function(e,t,n){if(n===0)return;const s=new Date,o=n*864e5,i={value:t,expiry:s.getTime()+o};localStorage.setItem(e,JSON.stringify(i))},get:function(e){const t=localStorage.getItem(e);if(!t)return void 0;const n=JSON.parse(t),s=new Date;return s.getTime()>n.expiry?(localStorage.removeItem(e),void 0):n.value}},theme={active:function(){const e=localDB.get("theme");if(e==null)return;theme.toggle(e),window.matchMedia("(prefers-color-scheme: dark)").addListener(function(e){theme.toggle(e.matches?"dark":"light")})},toggle:function(e){document.documentElement.setAttribute("data-theme",e),localDB.set("theme",e,2);const t=document.querySelector("iframe.giscus-frame");if(t){const n={setConfig:{theme:e}};t.contentWindow.postMessage({giscus:n},"https://giscus.app")}}},theme.active()})(window)</script><script class=next-config data-name=page type=application/json>{"comments":false,"isHome":false,"isPage":true,"path":"ml-%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9Cgan","permalink":"/post/ml-%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9Cgan/","title":"ml-生成对抗网络(GAN)","waline":{"js":[{"alias":"waline","alias_name":"@waline/client","file":"dist/pageview.js","name":"pageview","version":"2.13.0"},{"alias":"waline","alias_name":"@waline/client","file":"dist/comment.js","name":"comment","version":"2.13.0"}]}}</script><script type=text/javascript>document.addEventListener("DOMContentLoaded",()=>{var e=document.createElement("script");e.charset="UTF-8",e.src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js",e.async=!1,e.defer=!0,document.head.appendChild(e),e.onload=function(){NexT.utils.fmtBusuanzi()}})</script><title>ml-生成对抗网络(GAN) - Tomding's Blog</title><noscript><link rel=stylesheet href=/css/noscript.css></noscript></head><body itemscope itemtype=http://schema.org/WebPage class=use-motion><div class=headband></div><main class=main><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle aria-label=切换导航栏 role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div></div><div class=site-meta><a href=/ class=brand rel=start><i class=logo-line></i><h1 class=site-title>Tomding's Blog</h1><i class=logo-line></i></a><p class=site-subtitle itemprop=description>Just do it!</p></div><div class=site-nav-right><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href=/ class=hvr-icon-pulse rel=section><i class="fa fa-home hvr-icon"></i>首页</a></li><li class="menu-item menu-item-about"><a href=/about.html class=hvr-icon-pulse rel=section><i class="fa fa-user hvr-icon"></i>关于</a></li><li class="menu-item menu-item-archives"><a href=/archives/ class=hvr-icon-pulse rel=section><i class="fa fa-archive hvr-icon"></i>归档
<span class=badge>73</span></a></li><li class="menu-item menu-item-search"><a role=button class="popup-trigger hvr-icon-pulse"><i class="fa fa-search fa-fw hvr-icon"></i>搜索</a></li></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon><i class="fa fa-search"></i></span><div class=search-input-container><input autocomplete=off autocapitalize=off maxlength=80 placeholder=搜索... spellcheck=false type=search class=search-input></div><span class=popup-btn-close role=button><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class=search-result-icon><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></div><div class="toggle sidebar-toggle" role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div><aside class=sidebar><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>文章目录</li><li class=sidebar-nav-overview>站点概览</li></ul><div class=sidebar-panel-container><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><nav id=TableOfContents><ul><li><ul><li><a href=#用keras实现gan识别mnisthttpsgithubcomdingtompythonblobmastergan_mnist_keras201ipynb><a href=https://github.com/dingtom/python/blob/master/GAN_MNIST_Keras%20(1).ipynb>用keras实现GAN识别MNIST</a></a></li><li><a href=#tensorflow实现gan识别mnisthttpsgithubcomdingtompythonblobmastergan_mnist_tensorflow201ipynb><a href=https://github.com/dingtom/python/blob/master/GAN_MNIST_Tensorflow%20(1).ipynb>Tensorflow实现GAN识别MNIST</a></a></li></ul></li></ul></nav></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author site-overview-item animated" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image alt=Tomding src=/imgs/img-lazy-loading.gif data-src=/imgs/hugo_next_avatar.png><p class=site-author-name itemprop=name>Tomding</p><div class=site-description itemprop=description>Love and Peace</div></div><div class="site-state-wrap site-overview-item animated"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/><span class=site-state-item-count>73</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>5</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>0</span>
<span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-social site-overview-item animated"><span class=links-of-social-item><a href=https://github.com/ title="Github → https://github.com/" rel=noopener class=hvr-icon-pulse target=_blank><i class="fab fa-github fa-fw hvr-icon"></i>Github</a></span>
<span class=links-of-social-item><a href=https://www.zhihu.com/hot title="知乎 → https://www.zhihu.com/hot" rel=noopener class=hvr-icon-pulse target=_blank><i class="fa fa-book fa-fw hvr-icon"></i>知乎</a></span></div><div class="cc-license animated" itemprop=license><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh class=cc-opacity rel=noopener target=_blank title=共享知识><img src=/imgs/img-lazy-loading.gif data-src=/imgs/cc/big/by_nc_sa.svg alt=共享知识></a></div><div class="links-of-blogroll site-overview-item animated"><div class=links-of-blogroll-title><i class="fa fa-globe fa-fw"></i>友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://gitee.com/hugo-next/hugo-theme-next title=https://gitee.com/hugo-next/hugo-theme-next target=_blank>Hugo-NexT</a></li><li class=links-of-blogroll-item><a href=https://lisenhui.cn title=https://lisenhui.cn target=_blank>凡梦星尘空间站</a></li></ul></div></div></div></div><div id=siteinfo-card-widget class=sidebar-card-widget><div class=item-headline><i class="fas fa-chart-line"></i>
<span>网站资讯</span></div><div class=siteinfo><div class=siteinfo-item><div class=item-name><i class="fa-solid fa-calendar-check"></i>已运行：</div><div class=item-count id=runTimes data-publishdate=2022-12-01T19:59:47+08:00></div></div><div class=siteinfo-item><div class=item-name><i class="fas fa fa-user"></i>总访客数：</div><div class=item-count id=busuanzi_value_site_uv><i class="fa fa-sync fa-spin"></i></div></div><div class=siteinfo-item><div class=item-name><i class="fas fa fa-eye"></i>页面浏览：</div><div class=item-count id=busuanzi_value_site_pv><i class="fa fa-sync fa-spin"></i></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-font"></i>总字数：</div><div class=item-count id=wordsCount data-count=279850></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-mug-hot"></i>阅读约：</div><div class=item-count id=readTimes data-times=597></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-clock-rotate-left"></i>最后更新于：</div><div class=item-count id=last-push-date data-lastpushdate=2022-12-02T03:11:14+08:00></div></div></div></div></aside><div class=sidebar-dimmer></div></header><div class=tool-buttons><div id=toggle-theme class=button title=深浅模式切换><i class="fas fa-adjust"></i></div><div class=back-to-top role=button title=返回顶部><i class="fa fa-arrow-up"></i>
<span>0%</span></div></div><div class=reading-progress-bar></div><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><div class="main-inner post posts-expand"><div class=post-block><article itemscope itemtype=http://schema.org/Article class=post-content lang><link itemprop=mainEntityOfPage href=/post/ml-%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9Cgan/><span hidden itemprop=author itemscope itemtype=http://schema.org/Person><meta itemprop=image content="/imgs/hugo_next_avatar.png"><meta itemprop=name content="Tomding"></span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization><meta itemprop=name content="Tomding"><meta itemprop=description content="Love and Peace"></span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork><meta itemprop=name content="ml-生成对抗网络(GAN)"><meta itemprop=description content="Goodfellow的Generative Adversarial Networks https://arxiv.org/abs/1406.2661 **本质上， GAN 目标是训练出一个好的生成模型，来模拟训练集中的数据。**不同的是， 一般的生成模"></span><header class=post-header><h1 class=post-title itemprop="name headline">ml-生成对抗网络(GAN)
<a href=https://github.com/user-name/repo-name/tree/branch-name/subdirectory-name/post/ml-%e7%94%9f%e6%88%90%e5%af%b9%e6%8a%97%e7%bd%91%e7%bb%9c%28GAN%29.md rel="noopener external nofollow noreferrer" target=_blank class="exturl post-edit-link" title=编辑><i class="fa fa-pen-nib"></i></a></h1><div class=post-meta-container><div class=post-meta-items><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-calendar"></i></span>
<span class=post-meta-item-text>发表于：</span>
<time title="发表于：2022-12-01 19:59:47 +0800 CST" itemprop="dateCreated datePublished" datetime="2022-12-01 19:59:47 +0800 CST">2022-12-01</time></span>
<span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-folder-open"></i></span>
<span class=post-meta-item-text>分类于：</span>
<span itemprop=about itemscope itemtype=http://schema.org/Thing><a href=/categories/ml itemprop=url rel=index><span itemprop=name>ml</span></a></span></span></div><div class=post-meta-items><span class=post-meta-item title=字数><span class=post-meta-item-icon><i class="far fa-file-word"></i></span>
<span class=post-meta-item-text>字数：</span><span>3712</span></span>
<span class=post-meta-item title=阅读><span class=post-meta-item-icon><i class="far fa-clock"></i></span>
<span class=post-meta-item-text>阅读：&ap;</span>
<span>8分钟</span></span>
<span class=post-meta-item title=浏览><span class=post-meta-item-icon><i class="far fa-eye"></i></span>
<span class=post-meta-item-text>浏览：</span>
<span id=busuanzi_value_page_pv class=waline-pageview-count data-path=/post/ml-%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9Cgan/><i class="fa fa-sync fa-spin"></i></span></span></div></div></header><div class="post-body autonumber" itemprop=articleBody><p>Goodfellow的Generative Adversarial Networks
<a href=https://arxiv.org/abs/1406.2661 title=https://arxiv.org/abs/1406.2661 rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://arxiv.org/abs/1406.2661
<i class="fa fa-external-link-alt"></i></a>
**本质上， GAN 目标是训练出一个好的生成模型，来模拟训练集中的数据。**不同的是， 一般的生成模型，必须先初始化一个“假设分布”，即后验分布，通过各种抽样方法抽样这个后验分布，就能知道这个分布与真实分布之间究竟有多大差异。这里的差异就要通过构造损失函数（ loss function ）来估算。知道了这个差异后，就能不断调优一开始的“假设分布”，从而不断逼近真实分布。限制玻尔兹曼机CRBM)就是这种生成模型的一种。然而，对抗网络可以学习自己的损失函数，无须精心设计和建构一个损失函数，却能达成无监督学习。
生成网络负责生成，辨别网络负责分辨生成的质量，然后不断的生成与辨别，最后达到效果。通过这种方式，损失函数被蕴含在判别器中了。我们不再需要思考损失函数应该如何设定</p><p>虽然，省去复杂的后验推断过程是GANs相对其他生成模型的优势。但是，早期的GANs 有许多问题，最主要的一项通病是GANs 不稳定“有时候它永远不会开始学习，或者生成我们认为合格的输出。DCGAN 方法对CNN 使用和修改的核心建议如下：</p><blockquote><ul><li>在判别器中用带步长的卷积层（ strided convolutions ）取代的池化层（ pooling layers ） 。在生成器中用小步幅卷积C fractional strided convolutions ）取代的池化层（ pooling layers ） ，达到学习上采样的效果。</li><li>在判别器和生成器中都采用Batch Normalization 批标准化。</li><li>对于较深的网络，移除全连接层。</li><li>在生成器中除了最后输出层，其他每一层输出使用ReLU 激活函数。在最后一层输出，可以使用Tanh 或Sigmoid 等两端饱和的激活函数。</li><li>在判别器中的每一层使用LeakyReLU 激活函数。</li></ul></blockquote><p>以图片为例，在最理想的状态下，G可以生成足以“以假乱真”的图片G(z)。对于D来说，它难以判定G生成的图片究竟是不是真实的，因此D(G(z)) = 0.5。但是实际训练的时候这个状态一般是不可达的。上面的过程使用数学公式来表达：</p><p>$$
\min <em>{G} \max <em>{D} V(D, G)=\mathbb{E}</em>{\boldsymbol{x} \sim p</em>{\text {data }}(\boldsymbol{x})}[\log D(\boldsymbol{x})]+\mathbb{E}<em>{\boldsymbol{z} \sim p</em>{\boldsymbol{z}}(\boldsymbol{z})}[\log (1-D(G(\boldsymbol{z})))]
$$
分析这个公式：</p><ul><li>$x$表示真实输入</li><li>$z$表示输入G网络的噪声</li><li>$G(z)$表示G网络生成</li><li>$D(x)$表示D网络判断真实图片是否真实的概率（因为x就是真实的，所以对于D来说，这个值越接近1越好）。</li><li>$D(G(z))$是D网络判断G生成的图片的是否真实的概率</li><li>G希望$D(G(z))$尽可能得大，这时$V(D, G)$会变小。因此我们看到式子的最前面的记号是$min_G$</li><li>D希望$D(x)$越大，$D(G(z))$越小。这时$V(D,G)$会变大。因此式子对于D来说是求最大$max_D$</li></ul><p><img src=/imgs/img-lazy-loading.gif data-src=https://upload-images.jianshu.io/upload_images/18339009-75e67a26a46d195e.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 alt>
<img src=/imgs/img-lazy-loading.gif data-src=https://upload-images.jianshu.io/upload_images/18339009-8b283271ff4406f8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 alt></p><p><img src=/imgs/img-lazy-loading.gif data-src=https://upload-images.jianshu.io/upload_images/18339009-830ecc6f5c3368d8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 alt>
<img src=/imgs/img-lazy-loading.gif data-src=https://upload-images.jianshu.io/upload_images/18339009-f1d24ed94706abc3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 alt></p><p>需要注意的是，整个GAN的整个过程都是无监督的
这里，给的真图是没有经过人工标注的，而系统里的D并不知道来的图片是什么玩意儿，它只需要分辨真假。G也不知道自己生成的是什么，反正就是学真图片的样子骗D。
正由于GAN的无监督，在生成过程中，G就会按照自己的意思天马行空生成一些“诡异”的图片，可怕的是D还能给一个很高的分数。</p><h3 id=用keras实现gan识别mnisthttpsgithubcomdingtompythonblobmastergan_mnist_keras201ipynb><a href=https://github.com/dingtom/python/blob/master/GAN_MNIST_Keras%20%281%29.ipynb title=用keras实现GAN识别MNIST rel="noopener external nofollow noreferrer" target=_blank class=exturl>用keras实现GAN识别MNIST
<i class="fa fa-external-link-alt"></i></a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>import tensorflow as tf
</span></span><span style=display:flex><span>import numpy as np
</span></span><span style=display:flex><span>import matplotlib.pyplot as plt
</span></span><span style=display:flex><span>import sys
</span></span><span style=display:flex><span>from tensorflow import keras
</span></span><span style=display:flex><span>from tensorflow.keras.datasets import mnist
</span></span><span style=display:flex><span>from tensorflow.keras.models import Model
</span></span><span style=display:flex><span>from tensorflow.keras.optimizers import Adam
</span></span><span style=display:flex><span>from tensorflow.keras.layers import *
</span></span><span style=display:flex><span>import tensorflow as tf
</span></span><span style=display:flex><span>import numpy as np
</span></span><span style=display:flex><span>import matplotlib.pyplot as plt
</span></span><span style=display:flex><span>import sys
</span></span><span style=display:flex><span>from tensorflow import keras
</span></span><span style=display:flex><span>from tensorflow.keras.datasets import mnist
</span></span><span style=display:flex><span>from tensorflow.keras.models import Model
</span></span><span style=display:flex><span>from tensorflow.keras.optimizers import Adam
</span></span><span style=display:flex><span>from tensorflow.keras.layers import *
</span></span><span style=display:flex><span>class GAN():
</span></span><span style=display:flex><span>    def __init__(self):
</span></span><span style=display:flex><span>        self.img_rows = 28
</span></span><span style=display:flex><span>        self.img_cols = 28
</span></span><span style=display:flex><span>        self.channels = 1
</span></span><span style=display:flex><span>        self.img_shape = (self.img_rows, self.img_cols, self.channels)
</span></span><span style=display:flex><span>        self.latent_dim = 100
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        # -----------------------创建编译 discriminator 训练D----------------------------
</span></span><span style=display:flex><span>        self.discriminator = self.build_discriminator()
</span></span><span style=display:flex><span>        self.discriminator.compile(loss=&#39;binary_crossentropy&#39;,
</span></span><span style=display:flex><span>                                   optimizer=Adam(0.0002, 0.5),
</span></span><span style=display:flex><span>                                   metrics=[&#39;accuracy&#39;])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        # ------------------------创建编译  DG 联合模型 训练G,inputs=z, outputs=label--------
</span></span><span style=display:flex><span>        z = Input(shape=(self.latent_dim,))
</span></span><span style=display:flex><span>        self.generator = self.build_generator()
</span></span><span style=display:flex><span>        img = self.generator(z)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        # DG 联合模型在训练时discriminator不需训练
</span></span><span style=display:flex><span>        # 只会关闭self.combined中discriminator的训练，之前的discriminator已经compile了，
</span></span><span style=display:flex><span>        # 不影响discriminator单独训练。
</span></span><span style=display:flex><span>        self.discriminator.trainable = False  
</span></span><span style=display:flex><span>        label = self.discriminator(img)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        self.combined = Model(inputs=z, outputs=label)
</span></span><span style=display:flex><span>        self.combined.summary()
</span></span><span style=display:flex><span>        self.combined.compile(loss=&#39;binary_crossentropy&#39;,
</span></span><span style=display:flex><span>                              optimizer=Adam(0.0002, 0.5))
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>    # 输入长为100的噪声，返回28*28图像
</span></span><span style=display:flex><span>    def build_generator(self):
</span></span><span style=display:flex><span>        noises = Input(shape=(self.latent_dim,))
</span></span><span style=display:flex><span>        l = Dense(256, input_dim=self.latent_dim)(noises)
</span></span><span style=display:flex><span>        l = LeakyReLU(alpha=0.2)(l)
</span></span><span style=display:flex><span>        l = BatchNormalization(momentum=0.8)(l)
</span></span><span style=display:flex><span>        l = Dense(512)(l)
</span></span><span style=display:flex><span>        l = LeakyReLU(alpha=0.2)(l)
</span></span><span style=display:flex><span>        l = BatchNormalization(momentum=0.8)(l)
</span></span><span style=display:flex><span>        l = Dense(1024)(l)
</span></span><span style=display:flex><span>        l = LeakyReLU(alpha=0.2)(l)
</span></span><span style=display:flex><span>        l = BatchNormalization(momentum=0.8)(l)
</span></span><span style=display:flex><span>        l = Dense(np.prod(self.img_shape), activation=&#39;tanh&#39;)(l)
</span></span><span style=display:flex><span>        imgs = Reshape(self.img_shape)(l)
</span></span><span style=display:flex><span>        return Model(inputs=noises, outputs=imgs)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    # 输入28*28图像，返回0/1标签
</span></span><span style=display:flex><span>    def build_discriminator(self):
</span></span><span style=display:flex><span>        imgs = Input(shape=self.img_shape)
</span></span><span style=display:flex><span>        l = Flatten(input_shape=self.img_shape)(imgs)
</span></span><span style=display:flex><span>        l = Dense(512)(l)
</span></span><span style=display:flex><span>        l = LeakyReLU(alpha=0.2)(l)
</span></span><span style=display:flex><span>        l = Dense(256)(l)
</span></span><span style=display:flex><span>        l = LeakyReLU(alpha=0.2)(l)
</span></span><span style=display:flex><span>        labels = Dense(1, activation=&#39;sigmoid&#39;)(l)
</span></span><span style=display:flex><span>        return Model(inputs=imgs, outputs=labels)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    def train(self, epochs, batch_size=128, sample_interval=50):
</span></span><span style=display:flex><span>        # 加载数据
</span></span><span style=display:flex><span>        (x_train, y_train), (x_test, y_test) = mnist.load_data()
</span></span><span style=display:flex><span>        # 归一化 -1 to 1
</span></span><span style=display:flex><span>        x_train = x_train/127.5-1.
</span></span><span style=display:flex><span>        # (60000, 28, 28)   ---&gt;  (60000, 28, 28, 1)
</span></span><span style=display:flex><span>        x_train = np.expand_dims(x_train, axis=3)
</span></span><span style=display:flex><span>        # 生成照片的标签真1假0
</span></span><span style=display:flex><span>        real_label = np.ones((batch_size, 1))
</span></span><span style=display:flex><span>        fake_label = np.zeros((batch_size, 1))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        for epoch in range(epochs):
</span></span><span style=display:flex><span>            &#34;&#34;&#34;
</span></span><span style=display:flex><span>            GAN的训练在同一轮梯度反传的过程中可以细分为2步，先训练D在训练G；
</span></span><span style=display:flex><span>            注意不是等所有的D训练好以后，才开始训练G，
</span></span><span style=display:flex><span>            因为D的训练也需要上一轮梯度反传中G的输出值作为输入。
</span></span><span style=display:flex><span>            &#34;&#34;&#34;
</span></span><span style=display:flex><span>            # ---------------------训练 Discriminator---------------------
</span></span><span style=display:flex><span>            &#34;&#34;&#34;
</span></span><span style=display:flex><span>            当训练D的时候，上一轮G产生的新图片，和真实图片，直接拼接在一起，作为x。
</span></span><span style=display:flex><span>            然后根据，按顺序摆放0和1假图对应0，真图对应1。
</span></span><span style=display:flex><span>            然后就可以通过，x输入生成一个score（从0到1之间的数），通过score和y组成的损失函数，
</span></span><span style=display:flex><span>            就可以进行梯度反传了。
</span></span><span style=display:flex><span>            &#34;&#34;&#34;
</span></span><span style=display:flex><span>            # 随机选择一个batch 照片训练
</span></span><span style=display:flex><span>            index = np.random.randint(0, x_train.shape[0], batch_size)
</span></span><span style=display:flex><span>            real_imgs = x_train[index]
</span></span><span style=display:flex><span>            # 生成一个batch假照片
</span></span><span style=display:flex><span>            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))
</span></span><span style=display:flex><span>            fake_imgs = self.generator.predict(noise)
</span></span><span style=display:flex><span>            # 开始训练
</span></span><span style=display:flex><span>            d_loss_real = self.discriminator.train_on_batch(real_imgs, real_label)  
</span></span><span style=display:flex><span>            # train_on_batch 返回compile里的 loss and metrics
</span></span><span style=display:flex><span>            d_loss_fake = self.discriminator.train_on_batch(fake_imgs, fake_label)  
</span></span><span style=display:flex><span>            # d_loss_fake [0.7735841, 0.0625]
</span></span><span style=display:flex><span>            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)  
</span></span><span style=display:flex><span>            # d_loss [0.7576531 0.21875  ]  D_loss Acc
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            # ---------------------训练 DG模型---------------------
</span></span><span style=display:flex><span>            &#34;&#34;&#34;
</span></span><span style=display:flex><span>            当训练G的时候， 需要把G和D当作一个整体。这个整体(下面简称DG系统)的输出仍然是score。
</span></span><span style=display:flex><span>            输入一组随机向量，就可以在G生成一张图，通过D对生成的这张图进行打分， 这就是DG系统的前向过程。
</span></span><span style=display:flex><span>            score=1就是DG系统需要优化的目标， score和y=1之间的差异可以组成损失函数，然后可以反向传播梯度。
</span></span><span style=display:flex><span>            注意，这里的D的参数是不可训练的。这样就能保证G的训练是符合D的打分标准的。
</span></span><span style=display:flex><span>            这就好比：如果你参加考试，你别指望能改变老师的评分标准&#34;&#34;&#34;
</span></span><span style=display:flex><span>            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))
</span></span><span style=display:flex><span>            g_loss = self.combined.train_on_batch(noise, real_label)  
</span></span><span style=display:flex><span>            # g_loss 0.63344437
</span></span><span style=display:flex><span>            if epoch % 100 == 0:
</span></span><span style=display:flex><span>                print (&#34;epoch:{}， D_Acc:{}，D_loss:{}，G_loss:{}&#34; .format(
</span></span><span style=display:flex><span>                          epoch, 100*d_loss[1], d_loss[0], g_loss))
</span></span><span style=display:flex><span>            if epoch % sample_interval == 0:
</span></span><span style=display:flex><span>                self.show_images(epoch)
</span></span><span style=display:flex><span>                
</span></span><span style=display:flex><span>        self.combined.save(&#39;all_model.h5&#39;)
</span></span><span style=display:flex><span>    def show_images(self, epoch):
</span></span><span style=display:flex><span>        row, column = 5, 5
</span></span><span style=display:flex><span>        noise = np.random.normal(0, 1, (row*column, self.latent_dim))
</span></span><span style=display:flex><span>        fake_imgs = self.generator.predict(noise)
</span></span><span style=display:flex><span>        # Rescale images 0 - 1
</span></span><span style=display:flex><span>        fake_imgs = 0.5*fake_imgs+0.5
</span></span><span style=display:flex><span>        fig, axs = plt.subplots(row, column)
</span></span><span style=display:flex><span>        counter = 0
</span></span><span style=display:flex><span>        for i in range(row):
</span></span><span style=display:flex><span>            for j in range(column):
</span></span><span style=display:flex><span>                axs[i,j].imshow(fake_imgs[counter, :, :, 0], cmap=&#39;gray&#39;)
</span></span><span style=display:flex><span>                axs[i,j].axis(&#39;off&#39;)
</span></span><span style=display:flex><span>                counter += 1
</span></span><span style=display:flex><span>        # fig.savefig(&#34;images/{}.png&#34;.format(epoch))
</span></span><span style=display:flex><span>        plt.show()
</span></span><span style=display:flex><span>        plt.close()
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>if __name__ == &#39;__main__&#39;:
</span></span><span style=display:flex><span>    gan = GAN()
</span></span><span style=display:flex><span>    gan.train(epochs=10000, batch_size=1024, sample_interval=1000)
</span></span></code></pre></div><h3 id=tensorflow实现gan识别mnisthttpsgithubcomdingtompythonblobmastergan_mnist_tensorflow201ipynb><a href=https://github.com/dingtom/python/blob/master/GAN_MNIST_Tensorflow%20%281%29.ipynb title=Tensorflow实现GAN识别MNIST rel="noopener external nofollow noreferrer" target=_blank class=exturl>Tensorflow实现GAN识别MNIST
<i class="fa fa-external-link-alt"></i></a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>import tensorflow as tf
</span></span><span style=display:flex><span>import numpy as np
</span></span><span style=display:flex><span>import matplotlib.pyplot as plt
</span></span><span style=display:flex><span>import sys
</span></span><span style=display:flex><span>from tensorflow import keras
</span></span><span style=display:flex><span>from tensorflow.keras.datasets import mnist
</span></span><span style=display:flex><span>from tensorflow.keras.models import Model
</span></span><span style=display:flex><span>from tensorflow.keras.optimizers import Adam
</span></span><span style=display:flex><span>from tensorflow.keras.layers import *
</span></span><span style=display:flex><span>class GAN():
</span></span><span style=display:flex><span>    def __init__(self):
</span></span><span style=display:flex><span>        self.img_rows = 28
</span></span><span style=display:flex><span>        self.img_cols = 28
</span></span><span style=display:flex><span>        self.channels = 1
</span></span><span style=display:flex><span>        self.img_shape = (self.img_rows, self.img_cols, self.channels)
</span></span><span style=display:flex><span>        self.latent_dim = 100
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        # -----------------------创建编译 discriminator 训练D----------------------------
</span></span><span style=display:flex><span>        self.discriminator = self.build_discriminator()
</span></span><span style=display:flex><span>        self.discriminator.compile(loss=&#39;binary_crossentropy&#39;,
</span></span><span style=display:flex><span>                                   optimizer=Adam(0.0002, 0.5),
</span></span><span style=display:flex><span>                                   metrics=[&#39;accuracy&#39;])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        # ------------------------创建编译  DG 联合模型 训练G,inputs=z, outputs=label--------
</span></span><span style=display:flex><span>        z = Input(shape=(self.latent_dim,))
</span></span><span style=display:flex><span>        self.generator = self.build_generator()
</span></span><span style=display:flex><span>        img = self.generator(z)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        # DG 联合模型在训练时discriminator不需训练
</span></span><span style=display:flex><span>        # 只会关闭self.combined中discriminator的训练，之前的discriminator已经compile了，
</span></span><span style=display:flex><span>        # 不影响discriminator单独训练。
</span></span><span style=display:flex><span>        self.discriminator.trainable = False  
</span></span><span style=display:flex><span>        label = self.discriminator(img)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        self.combined = Model(inputs=z, outputs=label)
</span></span><span style=display:flex><span>        self.combined.summary()
</span></span><span style=display:flex><span>        self.combined.compile(loss=&#39;binary_crossentropy&#39;,
</span></span><span style=display:flex><span>                              optimizer=Adam(0.0002, 0.5))
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>    # 输入长为100的噪声，返回28*28图像
</span></span><span style=display:flex><span>    def build_generator(self):
</span></span><span style=display:flex><span>        noises = Input(shape=(self.latent_dim,))
</span></span><span style=display:flex><span>        l = Dense(256, input_dim=self.latent_dim)(noises)
</span></span><span style=display:flex><span>        l = LeakyReLU(alpha=0.2)(l)
</span></span><span style=display:flex><span>        l = BatchNormalization(momentum=0.8)(l)
</span></span><span style=display:flex><span>        l = Dense(512)(l)
</span></span><span style=display:flex><span>        l = LeakyReLU(alpha=0.2)(l)
</span></span><span style=display:flex><span>        l = BatchNormalization(momentum=0.8)(l)
</span></span><span style=display:flex><span>        l = Dense(1024)(l)
</span></span><span style=display:flex><span>        l = LeakyReLU(alpha=0.2)(l)
</span></span><span style=display:flex><span>        l = BatchNormalization(momentum=0.8)(l)
</span></span><span style=display:flex><span>        l = Dense(np.prod(self.img_shape), activation=&#39;tanh&#39;)(l)
</span></span><span style=display:flex><span>        imgs = Reshape(self.img_shape)(l)
</span></span><span style=display:flex><span>        return Model(inputs=noises, outputs=imgs)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    # 输入28*28图像，返回0/1标签
</span></span><span style=display:flex><span>    def build_discriminator(self):
</span></span><span style=display:flex><span>        imgs = Input(shape=self.img_shape)
</span></span><span style=display:flex><span>        l = Flatten(input_shape=self.img_shape)(imgs)
</span></span><span style=display:flex><span>        l = Dense(512)(l)
</span></span><span style=display:flex><span>        l = LeakyReLU(alpha=0.2)(l)
</span></span><span style=display:flex><span>        l = Dense(256)(l)
</span></span><span style=display:flex><span>        l = LeakyReLU(alpha=0.2)(l)
</span></span><span style=display:flex><span>        labels = Dense(1, activation=&#39;sigmoid&#39;)(l)
</span></span><span style=display:flex><span>        return Model(inputs=imgs, outputs=labels)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    def train(self, epochs, batch_size=128, sample_interval=50):
</span></span><span style=display:flex><span>        # 加载数据
</span></span><span style=display:flex><span>        (x_train, y_train), (x_test, y_test) = mnist.load_data()
</span></span><span style=display:flex><span>        # 归一化 -1 to 1
</span></span><span style=display:flex><span>        x_train = x_train/127.5-1.
</span></span><span style=display:flex><span>        # (60000, 28, 28)   ---&gt;  (60000, 28, 28, 1)
</span></span><span style=display:flex><span>        x_train = np.expand_dims(x_train, axis=3)
</span></span><span style=display:flex><span>        # 生成照片的标签真1假0
</span></span><span style=display:flex><span>        real_label = np.ones((batch_size, 1))
</span></span><span style=display:flex><span>        fake_label = np.zeros((batch_size, 1))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        for epoch in range(epochs):
</span></span><span style=display:flex><span>            &#34;&#34;&#34;
</span></span><span style=display:flex><span>            GAN的训练在同一轮梯度反传的过程中可以细分为2步，先训练D在训练G；
</span></span><span style=display:flex><span>            注意不是等所有的D训练好以后，才开始训练G，
</span></span><span style=display:flex><span>            因为D的训练也需要上一轮梯度反传中G的输出值作为输入。
</span></span><span style=display:flex><span>            &#34;&#34;&#34;
</span></span><span style=display:flex><span>            # ---------------------训练 Discriminator---------------------
</span></span><span style=display:flex><span>            &#34;&#34;&#34;
</span></span><span style=display:flex><span>            当训练D的时候，上一轮G产生的新图片，和真实图片，直接拼接在一起，作为x。
</span></span><span style=display:flex><span>            然后根据，按顺序摆放0和1假图对应0，真图对应1。
</span></span><span style=display:flex><span>            然后就可以通过，x输入生成一个score（从0到1之间的数），通过score和y组成的损失函数，
</span></span><span style=display:flex><span>            就可以进行梯度反传了。
</span></span><span style=display:flex><span>            &#34;&#34;&#34;
</span></span><span style=display:flex><span>            # 随机选择一个batch 照片训练
</span></span><span style=display:flex><span>            index = np.random.randint(0, x_train.shape[0], batch_size)
</span></span><span style=display:flex><span>            real_imgs = x_train[index]
</span></span><span style=display:flex><span>            # 生成一个batch假照片
</span></span><span style=display:flex><span>            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))
</span></span><span style=display:flex><span>            fake_imgs = self.generator.predict(noise)
</span></span><span style=display:flex><span>            # 开始训练
</span></span><span style=display:flex><span>            d_loss_real = self.discriminator.train_on_batch(real_imgs, real_label)  
</span></span><span style=display:flex><span>            # train_on_batch 返回compile里的 loss and metrics
</span></span><span style=display:flex><span>            d_loss_fake = self.discriminator.train_on_batch(fake_imgs, fake_label)  
</span></span><span style=display:flex><span>            # d_loss_fake [0.7735841, 0.0625]
</span></span><span style=display:flex><span>            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)  
</span></span><span style=display:flex><span>            # d_loss [0.7576531 0.21875  ]  D_loss Acc
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            # ---------------------训练 DG模型---------------------
</span></span><span style=display:flex><span>            &#34;&#34;&#34;
</span></span><span style=display:flex><span>            当训练G的时候， 需要把G和D当作一个整体。这个整体(下面简称DG系统)的输出仍然是score。
</span></span><span style=display:flex><span>            输入一组随机向量，就可以在G生成一张图，通过D对生成的这张图进行打分， 这就是DG系统的前向过程。
</span></span><span style=display:flex><span>            score=1就是DG系统需要优化的目标， score和y=1之间的差异可以组成损失函数，然后可以反向传播梯度。
</span></span><span style=display:flex><span>            注意，这里的D的参数是不可训练的。这样就能保证G的训练是符合D的打分标准的。
</span></span><span style=display:flex><span>            这就好比：如果你参加考试，你别指望能改变老师的评分标准&#34;&#34;&#34;
</span></span><span style=display:flex><span>            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))
</span></span><span style=display:flex><span>            g_loss = self.combined.train_on_batch(noise, real_label)  
</span></span><span style=display:flex><span>            # g_loss 0.63344437
</span></span><span style=display:flex><span>            if epoch % 100 == 0:
</span></span><span style=display:flex><span>                print (&#34;epoch:{}， D_Acc:{}，D_loss:{}，G_loss:{}&#34; .format(
</span></span><span style=display:flex><span>                          epoch, 100*d_loss[1], d_loss[0], g_loss))
</span></span><span style=display:flex><span>            if epoch % sample_interval == 0:
</span></span><span style=display:flex><span>                self.show_images(epoch)
</span></span><span style=display:flex><span>                
</span></span><span style=display:flex><span>        self.combined.save(&#39;all_model.h5&#39;)
</span></span><span style=display:flex><span>    def show_images(self, epoch):
</span></span><span style=display:flex><span>        row, column = 5, 5
</span></span><span style=display:flex><span>        noise = np.random.normal(0, 1, (row*column, self.latent_dim))
</span></span><span style=display:flex><span>        fake_imgs = self.generator.predict(noise)
</span></span><span style=display:flex><span>        # Rescale images 0 - 1
</span></span><span style=display:flex><span>        fake_imgs = 0.5*fake_imgs+0.5
</span></span><span style=display:flex><span>        fig, axs = plt.subplots(row, column)
</span></span><span style=display:flex><span>        counter = 0
</span></span><span style=display:flex><span>        for i in range(row):
</span></span><span style=display:flex><span>            for j in range(column):
</span></span><span style=display:flex><span>                axs[i,j].imshow(fake_imgs[counter, :, :, 0], cmap=&#39;gray&#39;)
</span></span><span style=display:flex><span>                axs[i,j].axis(&#39;off&#39;)
</span></span><span style=display:flex><span>                counter += 1
</span></span><span style=display:flex><span>        # fig.savefig(&#34;images/{}.png&#34;.format(epoch))
</span></span><span style=display:flex><span>        plt.show()
</span></span><span style=display:flex><span>        plt.close()
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>if __name__ == &#39;__main__&#39;:
</span></span><span style=display:flex><span>    gan = GAN()
</span></span><span style=display:flex><span>    gan.train(epochs=10000, batch_size=1024, sample_interval=1000)
</span></span></code></pre></div><p>参考：
<a href=https://blog.csdn.net/leviopku/article/details/81292192 title=https://blog.csdn.net/leviopku/article/details/81292192 rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://blog.csdn.net/leviopku/article/details/81292192
<i class="fa fa-external-link-alt"></i></a></p></div><footer class=post-footer><div class=addthis_inline_share_toolbox style=text-align:center></div><hr><div class=post-copyright><img src=/imgs/cc/cc.svg width=75 height=75 align=right><ul><li class=post-copyright-title><strong>文章标题：</strong>
ml-生成对抗网络(GAN)</li><li class=post-copyright-author><strong>本文作者：</strong>
Tomding</li><li class=post-copyright-link><strong>本文链接：</strong>
<a id=post-cr-link href=/post/ml-%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9Cgan/ title=ml-生成对抗网络(GAN)>/post/ml-%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9Cgan/</a></li><li class=post-copyright-license><strong>版权声明：</strong>
本博客所有文章除特别声明外，均采用 <i class="fab fa-fw fa-creative-commons"></i><a target=_blank href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class=followme><span>欢迎关注我的其它发布渠道</span><div class=social-list><div class=social-item><a target=_blank class=social-link href=/images/wechat_channel.jpg><span class=icon><i class="fab fa-weixin"></i></span>
<span class=label>WeChat</span></a></div><div class=social-item><a target=_blank class=social-link href=/atom.xml><span class=icon><i class="fa fa-rss"></i></span>
<span class=label>RSS</span></a></div></div></div><div class=post-nav><div class="post-nav-next post-nav-item"><a href=/post/ml-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/ rel=next title=ml-神经网络><i class="fa fa-chevron-left"></i> ml-神经网络</a></div><div class="post-nav-prev post-nav-item"><a href=/post/ml-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9Crnn/ rel=prev title=ml-循环神经网络(RNN)>ml-循环神经网络(RNN)
<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div></main><footer class=footer><div class=footer-inner><div class=copyright>&copy;
<span itemprop=copyrightYear>2010 - 2022</span>
<span class=with-love><i class="fa fa-heart"></i></span>
<span class=author itemprop=copyrightHolder>Tomding</span></div></div></footer><script type=text/javascript src=https://cdn.staticfile.org/animejs/3.2.1/anime.min.js defer></script>
<script type=text/javascript src=https://cdn.staticfile.org/viewerjs/1.11.0/viewer.min.js defer></script>
<script class=next-config data-name=main type=application/json>{"bookmark":{"color":"#222","enable":false,"save":"manual"},"busuanzi":{"pageview":true},"copybtn":true,"darkmode":true,"giscus":{"cfg":{"category":"Comments","categoryid":null,"emit":false,"inputposition":"top","mapping":"title","reactions":false,"repo":"username/repo-name","repoid":null,"theme":"preferred_color_scheme"},"js":"https://giscus.app/client.js"},"hostname":"/","i18n":{"ds_day":" 天前","ds_days":" 天 ","ds_hour":" 小时前","ds_hours":" 小时 ","ds_just":"刚刚","ds_min":" 分钟前","ds_mins":" 分钟","ds_month":" 个月前","ds_years":" 年 ","empty":"没有找到任何搜索结果：${query}","hits":"","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","placeholder":"搜索..."},"lang":"zh-CN","lazyload":false,"localSearch":{"enable":true,"path":"/searchindexes.xml","preload":false,"topnperarticle":-1,"trigger":"auto","unescape":false},"motion":{"async":true,"enable":true,"transition":{"collheader":"fadeInLeft","postblock":"fadeIn","postbody":"fadeInDown","postheader":"fadeInDown","sidebar":"fadeInUp"}},"root":"/","scheme":"Gemini","sidebar":{"display":"post","offset":12,"padding":18,"position":"left","width":256},"statis":{"enable":true,"plugin":"busuanzi"},"vendor":{"plugins":"qiniu","router":"https://cdn.staticfile.org"},"version":"4.4.1","waline":{"cfg":{"comment":true,"emoji":false,"imguploader":false,"pageview":true,"placeholder":"请文明发言哟 ヾ(≧▽≦*)o","reaction":true,"reactiontext":["点赞","踩一下","得意","不屑","尴尬","睡觉"],"reactiontitle":"你认为这篇文章怎么样？","requiredmeta":["nick","mail"],"serverurl":null,"sofa":"快来发表你的意见吧 (≧∀≦)ゞ","wordlimit":200},"css":{"alias":"waline","file":"dist/waline.css","name":"@waline/client","version":"2.13.0"},"js":{"alias":"waline","file":"dist/waline.js","name":"@waline/client","version":"2.13.0"}}}</script><script type=text/javascript src=/js/main.min.e34208af37d3db3a875e6fbad04c2f1c241185af925a9c6ebf79dd1ba2730cdd.js defer></script></body></html>