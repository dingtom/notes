<!doctype html><html lang=zh-cn data-theme=dark><head><meta charset=utf-8><meta name=viewport content="width=device-width"><meta name=theme-color content="#222" media="(prefers-color-scheme: dark)"><meta name=generator content="Hugo 0.107.0"><link rel="shortcut icon" type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=/imgs/icons/favicon_16x16_next.png><link rel=icon type=image/png sizes=32x32 href=/imgs/icons/favicon_32_32_next.png><link rel=apple-touch-icon sizes=180x180 href=/imgs/icons/apple_touch_icon_next.png><meta itemprop=name content="ml-sklearn"><meta itemprop=description content="Love and Peace"><meta itemprop=datePublished zgotmplz><meta itemprop=dateModified zgotmplz><meta itemprop=image content="/imgs/hugo_next_avatar.png"><meta itemprop=keywords content="Hugo,NexT,主题,简单,强大"><meta property="og:type" content="article"><meta property="og:title" content="ml-sklearn"><meta property="og:description" content="Love and Peace"><meta property="og:image" content="/imgs/hugo_next_avatar.png"><meta property="og:image:width" content="312"><meta property="og:image:height" content="312"><meta property="og:image:type" content="image/jpeg/png/svg/jpg"><meta property="og:url" content="/post/ml-sklearn/"><meta property="og:site_name" content="Tomding's Blog"><meta property="og:locale" content="zh-CN"><meta property="article:author" content="Tomding"><meta property="article:published_time" content="2022-12-01 19:59:47 +0800 CST"><meta property="article:modified_time" content="2022-12-01 19:59:47 +0800 CST"><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/font-awesome/6.1.2/css/all.min.css><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/animate.css/3.1.1/animate.min.css><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/viewerjs/1.11.0/viewer.min.css><link rel=stylesheet href=/css/main.min.0ca97083b39f4eda7430d39b99194aa738d8f8db4090f00bc7e814013df699cb.css><style type=text/css>.post-footer,.flinks-list-footer hr:after{content:"~ 我可是有底线的哟 ~"}</style><script type=text/javascript>(function(){localDB={set:function(e,t,n){if(n===0)return;const s=new Date,o=n*864e5,i={value:t,expiry:s.getTime()+o};localStorage.setItem(e,JSON.stringify(i))},get:function(e){const t=localStorage.getItem(e);if(!t)return void 0;const n=JSON.parse(t),s=new Date;return s.getTime()>n.expiry?(localStorage.removeItem(e),void 0):n.value}},theme={active:function(){const e=localDB.get("theme");if(e==null)return;theme.toggle(e),window.matchMedia("(prefers-color-scheme: dark)").addListener(function(e){theme.toggle(e.matches?"dark":"light")})},toggle:function(e){document.documentElement.setAttribute("data-theme",e),localDB.set("theme",e,2);const t=document.querySelector("iframe.giscus-frame");if(t){const n={setConfig:{theme:e}};t.contentWindow.postMessage({giscus:n},"https://giscus.app")}}},theme.active()})(window)</script><script class=next-config data-name=page type=application/json>{"comments":false,"isHome":false,"isPage":true,"path":"ml-sklearn","permalink":"/post/ml-sklearn/","title":"ml-sklearn","waline":{"js":[{"alias":"waline","alias_name":"@waline/client","file":"dist/pageview.js","name":"pageview","version":"2.13.0"},{"alias":"waline","alias_name":"@waline/client","file":"dist/comment.js","name":"comment","version":"2.13.0"}]}}</script><script type=text/javascript>document.addEventListener("DOMContentLoaded",()=>{var e=document.createElement("script");e.charset="UTF-8",e.src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js",e.async=!1,e.defer=!0,document.head.appendChild(e),e.onload=function(){NexT.utils.fmtBusuanzi()}})</script><title>ml-sklearn - Tomding's Blog</title><noscript><link rel=stylesheet href=/css/noscript.css></noscript></head><body itemscope itemtype=http://schema.org/WebPage class=use-motion><div class=headband></div><main class=main><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle aria-label=切换导航栏 role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div></div><div class=site-meta><a href=/ class=brand rel=start><i class=logo-line></i><h1 class=site-title>Tomding's Blog</h1><i class=logo-line></i></a><p class=site-subtitle itemprop=description>Just do it!</p></div><div class=site-nav-right><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href=/ class=hvr-icon-pulse rel=section><i class="fa fa-home hvr-icon"></i>首页</a></li><li class="menu-item menu-item-about"><a href=/about.html class=hvr-icon-pulse rel=section><i class="fa fa-user hvr-icon"></i>关于</a></li><li class="menu-item menu-item-archives"><a href=/archives/ class=hvr-icon-pulse rel=section><i class="fa fa-archive hvr-icon"></i>归档
<span class=badge>72</span></a></li><li class="menu-item menu-item-search"><a role=button class="popup-trigger hvr-icon-pulse"><i class="fa fa-search fa-fw hvr-icon"></i>搜索</a></li></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon><i class="fa fa-search"></i></span><div class=search-input-container><input autocomplete=off autocapitalize=off maxlength=80 placeholder=搜索... spellcheck=false type=search class=search-input></div><span class=popup-btn-close role=button><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class=search-result-icon><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></div><div class="toggle sidebar-toggle" role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div><aside class=sidebar><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>文章目录</li><li class=sidebar-nav-overview>站点概览</li></ul><div class=sidebar-panel-container><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><nav id=TableOfContents><ul><li><ul><li><a href=#多输出的-multioutput>多输出的 multioutput</a></li><li><a href=#选择模型的-model_selection>选择模型的 model_selection</a></li><li><a href=#流水线的-pipeline>流水线的 pipeline</a></li></ul></li></ul><ul><li><ul><li><a href=#11-线性模型>1.1. 线性模型</a></li><li><a href=#12-线性和二次判别分析>1.2. 线性和二次判别分析</a></li><li><a href=#13-内核岭回归>1.3. 内核岭回归</a></li><li><a href=#14-支持向量机>1.4. 支持向量机</a></li><li><a href=#15-随机梯度下降>1.5. 随机梯度下降</a></li><li><a href=#16-最近邻>1.6. 最近邻</a></li><li><a href=#17-高斯过程>1.7. 高斯过程</a></li><li><a href=#18-交叉分解>1.8. 交叉分解</a></li><li><a href=#19-朴素贝叶斯>1.9. 朴素贝叶斯</a></li><li><a href=#110-决策树>1.10. 决策树</a></li><li><a href=#111-集成方法>1.11. 集成方法</a></li><li><a href=#112-多类和多标签算法>1.12. 多类和多标签算法</a></li><li><a href=#113-特征选择>1.13. 特征选择</a></li><li><a href=#114-半监督学习>1.14. 半监督学习</a></li><li><a href=#115-等式回归>1.15. 等式回归</a></li><li><a href=#116-概率校准>1.16. 概率校准</a></li><li><a href=#117-神经网络模型监督的>1.17. 神经网络模型（监督的）</a></li></ul></li></ul><ul><li><ul><li><a href=#21-高斯混合模型>2.1. 高斯混合模型</a></li><li><a href=#22-流形学习>2.2. 流形学习</a></li><li><a href=#23-聚类>2.3. 聚类</a></li><li><a href=#24-双聚类>2.4. 双聚类</a></li><li><a href=#25-分解组件中的信号矩阵分解问题>2.5. 分解组件中的信号（矩阵分解问题）</a></li><li><a href=#26-协方差估计>2.6. 协方差估计</a></li><li><a href=#27-异常值检测>2.7. 异常值检测</a></li><li><a href=#28-密度估算>2.8. 密度估算</a></li><li><a href=#29-神经网络模型无监督>2.9. 神经网络模型（无监督）</a></li></ul></li></ul><ul><li><ul><li><a href=#31-交叉验证评估估算器性能>3.1. 交叉验证：评估估算器性能</a></li><li><a href=#32-调整估算器的超参数>3.2. 调整估算器的超参数</a></li><li><a href=#33-评分量化预测的质量>3.3. 评分：量化预测的质量</a></li><li><a href=#34-模型持久性>3.4. 模型持久性</a></li><li><a href=#35-验证曲线绘制分数以评估模型>3.5. 验证曲线：绘制分数以评估模型</a></li></ul></li></ul><ul><li><ul><li><a href=#41-部分依赖图>4.1. 部分依赖图</a></li><li><a href=#42-排列特征的重要性>4.2. 排列特征的重要性</a></li></ul></li></ul><ul><li><ul><li><a href=#51-可用的绘图实用程序>5.1. 可用的绘图实用程序</a></li></ul></li></ul><ul><li><ul><li><a href=#61-pipeline管道和-复合估计器>6.1. Pipeline（管道）和 复合估计器</a><ul><li></li></ul></li><li><a href=#62-特征提取>6.2. 特征提取</a></li><li><a href=#63-预处理数据>6.3. 预处理数据</a><ul><li></li></ul></li><li><a href=#64-缺失值的插补>6.4. 缺失值的插补</a></li><li><a href=#65-无监督降维>6.5. 无监督降维</a></li><li><a href=#66-随机投影>6.6. 随机投影</a></li><li><a href=#67-内核近似>6.7. 内核近似</a></li><li><a href=#68-成对度量亲和力和内核>6.8. 成对度量，亲和力和内核</a></li><li><a href=#69-转换预测目标y>6.9. 转换预测目标（y）</a></li></ul></li></ul><ul><li><ul><li><a href=#71-通用数据集api>7.1. 通用数据集API</a><ul><li></li></ul></li><li><a href=#72-玩具数据集>7.2. 玩具数据集</a></li><li><a href=#73-现实世界的数据集>7.3. 现实世界的数据集</a></li><li><a href=#74-生成数据集>7.4. 生成数据集</a><ul><li></li></ul></li><li><a href=#75-加载其他数据集>7.5. 加载其他数据集</a></li></ul></li></ul><ul><li><ul><li><a href=#81计算-计算扩展的策略更大的数据>8.1计算. 计算扩展的策略：更大的数据</a></li><li><a href=#82-计算性能>8.2. 计算性能</a></li><li><a href=#83-并行性资源管理和配置>8.3. 并行性，资源管理和配置</a></li></ul></li></ul></nav></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author site-overview-item animated" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image alt=Tomding src=/imgs/img-lazy-loading.gif data-src=/imgs/hugo_next_avatar.png><p class=site-author-name itemprop=name>Tomding</p><div class=site-description itemprop=description>Love and Peace</div></div><div class="site-state-wrap site-overview-item animated"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/><span class=site-state-item-count>72</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>5</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>0</span>
<span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-social site-overview-item animated"><span class=links-of-social-item><a href=https://github.com/ title="Github → https://github.com/" rel=noopener class=hvr-icon-pulse target=_blank><i class="fab fa-github fa-fw hvr-icon"></i>Github</a></span>
<span class=links-of-social-item><a href=https://www.zhihu.com/hot title="知乎 → https://www.zhihu.com/hot" rel=noopener class=hvr-icon-pulse target=_blank><i class="fa fa-book fa-fw hvr-icon"></i>知乎</a></span></div><div class="cc-license animated" itemprop=license><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh class=cc-opacity rel=noopener target=_blank title=共享知识><img src=/imgs/img-lazy-loading.gif data-src=/imgs/cc/big/by_nc_sa.svg alt=共享知识></a></div><div class="links-of-blogroll site-overview-item animated"><div class=links-of-blogroll-title><i class="fa fa-globe fa-fw"></i>友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://gitee.com/hugo-next/hugo-theme-next title=https://gitee.com/hugo-next/hugo-theme-next target=_blank>Hugo-NexT</a></li><li class=links-of-blogroll-item><a href=https://lisenhui.cn title=https://lisenhui.cn target=_blank>凡梦星尘空间站</a></li></ul></div></div></div></div><div id=siteinfo-card-widget class=sidebar-card-widget><div class=item-headline><i class="fas fa-chart-line"></i>
<span>网站资讯</span></div><div class=siteinfo><div class=siteinfo-item><div class=item-name><i class="fa-solid fa-calendar-check"></i>已运行：</div><div class=item-count id=runTimes data-publishdate=2022-12-01T19:59:47+08:00></div></div><div class=siteinfo-item><div class=item-name><i class="fas fa fa-user"></i>总访客数：</div><div class=item-count id=busuanzi_value_site_uv><i class="fa fa-sync fa-spin"></i></div></div><div class=siteinfo-item><div class=item-name><i class="fas fa fa-eye"></i>页面浏览：</div><div class=item-count id=busuanzi_value_site_pv><i class="fa fa-sync fa-spin"></i></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-font"></i>总字数：</div><div class=item-count id=wordsCount data-count=276830></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-mug-hot"></i>阅读约：</div><div class=item-count id=readTimes data-times=590></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-clock-rotate-left"></i>最后更新于：</div><div class=item-count id=last-push-date data-lastpushdate=2022-12-02T03:11:14+08:00></div></div></div></div></aside><div class=sidebar-dimmer></div></header><div class=tool-buttons><div id=toggle-theme class=button title=深浅模式切换><i class="fas fa-adjust"></i></div><div class=back-to-top role=button title=返回顶部><i class="fa fa-arrow-up"></i>
<span>0%</span></div></div><div class=reading-progress-bar></div><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><div class="main-inner post posts-expand"><div class=post-block><article itemscope itemtype=http://schema.org/Article class=post-content lang><link itemprop=mainEntityOfPage href=/post/ml-sklearn/><span hidden itemprop=author itemscope itemtype=http://schema.org/Person><meta itemprop=image content="/imgs/hugo_next_avatar.png"><meta itemprop=name content="Tomding"></span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization><meta itemprop=name content="Tomding"><meta itemprop=description content="Love and Peace"></span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork><meta itemprop=name content="ml-sklearn"><meta itemprop=description content="中文手册 英文手册 在Sklearn当中有三大模型：Transformer 转换器、Estimator 估计器、Pipeline 管道 估计器 (estimator) 可以基于"></span><header class=post-header><h1 class=post-title itemprop="name headline">ml-sklearn
<a href=https://github.com/user-name/repo-name/tree/branch-name/subdirectory-name/post/ml-sklearn.md rel="noopener external nofollow noreferrer" target=_blank class="exturl post-edit-link" title=编辑><i class="fa fa-pen-nib"></i></a></h1><div class=post-meta-container><div class=post-meta-items><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-calendar"></i></span>
<span class=post-meta-item-text>发表于：</span>
<time title="发表于：2022-12-01 19:59:47 +0800 CST" itemprop="dateCreated datePublished" datetime="2022-12-01 19:59:47 +0800 CST">2022-12-01</time></span>
<span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-folder-open"></i></span>
<span class=post-meta-item-text>分类于：</span>
<span itemprop=about itemscope itemtype=http://schema.org/Thing><a href=/categories/ml itemprop=url rel=index><span itemprop=name>ml</span></a></span></span></div><div class=post-meta-items><span class=post-meta-item title=字数><span class=post-meta-item-icon><i class="far fa-file-word"></i></span>
<span class=post-meta-item-text>字数：</span><span>4189</span></span>
<span class=post-meta-item title=阅读><span class=post-meta-item-icon><i class="far fa-clock"></i></span>
<span class=post-meta-item-text>阅读：&ap;</span>
<span>9分钟</span></span>
<span class=post-meta-item title=浏览><span class=post-meta-item-icon><i class="far fa-eye"></i></span>
<span class=post-meta-item-text>浏览：</span>
<span id=busuanzi_value_page_pv class=waline-pageview-count data-path=/post/ml-sklearn/><i class="fa fa-sync fa-spin"></i></span></span></div></div></header><div class="post-body autonumber" itemprop=articleBody><p><a href=https://sklearn.apachecn.org/ title=中文手册 rel="noopener external nofollow noreferrer" target=_blank class=exturl>中文手册
<i class="fa fa-external-link-alt"></i></a>
<a href=https://scikit-learn.org/stable/user_guide.html title=英文手册 rel="noopener external nofollow noreferrer" target=_blank class=exturl>英文手册
<i class="fa fa-external-link-alt"></i></a>
在Sklearn当中有三大模型：Transformer 转换器、Estimator 估计器、Pipeline 管道</p><p><strong>估计器 (estimator)</strong> 可以基于数据集对一些参数进行估计的对象都被称为估计器。
**预测器 (predictor) **在估计器上做了一个延展，延展出预测的功能。
**转换器 (transformer) **也是一种估计器，两者都带拟合功能，但估计器做完拟合来预测，而转换器做完拟合来转换。</p><p>估计器都有 fit() 方法，预测器都有 predict() 和 score() （返回的是分类准确率）方法，言外之意不是每个预测器都有 predict_proba() 和 decision_function() （返回的是每个样例在每个类下的分数值）方法</p><p><strong>管道将Transformer、Estimator 组合起来成为一个大模型。
Transformer放在管道前几个模型中，而Estimator 只能放到管道的最后一个模型中。</strong></p><p>###　多分类和多标签的 multiclass</p><h3 id=多输出的-multioutput>多输出的 multioutput</h3><h3 id=选择模型的-model_selection>选择模型的 model_selection</h3><p>KFold交叉采样：将训练/测试数据集划分n_splits个互斥子集，每次只用其中一个子集当做测试集，剩下的（n_splits-1）作为训练集，进行n_splits次实验并得到n_splits个结果。
注：对于不能均等分的数据集，前n_samples%n_spllits子集拥有n_samples//n_spllits+1个样本，其余子集都只有n_samples//n_spllits个样本。（例10行数据分3份，只有一份可分4行，其他均为3行）</p><p>StratifiedKFold分层采样，用于交叉验证：与KFold最大的差异在于，<strong>StratifiedKFold方法是根据标签中不同类别占比1：1来进行拆分数据的。</strong></p><h3 id=流水线的-pipeline>流水线的 pipeline</h3><h1 id=1监督学习>1.监督学习</h1><h3 id=11-线性模型>1.1. 线性模型</h3><h3 id=12-线性和二次判别分析>1.2. 线性和二次判别分析</h3><h3 id=13-内核岭回归>1.3. 内核岭回归</h3><h3 id=14-支持向量机>1.4. 支持向量机</h3><h3 id=15-随机梯度下降>1.5. 随机梯度下降</h3><h3 id=16-最近邻>1.6. 最近邻</h3><h3 id=17-高斯过程>1.7. 高斯过程</h3><h3 id=18-交叉分解>1.8. 交叉分解</h3><h3 id=19-朴素贝叶斯>1.9. 朴素贝叶斯</h3><h3 id=110-决策树>1.10. 决策树</h3><h3 id=111-集成方法>1.11. 集成方法</h3><ul><li><p><code>AdaBoostClassifier</code>: 逐步提升分类器</p></li><li><p><code>AdaBoostRegressor</code>: 逐步提升回归器</p></li><li><p><code>BaggingClassifier</code>: 装袋分类器</p></li><li><p><code>BaggingRegressor</code>: 装袋回归器</p></li><li><p><code>GradientBoostingClassifier</code>: 梯度提升分类器</p></li><li><p><code>GradientBoostingRegressor</code>: 梯度提升回归器</p></li><li><p><code>RandomForestRegressor</code>: 随机森林回归</p></li><li><p><code>RandomForestClassifier</code>: 随机森林分类器(同质估计器)</p></li><li><p><code>VotingClassifier</code>: 投票分类器(异质估计器)</p></li><li><p><code>VotingRegressor</code>: 投票回归器</p></li></ul><h3 id=112-多类和多标签算法>1.12. 多类和多标签算法</h3><h3 id=113-特征选择>1.13. 特征选择</h3><h3 id=114-半监督学习>1.14. 半监督学习</h3><h3 id=115-等式回归>1.15. 等式回归</h3><h3 id=116-概率校准>1.16. 概率校准</h3><h3 id=117-神经网络模型监督的>1.17. 神经网络模型（监督的）</h3><h1 id=2无监督的学习>2.无监督的学习</h1><h3 id=21-高斯混合模型>2.1. 高斯混合模型</h3><h3 id=22-流形学习>2.2. 流形学习</h3><h3 id=23-聚类>2.3. 聚类</h3><h3 id=24-双聚类>2.4. 双聚类</h3><h3 id=25-分解组件中的信号矩阵分解问题>2.5. 分解组件中的信号（矩阵分解问题）</h3><h3 id=26-协方差估计>2.6. 协方差估计</h3><h3 id=27-异常值检测>2.7. 异常值检测</h3><h3 id=28-密度估算>2.8. 密度估算</h3><h3 id=29-神经网络模型无监督>2.9. 神经网络模型（无监督）</h3><h1 id=3模型选择和评估>3.模型选择和评估</h1><h3 id=31-交叉验证评估估算器性能>3.1. 交叉验证：评估估算器性能</h3><h3 id=32-调整估算器的超参数>3.2. 调整估算器的超参数</h3><p><code>sklearn.model_selection.GridSearchCV(estimator, param_grid, scoring=None, fit_params=None, n_jobs=1, iid=True, refit=True, cv=None, verbose=0, pre_dispatch=‘2*n_jobs’, error_score=’raise’, return_train_score=’warn’)</code></p><ul><li>estimator：所使用的分类器</li><li>param_grid：值为字典或者列表，即需要最优化的参数的取值</li><li>scoring :准确度评价标准，默认None,如果是None，则使用estimator的误差估计函数。scoring参数选择如下：<img src=/imgs/img-lazy-loading.gif data-src=https://upload-images.jianshu.io/upload_images/18339009-8f269477140c5af1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 alt></li><li>cv :交叉验证参数，默认None，也可以是yield训练/测试数据的生成器。</li><li>refit :默认为True,即在搜索参数结束后，用最佳参数结果再次fit一遍全部数据集。</li><li>iid:默认True,为True时，默认为各个样本fold概率分布一致，误差估计为所有样本之和，而非各个fold的平均。</li><li>verbose：，0：不输出训练过程，1：偶尔输出，>1：对每个子模型都输出。</li><li>n_jobs: 并行数-1：跟CPU核数一致, 1:默认值。</li><li>pre_dispatch：指定总共分发的并行任务数。当n_jobs大于1时，数据将在每个运行点进行复制，这可能导致OOM，而设置pre_dispatch参数，则可以预先划分总共的job数量，使数据最多被复制pre_dispatch次</li></ul><p>方法：</p><ul><li>fit（X, y=None, groups=None, **fit_params）：与所有参数组合运行。</li><li>get_params（[deep]）：获取此分类器的参数。</li><li>inverse_transform（Xt）使用找到的最佳参数在分类器上调用inverse_transform。</li><li>predict（X）调用使用最佳找到的参数对估计量进行预测，X：可索引，长度为n_samples；</li><li>score（X, y=None）返回给定数据上的分数，X： [n_samples，n_features]输入数据，其中n_samples是样本的数量，n_features是要素的数量。y： [n_samples]或[n_samples，n_output]，可选，相对于X进行分类或回归; 无无监督学习。</li></ul><p>属性：</p><ul><li>cv_results_ :将键作为列标题和值作为列的字典，可将其导入到pandas DataFrame中。</li><li>best_estimator_ : estimator或dict；由搜索选择的估算器，即在左侧数据上给出最高分数（或者如果指定最小损失）的估算器。 如果refit = False，则不可用。</li><li>best_params_ : 在保持数据上给出最佳结果的参数设置。对于多度量评估，只有在指定了重新指定的情况下才会出现。</li><li>best_score_ : best_estimator的平均交叉验证分数，对于多度量评估，只有在指定了重新指定的情况下才会出现。</li><li>n_splits：交叉验证拆分的数量</li></ul><h3 id=33-评分量化预测的质量>3.3. 评分：量化预测的质量</h3><p>准确率</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>from sklearn import metrics
</span></span><span style=display:flex><span>metrics.accuracy_score(y_test, RF.predict(X_test))
</span></span></code></pre></div><h3 id=34-模型持久性>3.4. 模型持久性</h3><h3 id=35-验证曲线绘制分数以评估模型>3.5. 验证曲线：绘制分数以评估模型</h3><h1 id=4检查>4.检查</h1><h3 id=41-部分依赖图>4.1. 部分依赖图</h3><h3 id=42-排列特征的重要性>4.2. 排列特征的重要性</h3><h1 id=5可视化>5.可视化</h1><h3 id=51-可用的绘图实用程序>5.1. 可用的绘图实用程序</h3><h1 id=6数据集转换>6.数据集转换</h1><h3 id=61-pipeline管道和-复合估计器>6.1. Pipeline（管道）和 复合估计器</h3><h6 id=pipeline>Pipeline</h6><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>from sklearn.pipeline import Pipeline
</span></span><span style=display:flex><span>from sklearn.preprocessing import StandardScaler
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span># evaluate baseline model with standardized dataset
</span></span><span style=display:flex><span>numpy.random.seed(seed)
</span></span><span style=display:flex><span>estimators = []
</span></span><span style=display:flex><span># 标准化的数据传到分类器
</span></span><span style=display:flex><span>estimators.append((&#39;standardize&#39;, StandardScaler()))
</span></span><span style=display:flex><span>estimators.append((&#39;mlp&#39;, KerasClassifier(build_fn=create_baseline, nb_epoch=100,
</span></span><span style=display:flex><span>    batch_size=5, verbose=0)))
</span></span><span style=display:flex><span>pipeline = Pipeline(estimators)
</span></span><span style=display:flex><span>kfold = StratifiedKFold(y=encoded_Y, n_folds=10, shuffle=True, random_state=seed)
</span></span><span style=display:flex><span>results = cross_val_score(pipeline, X, encoded_Y, cv=kfold)
</span></span><span style=display:flex><span>print(&#34;Standardized: %.2f%% (%.2f%%)&#34; % (results.mean()*100, results.std()*100))
</span></span></code></pre></div><h3 id=62-特征提取>6.2. 特征提取</h3><h3 id=63-预处理数据>6.3. 预处理数据</h3><h6 id=onehot>onehot</h6><p><code>OneHotEncoder(n_values=’auto’, categorical_features=’all’, dtype=&lt;class ‘numpy.float64’>, sparse=True, handle_unknown=’error’)</code></p><p><code>n_values=’auto’</code>表示每个特征使用几维的数值来表示。
<code>categorical_features = 'all'</code>指定了对哪些特征进行编码，默认对所有类别都进行编码。
<code>dtype=&lt;class ‘numpy.float64’></code> 表示编码数值格式，默认是浮点型。
<code>sparse=True</code> 表示编码的格式，默认为 True，即为稀疏的格式，指定 False 则就不用 toarray() 了
<code>handle_unknown=’error’</code>其值可以指定为 &ldquo;error&rdquo; 或者 &ldquo;ignore&rdquo;，即如果碰到未知的类别，是返回一个错误还是忽略它。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>from sklearn.preprocessing import  OneHotEncoder
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>enc = OneHotEncoder()
</span></span><span style=display:flex><span>enc.fit([[0, 0, 3],
</span></span><span style=display:flex><span>         [1, 1, 0],
</span></span><span style=display:flex><span>         [0, 2, 1],
</span></span><span style=display:flex><span>         [1, 0, 2]])
</span></span><span style=display:flex><span># 如果不加 toarray() 的话，输出的是稀疏的存储格式，即索引加值的形式，
</span></span><span style=display:flex><span># 也可以通过参数指定 sparse = False 来达到同样的效果
</span></span><span style=display:flex><span>ans = enc.transform([[0, 1, 3]]).toarray()  
</span></span><span style=display:flex><span>print(ans) 
</span></span><span style=display:flex><span># 输出 [[ 1.  0.  0.  1.  0.  0.  0.  0.  1.]]
</span></span></code></pre></div><p>把每一行当作一个样本，每一列当作一个特征</p><p>第一个特征有两个取值 0 或者 1，那么 one-hot 就会使用两位来表示这个特征，[1,0] 表示 0， [0,1] 表示 1，
第二列 [0,1,2,0]，它有三种值，那么 one-hot 就会使用三位来表示这个特征，[1,0,0] 表示 0， [0,1,0] 表示 1，[0,0,1] 表示 2，
第三列 [3,0,1,2]，它有四种值，那么 one-hot 就会使用四位来表示这个特征，[1,0,0,0] 表示 0， [0,1,0,0] 表示 1，[0,0,1,0] 表示 2，[0,0,0,1] 表示 3</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>enc = OneHotEncoder(n_values = [2, 3, 4])
</span></span><span style=display:flex><span>enc.fit([[0, 0, 3],
</span></span><span style=display:flex><span>         [1, 1, 0]])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ans = enc.transform([[0, 2, 3]]).toarray()
</span></span><span style=display:flex><span>print(ans) # 输出 [[ 1.  0.  0.  0.  1.  0.  0.  0.  1.]]
</span></span></code></pre></div><p>注意到训练样本中第二个特征列没有类别 2，但是结果中依然将类别 2 给编码了出来，这就是自己指定维数的作用了（我们使用 3 位来表示第二个特征，自然包括了类别 2），第三列特征同样如此。这也告诫我们，<strong>如果训练样本中有丢失的分类特征值，我们就必须显示地设置参数 n_values 了，这样防止编码出错。</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>from sklearn.preprocessing import  OneHotEncoder
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>enc = OneHotEncoder(categorical_features = [0,2]) 
</span></span><span style=display:flex><span># 等价于 [True, False, True]
</span></span><span style=display:flex><span>enc.fit([[0, 0, 3],
</span></span><span style=display:flex><span>         [1, 1, 0],
</span></span><span style=display:flex><span>         [0, 2, 1],
</span></span><span style=display:flex><span>         [1, 0, 2]])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>ans = enc.transform([[0, 2, 3]]).toarray()
</span></span><span style=display:flex><span>print(ans) # 输出 [[ 1.  0.  0.  0.  0.  1.  2.]]
</span></span></code></pre></div><p>输出结果中前两位 [1,0] 表示 0，中间四位 [0,0,0,1] 表示对第三个特征 3 编码，第二个特征 2 没有进行编码，就放在最后一位。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>from sklearn.preprocessing import  OneHotEncoder
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>enc = OneHotEncoder(sparse = False) 
</span></span><span style=display:flex><span>ans = enc.fit_transform([[0, 0, 3],
</span></span><span style=display:flex><span>                         [1, 1, 0],
</span></span><span style=display:flex><span>                         [0, 2, 1],
</span></span><span style=display:flex><span>                         [1, 0, 2]])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>print(ans) 
</span></span><span style=display:flex><span># 输出 [[ 1.  0.  1. ...,  0.  0.  1.]
</span></span><span style=display:flex><span>#      [ 0.  1.  0. ...,  0.  0.  0.]
</span></span><span style=display:flex><span>#      [ 1.  0.  0. ...,  1.  0.  0.]
</span></span><span style=display:flex><span>#      [ 0.  1.  1. ...,  0.  1.  0.]]
</span></span></code></pre></div><h6 id=类别转换为数字>类别转换为数字</h6><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span># encode class values as integers
</span></span><span style=display:flex><span>encoder = LabelEncoder()
</span></span><span style=display:flex><span>encoder.fit(Y)
</span></span><span style=display:flex><span>encoded_Y = encoder.transform(Y)
</span></span></code></pre></div><h6 id=练集测试集划分>练集测试集划分</h6><p><code>X_train,X_test, y_train, y_test =sklearn.model_selection.train_test_split(train_data,train_target,test_size=0.4, random_state=0,stratify=y_train)</code></p><h3 id=64-缺失值的插补>6.4. 缺失值的插补</h3><h3 id=65-无监督降维>6.5. 无监督降维</h3><h3 id=66-随机投影>6.6. 随机投影</h3><h3 id=67-内核近似>6.7. 内核近似</h3><h3 id=68-成对度量亲和力和内核>6.8. 成对度量，亲和力和内核</h3><h3 id=69-转换预测目标y>6.9. 转换预测目标（y）</h3><h1 id=7数据集加载实用程序>7.数据集加载实用程序</h1><p>打包好的数据：对于小数据集，用 sklearn.datasets.load_*</p><p>分流下载数据：对于大数据集，用 sklearn.datasets.fetch_*</p><p>随机创建数据：为了快速展示，用 sklearn.datasets.make_*</p><h3 id=71-通用数据集api>7.1. 通用数据集API</h3><h6 id=1分类>1.分类</h6><p>手写数字数据集：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>from sklearn.datasets import load_digits
</span></span><span style=display:flex><span>digits = load_digits(n_class=5)  # 只加载0-4
</span></span><span style=display:flex><span>print(digits.data.shape, digits.target.shape, digits.target_names)  
</span></span></code></pre></div><p>(901, 64) (901,) [0 1 2 3 4 5 6 7 8 9]</p><p>线鸢尾花数据集：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>from sklearn.datasets import load_iris
</span></span><span style=display:flex><span>iris = load_iris()
</span></span><span style=display:flex><span>print(iris.data.shape, iris.target.shape, iris.feature_names, iris.target_names)  
</span></span></code></pre></div><p>(150, 4) (150,) [&lsquo;sepal length (cm)&rsquo;, &lsquo;sepal width (cm)&rsquo;, &lsquo;petal length (cm)&rsquo;, &lsquo;petal width (cm)&rsquo;] [&lsquo;setosa&rsquo; &lsquo;versicolor&rsquo; &lsquo;virginica&rsquo;]</p><p>乳腺癌数据集：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>from sklearn.datasets import load_breast_cancer
</span></span><span style=display:flex><span>bc = load_breast_cancer()
</span></span><span style=display:flex><span>print(bc.data.shape, bc.target.shape, bc.feature_names, bc.target_names)  
</span></span></code></pre></div><p>(569, 30) (569,) [&lsquo;mean radius&rsquo; &lsquo;mean texture&rsquo; &mldr;][&lsquo;malignant&rsquo; &lsquo;benign&rsquo;]</p><h6 id=2回归>2.回归</h6><p>糖尿病数据集：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>from sklearn.datasets import load_diabetes
</span></span><span style=display:flex><span>diabetes = load_diabetes()
</span></span><span style=display:flex><span>print(diabetes.data.shape, diabetes.target.shape, diabetes.feature_names) 
</span></span></code></pre></div><p>(442, 10) (442,) [&lsquo;age&rsquo;, &lsquo;sex&rsquo;, &lsquo;bmi&rsquo;, &lsquo;bp&rsquo;, &lsquo;s1&rsquo;, &lsquo;s2&rsquo;, &lsquo;s3&rsquo;, &lsquo;s4&rsquo;, &lsquo;s5&rsquo;, &lsquo;s6&rsquo;] Average blood pressure</p><p>波士顿房价数据集：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>from sklearn.datasets import load_boston
</span></span><span style=display:flex><span>boston = load_boston()
</span></span><span style=display:flex><span>print(boston.data.shape, boston.target.shape, boston.feature_names)  
</span></span></code></pre></div><p>(506, 13) (506,) [&lsquo;CRIM&rsquo; &lsquo;ZN&rsquo; &lsquo;INDUS&rsquo; &lsquo;CHAS&rsquo; &lsquo;NOX&rsquo; &lsquo;RM&rsquo; &lsquo;AGE&rsquo; &lsquo;DIS&rsquo; &lsquo;RAD&rsquo; &lsquo;TAX&rsquo; &lsquo;PTRATIO&rsquo; &lsquo;B&rsquo; &lsquo;LSTAT&rsquo;]</p><h6 id=3多标签回归>3.多标签回归</h6><p>体能训练数据集：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>from sklearn.datasets import load_linnerud
</span></span><span style=display:flex><span>linnerud = load_linnerud()
</span></span><span style=display:flex><span>print(linnerud.data.shape, linnerud.target.shape, linnerud.target_names, linnerud.feature_names)  
</span></span></code></pre></div><p>(20, 3) (20, 3) [&lsquo;Weight&rsquo;, &lsquo;Waist&rsquo;, &lsquo;Pulse&rsquo;] [&lsquo;Chins&rsquo;, &lsquo;Situps&rsquo;, &lsquo;Jumps&rsquo;]</p><h3 id=72-玩具数据集>7.2. 玩具数据集</h3><h3 id=73-现实世界的数据集>7.3. 现实世界的数据集</h3><h3 id=74-生成数据集>7.4. 生成数据集</h3><h6 id=单标签>单标签</h6><p>make_blobs：多类单标签数据集，为每个类分配一个或多个正太分布的点集，对于中心和各簇的标准偏差提供了更好的控制，可用于演示聚类</p><p>make_classification：多类单标签数据集，为每个类分配一个或多个正太分布的点集，引入相关的，冗余的和未知的噪音特征；将高斯集群的每类复杂化；在特征空间上进行线性变换</p><p>make_gaussian_quantiles：将single Gaussian cluster （单高斯簇）分成近乎相等大小的同心超球面分离。</p><p>make_hastie_10_2：产生类似的二进制、10维问题。</p><p>make_moons/make_moons：生成二维分类数据集时可以帮助确定算法（如质心聚类或线性分类），包括可以选择性加入高斯噪声。它们有利于可视化。用球面决策边界对高斯数据生成二值分类。</p><h6 id=多标签>多标签</h6><p>make_multilabel_classification：生成多个标签的随机样本。</p><h6 id=二分聚类>二分聚类</h6><p>make_biclusters：Generate an array with constant block diagonal structure for biclustering。</p><p>make_checkerboard：Generate an array with block checkerboard structure for biclustering。</p><h6 id=回归生成器>回归生成器</h6><p>make_regression：产生的回归目标作为一个可选择的稀疏线性组合的具有噪声的随机的特征。它的信息特征可能是不相关的或低秩（少数特征占大多数的方差）。</p><p>make_sparse_uncorrelated: 产生目标为一个有四个固定系数的线性组合。</p><p>make_friedman1: 与多项式和正弦相关变换相联系。</p><p>make_friedman2: 包括特征相乘与交互。</p><p>make_friedman3: 类似与对目标的反正切变换。</p><h3 id=75-加载其他数据集>7.5. 加载其他数据集</h3><h1 id=8使用scikit-learn>8.使用scikit-learn</h1><h3 id=81计算-计算扩展的策略更大的数据>8.1计算. 计算扩展的策略：更大的数据</h3><h3 id=82-计算性能>8.2. 计算性能</h3><h3 id=83-并行性资源管理和配置>8.3. 并行性，资源管理和配置</h3></div><footer class=post-footer><div class=addthis_inline_share_toolbox style=text-align:center></div><hr><div class=post-copyright><img src=/imgs/cc/cc.svg width=75 height=75 align=right><ul><li class=post-copyright-title><strong>文章标题：</strong>
ml-sklearn</li><li class=post-copyright-author><strong>本文作者：</strong>
Tomding</li><li class=post-copyright-link><strong>本文链接：</strong>
<a id=post-cr-link href=/post/ml-sklearn/ title=ml-sklearn>/post/ml-sklearn/</a></li><li class=post-copyright-license><strong>版权声明：</strong>
本博客所有文章除特别声明外，均采用 <i class="fab fa-fw fa-creative-commons"></i><a target=_blank href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class=followme><span>欢迎关注我的其它发布渠道</span><div class=social-list><div class=social-item><a target=_blank class=social-link href=/images/wechat_channel.jpg><span class=icon><i class="fab fa-weixin"></i></span>
<span class=label>WeChat</span></a></div><div class=social-item><a target=_blank class=social-link href=/atom.xml><span class=icon><i class="fa fa-rss"></i></span>
<span class=label>RSS</span></a></div></div></div><div class=post-nav><div class="post-nav-next post-nav-item"><a href=/post/ml-seq2seq-%E6%A8%A1%E5%9E%8B%E5%8F%8A-attention-%E6%9C%BA%E5%88%B6/ rel=next title=ml-Seq2Seq-模型及-Attention-机制><i class="fa fa-chevron-left"></i> ml-Seq2Seq-模型及-Attention-机制</a></div><div class="post-nav-prev post-nav-item"><a href=/post/ml-tensorflow%E5%AE%98%E6%96%B9debug--tfdbg/ rel=prev title=ml-Tensorflow官方debug--tfdbg>ml-Tensorflow官方debug--tfdbg
<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div></main><footer class=footer><div class=footer-inner><div class=copyright>&copy;
<span itemprop=copyrightYear>2010 - 2022</span>
<span class=with-love><i class="fa fa-heart"></i></span>
<span class=author itemprop=copyrightHolder>Tomding</span></div></div></footer><script type=text/javascript src=https://cdn.staticfile.org/animejs/3.2.1/anime.min.js defer></script>
<script type=text/javascript src=https://cdn.staticfile.org/viewerjs/1.11.0/viewer.min.js defer></script>
<script class=next-config data-name=main type=application/json>{"bookmark":{"color":"#222","enable":false,"save":"manual"},"busuanzi":{"pageview":true},"copybtn":true,"darkmode":true,"giscus":{"cfg":{"category":"Comments","categoryid":null,"emit":false,"inputposition":"top","mapping":"title","reactions":false,"repo":"username/repo-name","repoid":null,"theme":"preferred_color_scheme"},"js":"https://giscus.app/client.js"},"hostname":"/","i18n":{"ds_day":" 天前","ds_days":" 天 ","ds_hour":" 小时前","ds_hours":" 小时 ","ds_just":"刚刚","ds_min":" 分钟前","ds_mins":" 分钟","ds_month":" 个月前","ds_years":" 年 ","empty":"没有找到任何搜索结果：${query}","hits":"","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","placeholder":"搜索..."},"lang":"zh-CN","lazyload":false,"localSearch":{"enable":true,"path":"/searchindexes.xml","preload":false,"topnperarticle":-1,"trigger":"auto","unescape":false},"motion":{"async":true,"enable":true,"transition":{"collheader":"fadeInLeft","postblock":"fadeIn","postbody":"fadeInDown","postheader":"fadeInDown","sidebar":"fadeInUp"}},"root":"/","scheme":"Gemini","sidebar":{"display":"post","offset":12,"padding":18,"position":"left","width":256},"statis":{"enable":true,"plugin":"busuanzi"},"vendor":{"plugins":"qiniu","router":"https://cdn.staticfile.org"},"version":"4.4.1","waline":{"cfg":{"comment":true,"emoji":false,"imguploader":false,"pageview":true,"placeholder":"请文明发言哟 ヾ(≧▽≦*)o","reaction":true,"reactiontext":["点赞","踩一下","得意","不屑","尴尬","睡觉"],"reactiontitle":"你认为这篇文章怎么样？","requiredmeta":["nick","mail"],"serverurl":null,"sofa":"快来发表你的意见吧 (≧∀≦)ゞ","wordlimit":200},"css":{"alias":"waline","file":"dist/waline.css","name":"@waline/client","version":"2.13.0"},"js":{"alias":"waline","file":"dist/waline.js","name":"@waline/client","version":"2.13.0"}}}</script><script type=text/javascript src=/js/main.min.e34208af37d3db3a875e6fbad04c2f1c241185af925a9c6ebf79dd1ba2730cdd.js defer></script></body></html>