<!doctype html><html lang=zh-cn data-theme=dark><head><meta charset=utf-8><meta name=viewport content="width=device-width"><meta name=theme-color content="#222" media="(prefers-color-scheme: dark)"><meta name=generator content="Hugo 0.107.0"><link rel="shortcut icon" type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=/imgs/icons/favicon_16x16_next.png><link rel=icon type=image/png sizes=32x32 href=/imgs/icons/favicon_32_32_next.png><link rel=apple-touch-icon sizes=180x180 href=/imgs/icons/apple_touch_icon_next.png><meta itemprop=name content="ml-pytorch"><meta itemprop=description content="Love and Peace"><meta itemprop=datePublished zgotmplz><meta itemprop=dateModified zgotmplz><meta itemprop=image content="/imgs/hugo_next_avatar.png"><meta itemprop=keywords content="Hugo,NexT,主题,简单,强大"><meta property="og:type" content="article"><meta property="og:title" content="ml-pytorch"><meta property="og:description" content="Love and Peace"><meta property="og:image" content="/imgs/hugo_next_avatar.png"><meta property="og:image:width" content="312"><meta property="og:image:height" content="312"><meta property="og:image:type" content="image/jpeg/png/svg/jpg"><meta property="og:url" content="/post/ml-pytorch/"><meta property="og:site_name" content="Tomding's Blog"><meta property="og:locale" content="zh-CN"><meta property="article:author" content="Tomding"><meta property="article:published_time" content="2022-12-01 19:59:47 +0800 CST"><meta property="article:modified_time" content="2022-12-01 19:59:47 +0800 CST"><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/font-awesome/6.1.2/css/all.min.css><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/animate.css/3.1.1/animate.min.css><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/viewerjs/1.11.0/viewer.min.css><link rel=stylesheet href=/css/main.min.0ca97083b39f4eda7430d39b99194aa738d8f8db4090f00bc7e814013df699cb.css><style type=text/css>.post-footer,.flinks-list-footer hr:after{content:"~ 我可是有底线的哟 ~"}</style><script type=text/javascript>(function(){localDB={set:function(e,t,n){if(n===0)return;const s=new Date,o=n*864e5,i={value:t,expiry:s.getTime()+o};localStorage.setItem(e,JSON.stringify(i))},get:function(e){const t=localStorage.getItem(e);if(!t)return void 0;const n=JSON.parse(t),s=new Date;return s.getTime()>n.expiry?(localStorage.removeItem(e),void 0):n.value}},theme={active:function(){const e=localDB.get("theme");if(e==null)return;theme.toggle(e),window.matchMedia("(prefers-color-scheme: dark)").addListener(function(e){theme.toggle(e.matches?"dark":"light")})},toggle:function(e){document.documentElement.setAttribute("data-theme",e),localDB.set("theme",e,2);const t=document.querySelector("iframe.giscus-frame");if(t){const n={setConfig:{theme:e}};t.contentWindow.postMessage({giscus:n},"https://giscus.app")}}},theme.active()})(window)</script><script class=next-config data-name=page type=application/json>{"comments":false,"isHome":false,"isPage":true,"path":"ml-pytorch","permalink":"/post/ml-pytorch/","title":"ml-pytorch","waline":{"js":[{"alias":"waline","alias_name":"@waline/client","file":"dist/pageview.js","name":"pageview","version":"2.13.0"},{"alias":"waline","alias_name":"@waline/client","file":"dist/comment.js","name":"comment","version":"2.13.0"}]}}</script><script type=text/javascript>document.addEventListener("DOMContentLoaded",()=>{var e=document.createElement("script");e.charset="UTF-8",e.src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js",e.async=!1,e.defer=!0,document.head.appendChild(e),e.onload=function(){NexT.utils.fmtBusuanzi()}})</script><title>ml-pytorch - Tomding's Blog</title><noscript><link rel=stylesheet href=/css/noscript.css></noscript></head><body itemscope itemtype=http://schema.org/WebPage class=use-motion><div class=headband></div><main class=main><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle aria-label=切换导航栏 role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div></div><div class=site-meta><a href=/ class=brand rel=start><i class=logo-line></i><h1 class=site-title>Tomding's Blog</h1><i class=logo-line></i></a><p class=site-subtitle itemprop=description>Just do it!</p></div><div class=site-nav-right><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href=/ class=hvr-icon-pulse rel=section><i class="fa fa-home hvr-icon"></i>首页</a></li><li class="menu-item menu-item-about"><a href=/about.html class=hvr-icon-pulse rel=section><i class="fa fa-user hvr-icon"></i>关于</a></li><li class="menu-item menu-item-archives"><a href=/archives/ class=hvr-icon-pulse rel=section><i class="fa fa-archive hvr-icon"></i>归档
<span class=badge>74</span></a></li><li class="menu-item menu-item-search"><a role=button class="popup-trigger hvr-icon-pulse"><i class="fa fa-search fa-fw hvr-icon"></i>搜索</a></li></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon><i class="fa fa-search"></i></span><div class=search-input-container><input autocomplete=off autocapitalize=off maxlength=80 placeholder=搜索... spellcheck=false type=search class=search-input></div><span class=popup-btn-close role=button><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class=search-result-icon><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></div><div class="toggle sidebar-toggle" role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div><aside class=sidebar><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>文章目录</li><li class=sidebar-nav-overview>站点概览</li></ul><div class=sidebar-panel-container><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><nav id=TableOfContents><ul><li><a href=#pip3-config-set-globalindex-url-httpspypitunatsinghuaeducnsimple><a href=https://pytorch.org/>https://pytorch.org</a>
<code>pip3 config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple</code></a><ul><li><ul><li></li></ul></li><li><a href=#torchvision-是pytorch中专门用来处理图像的库>torchvision 是PyTorch中专门用来处理图像的库</a></li></ul></li></ul><ul><li><ul><li><ul><li><a href=#当我们调用-lossbackward时整张计算图都会-根据loss进行微分>当我们调用 loss.backward()时,整张计算图都会 根据loss进行微分，</a></li></ul></li></ul></li></ul><ul><li><ul><li><a href=#nnl1loss>nn.L1Loss:</a></li><li><a href=#nnnllloss>nn.NLLLoss:</a></li><li><a href=#nnmseloss>nn.MSELoss:</a></li><li><a href=#nncrossentropyloss>nn.CrossEntropyLoss:</a></li><li><a href=#nnbceloss>nn.BCELoss:</a></li></ul></li></ul><ul><li><ul><li><a href=#torchoptimsgd>torch.optim.SGD</a></li><li><a href=#torchoptimrmsprop>torch.optim.RMSprop</a></li><li><a href=#torchoptimadam>torch.optim.Adam</a></li></ul></li></ul><ul><li><ul><li><a href=#l1正则化>L1正则化</a></li><li><a href=#l2正则化>L2正则化</a></li></ul></li></ul><ul><li><ul><li><ul><li></li></ul></li><li><a href=#lenet-5>LeNet-5</a></li><li><a href=#alexnet>AlexNet</a></li><li><a href=#vgg>VGG</a></li><li><a href=#googlenet-inceptionhttplocalhost8888notebookschapter224-cnnipynbgooglenet-inception>GoogLeNet (Inception)<a href=http://localhost:8888/notebooks/chapter2/2.4-cnn.ipynb#GoogLeNet-(Inception)></a></a></li></ul></li></ul></nav></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author site-overview-item animated" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image alt=Tomding src=/imgs/img-lazy-loading.gif data-src=/imgs/hugo_next_avatar.png><p class=site-author-name itemprop=name>Tomding</p><div class=site-description itemprop=description>Love and Peace</div></div><div class="site-state-wrap site-overview-item animated"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/><span class=site-state-item-count>74</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>5</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>0</span>
<span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-social site-overview-item animated"><span class=links-of-social-item><a href=https://github.com/ title="Github → https://github.com/" rel=noopener class=hvr-icon-pulse target=_blank><i class="fab fa-github fa-fw hvr-icon"></i>Github</a></span>
<span class=links-of-social-item><a href=https://www.zhihu.com/hot title="知乎 → https://www.zhihu.com/hot" rel=noopener class=hvr-icon-pulse target=_blank><i class="fa fa-book fa-fw hvr-icon"></i>知乎</a></span></div><div class="cc-license animated" itemprop=license><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh class=cc-opacity rel=noopener target=_blank title=共享知识><img src=/imgs/img-lazy-loading.gif data-src=/imgs/cc/big/by_nc_sa.svg alt=共享知识></a></div><div class="links-of-blogroll site-overview-item animated"><div class=links-of-blogroll-title><i class="fa fa-globe fa-fw"></i>友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://gitee.com/hugo-next/hugo-theme-next title=https://gitee.com/hugo-next/hugo-theme-next target=_blank>Hugo-NexT</a></li><li class=links-of-blogroll-item><a href=https://lisenhui.cn title=https://lisenhui.cn target=_blank>凡梦星尘空间站</a></li></ul></div></div></div></div><div id=siteinfo-card-widget class=sidebar-card-widget><div class=item-headline><i class="fas fa-chart-line"></i>
<span>网站资讯</span></div><div class=siteinfo><div class=siteinfo-item><div class=item-name><i class="fa-solid fa-calendar-check"></i>已运行：</div><div class=item-count id=runTimes data-publishdate=2022-12-01T19:59:47+08:00></div></div><div class=siteinfo-item><div class=item-name><i class="fas fa fa-user"></i>总访客数：</div><div class=item-count id=busuanzi_value_site_uv><i class="fa fa-sync fa-spin"></i></div></div><div class=siteinfo-item><div class=item-name><i class="fas fa fa-eye"></i>页面浏览：</div><div class=item-count id=busuanzi_value_site_pv><i class="fa fa-sync fa-spin"></i></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-font"></i>总字数：</div><div class=item-count id=wordsCount data-count=273678></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-mug-hot"></i>阅读约：</div><div class=item-count id=readTimes data-times=585></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-clock-rotate-left"></i>最后更新于：</div><div class=item-count id=last-push-date data-lastpushdate=2022-12-05T20:43:26+08:00></div></div></div></div></aside><div class=sidebar-dimmer></div></header><div class=tool-buttons><div id=toggle-theme class=button title=深浅模式切换><i class="fas fa-adjust"></i></div><div class=back-to-top role=button title=返回顶部><i class="fa fa-arrow-up"></i>
<span>0%</span></div></div><div class=reading-progress-bar></div><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><div class="main-inner post posts-expand"><div class=post-block><article itemscope itemtype=http://schema.org/Article class=post-content lang><link itemprop=mainEntityOfPage href=/post/ml-pytorch/><span hidden itemprop=author itemscope itemtype=http://schema.org/Person><meta itemprop=image content="/imgs/hugo_next_avatar.png"><meta itemprop=name content="Tomding"></span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization><meta itemprop=name content="Tomding"><meta itemprop=description content="Love and Peace"></span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork><meta itemprop=name content="ml-pytorch"><meta itemprop=description content="1.安装 https://pytorch.org pip3 config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple # ２.基础 创建一个 5x3 矩阵, 但是未初始化: torch.empty(5, 3) 创建一个随机初始化的矩阵: torch.rand(5, 3) 创建一个0填充的矩阵，数据类型为long torch.zeros(5, 3, dtype=torch.long)"></span><header class=post-header><h1 class=post-title itemprop="name headline">ml-pytorch
<a href=https://github.com/user-name/repo-name/tree/branch-name/subdirectory-name/post/ml-pytorch.md rel="noopener external nofollow noreferrer" target=_blank class="exturl post-edit-link" title=编辑><i class="fa fa-pen-nib"></i></a></h1><div class=post-meta-container><div class=post-meta-items><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-calendar"></i></span>
<span class=post-meta-item-text>发表于：</span>
<time title="发表于：2022-12-01 19:59:47 +0800 CST" itemprop="dateCreated datePublished" datetime="2022-12-01 19:59:47 +0800 CST">2022-12-01</time></span>
<span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-folder-open"></i></span>
<span class=post-meta-item-text>分类于：</span>
<span itemprop=about itemscope itemtype=http://schema.org/Thing><a href=/categories/ml itemprop=url rel=index><span itemprop=name>ml</span></a></span></span></div><div class=post-meta-items><span class=post-meta-item title=字数><span class=post-meta-item-icon><i class="far fa-file-word"></i></span>
<span class=post-meta-item-text>字数：</span><span>5788</span></span>
<span class=post-meta-item title=阅读><span class=post-meta-item-icon><i class="far fa-clock"></i></span>
<span class=post-meta-item-text>阅读：&ap;</span>
<span>12分钟</span></span>
<span class=post-meta-item title=浏览><span class=post-meta-item-icon><i class="far fa-eye"></i></span>
<span class=post-meta-item-text>浏览：</span>
<span id=busuanzi_value_page_pv class=waline-pageview-count data-path=/post/ml-pytorch/><i class="fa fa-sync fa-spin"></i></span></span></div></div></header><div class="post-body autonumber" itemprop=articleBody><h1 id=1安装>1.安装</h1><h2 id=pip3-config-set-globalindex-url-httpspypitunatsinghuaeducnsimple><a href=https://pytorch.org/ title=https://pytorch.org rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://pytorch.org
<i class="fa fa-external-link-alt"></i></a>
<code>pip3 config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple</code></h2><p>#　２.基础</p><h5 id=创建一个-5x3-矩阵-但是未初始化>创建一个 5x3 矩阵, 但是未初始化:</h5><p><code>torch.empty(5, 3)</code></p><h5 id=创建一个随机初始化的矩阵>创建一个随机初始化的矩阵:</h5><p><code>torch.rand(5, 3)</code></p><h5 id=创建一个0填充的矩阵数据类型为long>创建一个0填充的矩阵，数据类型为long</h5><p><code>torch.zeros(5, 3, dtype=torch.long)</code></p><h5 id=创建tensor并使用现有数据初始化>创建tensor并使用现有数据初始化:</h5><p><code>torch.tensor([5.5, 3])</code></p><h5 id=改变张量的维度和大小>改变张量的维度和大小</h5><p><code>torch.view</code></p><h5 id=根据现有的张量创建张量-这些方法将重用输入张量的属性例如-dtype除非设置新的值进行覆盖>根据现有的张量创建张量。 这些方法将重用输入张量的属性，例如， dtype，除非设置新的值进行覆盖</h5><p><code>x = x.new_ones(5, 3, dtype=torch.double) # new_* 方法来创建对象</code></p><blockquote><p>tensor([[1., 1., 1.],
[1., 1., 1.],
[1., 1., 1.],
[1., 1., 1.],
[1., 1., 1.]], dtype=torch.float64)</p></blockquote><p><code>x = torch.randn_like(x, dtype=torch.float) # 覆盖 dtype!</code></p><blockquote><p>tensor([[ 0.5691, -2.0126, -0.4064],
[-0.0863, 0.4692, -1.1209],
[-1.1177, -0.5764, -0.5363],
[-0.4390, 0.6688, 0.0889],
[ 1.3334, -1.1600, 1.8457]])</p></blockquote><h5 id=tensornumpy-转换>tensor/NumPy 转换</h5><p><code>a = torch.ones(5)</code></p><blockquote><p>tensor([1., 1., 1., 1., 1.])</p></blockquote><p><code>b = a.numpy()</code></p><blockquote><p>[1. 1. 1. 1. 1.]</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>a.add_(1)
</span></span><span style=display:flex><span>print(a)
</span></span><span style=display:flex><span>print(b)
</span></span></code></pre></div><blockquote><p>tensor([2., 2., 2., 2., 2.])
[2. 2. 2. 2. 2.]</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>import numpy as np
</span></span><span style=display:flex><span>a = np.ones(5)
</span></span><span style=display:flex><span>b = torch.from_numpy(a)
</span></span><span style=display:flex><span>np.add(a, 1, out=a)
</span></span><span style=display:flex><span>print(a)
</span></span><span style=display:flex><span>print(b)
</span></span></code></pre></div><blockquote><p>[2. 2. 2. 2. 2.]
tensor([2., 2., 2., 2., 2.], dtype=torch.float64)</p></blockquote><h5 id=cuda-张量>CUDA 张量</h5><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span># is_available 函数判断是否有cuda可以使用
</span></span><span style=display:flex><span># ``torch.device``将张量移动到指定的设备中
</span></span><span style=display:flex><span>x = torch.randn(1)
</span></span><span style=display:flex><span>if torch.cuda.is_available():
</span></span><span style=display:flex><span>    device = torch.device(&#34;cuda&#34;)          # a CUDA 设备对象
</span></span><span style=display:flex><span>    y = torch.ones_like(x, device=device)  # 直接从GPU创建张量
</span></span><span style=display:flex><span>    x = x.to(device)                       # 或者直接使用``.to(&#34;cuda&#34;)``将张量移动到cuda中
</span></span><span style=display:flex><span>    z = x + y
</span></span><span style=display:flex><span>    print(z)
</span></span><span style=display:flex><span>    print(z.to(&#34;cpu&#34;, torch.double))       # ``.to`` 也会对变量的类型做更改
</span></span></code></pre></div><blockquote><p>tensor([0.7632], device=&lsquo;cuda:0&rsquo;)
tensor([0.7632], dtype=torch.float64)</p></blockquote><h5 id=autograd-自动求导机制>Autograd: 自动求导机制</h5><p>每个张量都有一个.grad_fn属性，这个属性引用了一个创建了Tensor的Function（除非这个张量是用户手动创建的，即，这个张量的 grad_fn 是 None）。.requires_grad_( &mldr; ) 可以改变现有张量的 requires_grad属性。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>a = torch.randn(2, 2)
</span></span><span style=display:flex><span>print(a.requires_grad)
</span></span><span style=display:flex><span>a.requires_grad_(True)
</span></span><span style=display:flex><span>print(a.requires_grad)
</span></span></code></pre></div><blockquote><p>False
True</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>x = torch.ones(2, 2, requires_grad=True)
</span></span><span style=display:flex><span>print(x)
</span></span></code></pre></div><blockquote><p>tensor([[1., 1.], [1., 1.]], requires_grad=True)</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>y = x + 2
</span></span><span style=display:flex><span>print(y)
</span></span></code></pre></div><blockquote><p>tensor([[3., 3.], [3., 3.]], grad_fn=<addbackward>)</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>z = y * y * 3
</span></span><span style=display:flex><span>out = z.mean()
</span></span><span style=display:flex><span>print(z, out)
</span></span></code></pre></div><blockquote><p>tensor([[27., 27.],[27., 27.]], grad_fn=<mulbackward0>)
tensor(27., grad_fn=<meanbackward0>)</p></blockquote><p>反向传播 因为 out是一个纯量（scalar），out.backward() 等于out.backward(torch.tensor(1))。
<code>out.backward()</code></p><blockquote><p>print gradients d(out)/dx</p></blockquote><p><code>print(x.grad)</code></p><blockquote><p>tensor([[4.5000, 4.5000],[4.5000, 4.5000]])</p></blockquote><p>得到 $o = \frac{1}{4}\sum_i z_i$,$z_i = 3(x_i+2)^2$ and $z_i\bigr\rvert_{x_i=1} = 27$.</p><p>因此,$\frac{\partial o}{\partial x_i} = \frac{3}{2}(x_i+2)$, hence$\frac{\partial o}{\partial x_i}\bigr\rvert_{x_i=1} = \frac{9}{2} = 4.5$.</p><p>如果.requires_grad=True但是你又不希望进行autograd的计算， 那么可以将变量包裹在 with torch.no_grad()中:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>print(x.requires_grad)
</span></span><span style=display:flex><span>print((x ` 2).requires_grad)
</span></span><span style=display:flex><span>with torch.no_grad():
</span></span><span style=display:flex><span>	print((x ` 2).requires_grad)
</span></span></code></pre></div><blockquote><p>True
True
False</p></blockquote><hr><p>#　３.数据集
定义一个数据集</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>from torch.utils.data import Dataset
</span></span><span style=display:flex><span>import pandas as pd
</span></span><span style=display:flex><span>class BulldozerDataset(Dataset):
</span></span><span style=display:flex><span>    def __init__(self, csv_file):
</span></span><span style=display:flex><span>        self.df=pd.read_csv(csv_file)
</span></span><span style=display:flex><span>    # 该方法返回数据集的总长度
</span></span><span style=display:flex><span>    def __len__(self):
</span></span><span style=display:flex><span>        return len(self.df)
</span></span><span style=display:flex><span>    # 该方法定义用索引(0 到 len(self))获取一条数据或一个样本
</span></span><span style=display:flex><span>    def __getitem__(self, idx):
</span></span><span style=display:flex><span>        return self.df.iloc[idx].SalePrice
</span></span><span style=display:flex><span>ds_demo= BulldozerDataset(&#39;median_benchmark.csv&#39;)
</span></span><span style=display:flex><span>#实现了 __len__ 方法所以可以直接使用len获取数据总数
</span></span><span style=display:flex><span>len(ds_demo)
</span></span><span style=display:flex><span>#用索引可以直接访问对应的数据, 对应 __getitem__ 方法
</span></span><span style=display:flex><span>ds_demo[0]
</span></span></code></pre></div><p>DataLoader为我们提供了对Dataset的读取操作</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>#batch_size, shuffle, num_workers(加载数据的时候使用几个子进程)
</span></span><span style=display:flex><span>dl = torch.utils.data.DataLoader(ds_demo, batch_size=10, shuffle=True, num_workers=0)
</span></span><span style=display:flex><span># DataLoader返回的是一个可迭代对象，我们可以使用迭代器分次获取数据
</span></span><span style=display:flex><span># idata=iter(dl)
</span></span><span style=display:flex><span># print(next(idata))
</span></span><span style=display:flex><span>for i, data in enumerate(dl):
</span></span><span style=display:flex><span>    print(i,data)
</span></span></code></pre></div><h3 id=torchvision-是pytorch中专门用来处理图像的库>torchvision 是PyTorch中专门用来处理图像的库</h3><p>torchvision.datasets 可以理解为PyTorch团队自定义的dataset，不仅提供了常用图片数据集，还提供了训练好的模型，可以加载之后，直接使用：</p><ul><li>MNIST- COCO- Captions- Detection- LSUN- ImageFolder- Imagenet-12- CIFAR- STL10- SVHN- PhotoTour</li><li>AlexNet- VGG- ResNet- SqueezeNet- DenseNet</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>import torchvision.datasets as datasets
</span></span><span style=display:flex><span>trainset = datasets.MNIST(root=&#39;./data&#39;, # 加载的目录
</span></span><span style=display:flex><span>train=True,  # 表示是否加载数据库的训练集，false的时候加载测试集
</span></span><span style=display:flex><span>download=True, # 表示是否自动下载 MNIST 数据集
</span></span><span style=display:flex><span>transform=None) # 表示是否需要对数据进行预处理，none为不进行预处理
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>import torchvision.models as models
</span></span><span style=display:flex><span>resnet18 = models.resnet18(pretrained=True)
</span></span></code></pre></div><hr><h1 id=torchvisiontransforms-模块提供了一般的图像转换操作类用作数据处理和数据增强>torchvision.transforms 模块提供了一般的图像转换操作类，用作数据处理和数据增强</h1><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>from torchvision import transforms as transforms
</span></span><span style=display:flex><span>transform = transforms.Compose([
</span></span><span style=display:flex><span>    transforms.RandomCrop(32, padding=4),  #先四周填充0，在把图像随机裁剪成32*32
</span></span><span style=display:flex><span>    transforms.RandomHorizontalFlip(),  #图像一半的概率翻转，一半的概率不翻转
</span></span><span style=display:flex><span>    transforms.RandomRotation((-45,45)), #随机旋转
</span></span><span style=display:flex><span>    transforms.ToTensor(),
</span></span><span style=display:flex><span>    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.229, 0.224, 0.225)), #R,G,B每层的归一化用到的均值和方差
</span></span><span style=display:flex><span>])
</span></span></code></pre></div><hr><h1 id=4反向传播>4.反向传播</h1><h4 id=当我们调用-lossbackward时整张计算图都会-根据loss进行微分>当我们调用 loss.backward()时,整张计算图都会 根据loss进行微分，</h4><p>而且图中所有设置为requires_grad=True的张量 将会拥有一个随着梯度累积的.grad 张量。
relu -> linear -> MSELoss -> loss</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>print(loss.grad_fn)  # MSELoss
</span></span><span style=display:flex><span>print(loss.grad_fn.next_functions[0][0])  # Linear
</span></span><span style=display:flex><span>print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU
</span></span></code></pre></div><blockquote><p>&lt;MseLossBackward object at 0x7f3b49fe2470>
&lt;AddmmBackward object at 0x7f3bb05f17f0>
&lt;AccumulateGrad object at 0x7f3b4a3c34e0></p></blockquote><p>现在，我们将调用loss.backward()，并查看conv1层的偏差（bias）项在反向传播前后的梯度。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>net.zero_grad()     # 清除梯度
</span></span><span style=display:flex><span>print(&#39;conv1.bias.grad before backward&#39;)
</span></span><span style=display:flex><span>print(net.conv1.bias.grad)
</span></span><span style=display:flex><span>loss.backward()
</span></span><span style=display:flex><span>print(&#39;conv1.bias.grad after backward&#39;)
</span></span><span style=display:flex><span>print(net.conv1.bias.grad)
</span></span></code></pre></div><blockquote><p>conv1.bias.grad before backward
tensor([0., 0., 0., 0., 0., 0.])
conv1.bias.grad after backward
tensor([ 0.0051, 0.0042, 0.0026, 0.0152, -0.0040, -0.0036])</p></blockquote><hr><h1 id=5损失函数loss-function>5.损失函数(Loss Function)</h1><p>损失函数（loss function）是用来估量模型的预测值与真实值的不一致程度，它是一个非负实值函数,损失函数越小，模型的鲁棒性就越好。</p><h3 id=nnl1loss>nn.L1Loss:</h3><p>输入x和目标y之间差的绝对值，要求 x 和 y 的维度要一样（可以是向量或者矩阵），得到的 loss 维度也是对应一样的</p><p>$ loss(x,y)=1/n\sum|x_i-y_i| $</p><h3 id=nnnllloss>nn.NLLLoss:</h3><p><code>用于多分类的负对数似然损失函数</code></p><p>$ loss(x, class) = -x[class]$</p><p>NLLLoss中如果传递了weights参数，会对损失进行加权，公式就变成了</p><p>$ loss(x, class) = -weights[class] * x[class] $</p><h3 id=nnmseloss>nn.MSELoss:</h3><p>均方损失函数 ，输入x和目标y之间均方差</p><p>$ loss(x,y)=1/n\sum(x_i-y_i)^2 $</p><h3 id=nncrossentropyloss>nn.CrossEntropyLoss:</h3><p>多分类用的交叉熵损失函数，LogSoftMax和NLLLoss集成到一个类中，会调用nn.NLLLoss函数,我们可以理解为CrossEntropyLoss()=log_softmax() + NLLLoss()</p><p>$ \begin{aligned} loss(x, class) &= -\text{log}\frac{exp(x[class])}{\sum_j exp(x[j]))}\ &= -x[class] + log(\sum_j exp(x[j])) \end{aligned} $</p><p>因为使用了NLLLoss，所以也可以传入weight参数，这时loss的计算公式变为：</p><p>$ loss(x, class) = weights[class] * (-x[class] + log(\sum_j exp(x[j]))) $</p><p>所以一般多分类的情况会使用这个损失函数</p><h3 id=nnbceloss>nn.BCELoss:</h3><p>计算 x 与 y 之间的二进制交叉熵。</p><p>$ loss(o,t)=-\frac{1}{n}\sum_i(t[i]* log(o[i])+(1-t[i])* log(1-o[i])) $</p><p>与NLLLoss类似，也可以添加权重参数：</p><p>$ loss(o,t)=-\frac{1}{n}\sum_iweights[i]* (t[i]* log(o[i])+(1-t[i])* log(1-o[i])) $</p><p>用的时候需要在该层前面加上 Sigmoid 函数。</p><hr><h1 id=6优化算法>6.优化算法</h1><h3 id=torchoptimsgd>torch.optim.SGD</h3><p>随机梯度下降算法,带有动量（momentum）的算法作为一个可选参数可以进行设置，样例如下：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>#lr参数为学习率，对于SGD来说一般选择0.1 0.01.0.001，如何设置会在后面实战的章节中详细说明
</span></span><span style=display:flex><span>#如果设置了momentum，就是带有动量的SGD，可以不设置
</span></span><span style=display:flex><span>optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)
</span></span></code></pre></div><h3 id=torchoptimrmsprop>torch.optim.RMSprop</h3><p>除了以上的带有动量Momentum梯度下降法外，RMSprop（root mean square prop）也是一种可以加快梯度下降的算法，利用RMSprop算法，<code>可以减小某些维度梯度更新波动较大的情况</code>，使其梯度下降的速度变得更快</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span># 我们的课程基本不会使用到RMSprop所以这里只给一个实例
</span></span><span style=display:flex><span>optimizer = torch.optim.RMSprop(model.parameters(), lr=0.01, alpha=0.99)
</span></span></code></pre></div><h3 id=torchoptimadam>torch.optim.Adam</h3><p>Adam 优化算法的基本思想就是将 Momentum 和 RMSprop 结合起来形成的一种适用于不同深度学习结构的优化算法</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span># 这里的lr，betas，还有eps都是用默认值即可，所以Adam是一个使用起来最简单的优化方法
</span></span><span style=display:flex><span>optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)
</span></span></code></pre></div><hr><h1 id=7正则化>7.正则化</h1><h3 id=l1正则化>L1正则化</h3><p>损失函数基础上加上权重参数的绝对值</p><p>$ L=E_{in}+\lambda{\sum_j} \left|w_j\right|$</p><h3 id=l2正则化>L2正则化</h3><p>损失函数基础上加上权重参数的平方和</p><p>$ L=E_{in}+\lambda{\sum_j} w^2_j$</p><p>需要说明的是：l1 相比于 l2 会更容易获得稀疏解</p><hr><h1 id=8多gpu数据并行>8.多GPU数据并行</h1><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>model = Model(input_size, output_size)
</span></span><span style=display:flex><span>if torch.cuda.device_count() &gt; 1:
</span></span><span style=display:flex><span>    print(&#34;Let&#39;s use&#34;, torch.cuda.device_count(), &#34;GPUs!&#34;)
</span></span><span style=display:flex><span>    # DataParallel会自动的划分数据，并将作业发送到多个GPU上的多个模型。 并在每个模型完成作业后，收集合并结果并返回。
</span></span><span style=display:flex><span>    model = nn.DataParallel(model)
</span></span><span style=display:flex><span>model.to(device)
</span></span><span style=display:flex><span>for data in rand_loader:
</span></span><span style=display:flex><span>    # 请注意，只调用data.to(device)并没有复制张量到GPU上，而是返回了一个copy。所以你需要把它赋值给一个新的张量并在GPU上使用这个张量。
</span></span><span style=display:flex><span>    input = data.to(device)
</span></span><span style=display:flex><span>    output = model(input)
</span></span><span style=display:flex><span>    print(&#34;Outside: input size&#34;, input.size(), &#34;output_size&#34;, output.size())
</span></span></code></pre></div><hr><h1 id=9cnn>9.CNN</h1><h5 id=卷积层输出矩阵大小>卷积层输出矩阵大小</h5><p>ensorFlow里面的padding只有两个选项也就是valid和same
pytorch里面的padding么有这两个选项，它是数字0,1,2,3等等，默认是0
所以输出的h和w的计算方式也是稍微有一点点不同的：tf中的输出大小是和原来的大小成倍数关系，不能任意的输出大小；而nn输出大小可以通过padding进行改变</p><p><code>Conv2d（in_channels, out_channels, kernel_size, stride=1,padding=0, dilation=1, groups=1,bias=True, padding_mode='zeros')</code></p><h5 id=池化层的输出大小公式也与卷积层一样由于没有进行填充所以p0可以简化为---fracn-fs-1->池化层的输出大小公式也与卷积层一样，由于没有进行填充，所以p=0，可以简化为 $ \frac{n-f}{s} +1 $</h5><p>通过减少卷积层之间的连接，降低运算复杂程度
<code>import torch.nn.functional as F</code>
<code>F.max_pool2d(input, kernel_size, stride=None, padding=0, dilation=1, ceil_mode=False, return_indices=False))</code></p><h3 id=lenet-5>LeNet-5</h3><p><a href=http://yann.lecun.com/exdb/lenet/index.html title=官网 rel="noopener external nofollow noreferrer" target=_blank class=exturl>官网
<i class="fa fa-external-link-alt"></i></a>
卷积神经网路的开山之作，麻雀虽小，但五脏俱全，卷积层、pooling层、全连接层，这些都是现代CNN网络的基本组件</p><p>用卷积提取空间特征；由空间平均得到子样本；用 tanh 或 sigmoid 得到非线性；
用 multi-layer neural network（MLP）作为最终分类器；层层之间用稀疏的连接矩阵，以避免大的计算成本。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>&#39;&#39;&#39;
</span></span><span style=display:flex><span>C1层是一个卷积层，有6个卷积核（提取6种局部特征），核大小为5 * 5
</span></span><span style=display:flex><span>S2层是pooling层，下采样（区域:2 * 2 ）降低网络训练参数及模型的过拟合程度。
</span></span><span style=display:flex><span>C3层是第二个卷积层，使用16个卷积核，核大小:5 * 5 提取特征
</span></span><span style=display:flex><span>S4层也是一个pooling层，区域:2*2
</span></span><span style=display:flex><span>C5层是最后一个卷积层，卷积核大小:5 * 5 卷积核种类:120
</span></span><span style=display:flex><span>最后使用全连接层，将C5的120个特征进行分类，最后输出0-9的概率
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>&#39;&#39;&#39;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>import torch.nn as nn
</span></span><span style=display:flex><span>class LeNet5(nn.Module):
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    def __init__(self):
</span></span><span style=display:flex><span>        super(LeNet5, self).__init__()
</span></span><span style=display:flex><span>        # 1 input image channel, 6 output channels, 5x5 square convolution
</span></span><span style=display:flex><span>        # kernel
</span></span><span style=display:flex><span>        self.conv1 = nn.Conv2d(1, 6, 5)
</span></span><span style=display:flex><span>        self.conv2 = nn.Conv2d(6, 16, 5)
</span></span><span style=display:flex><span>        # an affine operation: y = Wx + b
</span></span><span style=display:flex><span>        self.fc1 = nn.Linear(16 * 5 * 5, 120) # 这里论文上写的是conv,官方教程用了线性层
</span></span><span style=display:flex><span>        self.fc2 = nn.Linear(120, 84)
</span></span><span style=display:flex><span>        self.fc3 = nn.Linear(84, 10)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    def forward(self, x):
</span></span><span style=display:flex><span>        # Max pooling over a (2, 2) window
</span></span><span style=display:flex><span>        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
</span></span><span style=display:flex><span>        # If the size is a square you can only specify a single number
</span></span><span style=display:flex><span>        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
</span></span><span style=display:flex><span>        x = x.view(-1, self.num_flat_features(x))
</span></span><span style=display:flex><span>        x = F.relu(self.fc1(x))
</span></span><span style=display:flex><span>        x = F.relu(self.fc2(x))
</span></span><span style=display:flex><span>        x = self.fc3(x)
</span></span><span style=display:flex><span>        return x
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    def num_flat_features(self, x):
</span></span><span style=display:flex><span>        size = x.size()[1:]  # all dimensions except the batch dimension
</span></span><span style=display:flex><span>        num_features = 1
</span></span><span style=display:flex><span>        for s in size:
</span></span><span style=display:flex><span>            num_features *= s
</span></span><span style=display:flex><span>        return num_features
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>net = LeNet5()
</span></span><span style=display:flex><span>print(net)
</span></span></code></pre></div><h3 id=alexnet>AlexNet</h3><p>2012，Alex Krizhevsky 可以算作LeNet的一个更深和更广的版本，可以用来学习更复杂的对象 .
<a href=https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf title=论文 rel="noopener external nofollow noreferrer" target=_blank class=exturl>论文
<i class="fa fa-external-link-alt"></i></a></p><p>用rectified linear units（ReLU）得到非线性；
使用 dropout 技巧在训练期间有选择性地忽略单个神经元，来减缓模型的过拟合；
重叠最大池，避免平均池的平均效果；
虽然 AlexNet只有8层，但是它有60M以上的参数总量，Alexnet有一个特殊的计算层，LRN层，做的事是对当前层的输出结果做平滑处理，这里就不做详细介绍了， Alexnet的每一阶段（含一次卷积主要计算的算作一层）可以分为8层：</p><blockquote><p>con - relu - pooling - LRN ： 要注意的是input层是227*227，而不是paper里面的224，这里可以算一下，主要是227可以整除后面的conv1计算，224不整除。如果一定要用224可以通过自动补边实现，不过在input就补边感觉没有意义，补得也是0，这就是我们上面说的公式的重要性。
conv - relu - pool - LRN ： group=2，这个属性强行把前面结果的feature map分开，卷积部分分成两部分做
conv - relu
conv-relu
conv - relu - pool
fc - relu - dropout ： dropout层，在alexnet中是说在训练的以1/2概率使得隐藏层的某些neuron的输出为0，这样就丢到了一半节点的输出，BP的时候也不更新这些节点，防止过拟合。
fc - relu - dropout
fc - softmax</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>import torchvision
</span></span><span style=display:flex><span>model = torchvision.models.alexnet(pretrained=False) #我们不下载预训练权重
</span></span><span style=display:flex><span>print(model)
</span></span></code></pre></div><h3 id=vgg>VGG</h3><p>2015，牛津的 VGG。
<a href=https://arxiv.org/pdf/1409.1556.pdf title=论文 rel="noopener external nofollow noreferrer" target=_blank class=exturl>论文
<i class="fa fa-external-link-alt"></i></a>
每个卷积层中使用更小的 3×3 filters，并将它们组合成卷积序列
多个3×3卷积序列可以模拟更大的接收场的效果
每次的图像像素缩小一倍，卷积核的数量增加一倍</p><blockquote><p>VGG清一色用小卷积核，结合作者和自己的观点，这里整理出小卷积核比用大卷积核的优势：
根据作者的观点，input8 -> 3层conv3x3后，output=2，等同于1层conv7x7的结果； input=8 -> 2层conv3x3后，output=2，等同于2层conv5x5的结果
卷积层的参数减少。相比5x5、7x7和11x11的大卷积核，3x3明显地减少了参数量
通过卷积和池化层后，图像的分辨率降低为原来的一半，但是图像的特征增加一倍，这是一个十分规整的操作: 分辨率由输入的224->112->56->28->14->7, 特征从原始的RGB3个通道-> 64 ->128 -> 256 -> 512</p></blockquote><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>import torchvision
</span></span><span style=display:flex><span>model = torchvision.models.vgg16(pretrained=False) #我们不下载预训练权重
</span></span><span style=display:flex><span>print(model)
</span></span></code></pre></div><h3 id=googlenet-inceptionhttplocalhost8888notebookschapter224-cnnipynbgooglenet-inception>GoogLeNet (Inception)
<a href=http://localhost:8888/notebooks/chapter2/2.4-cnn.ipynb#GoogLeNet-%28Inception%29 title rel="noopener external nofollow noreferrer" target=_blank class=exturl><i class="fa fa-external-link-alt"></i></a></h3><p>2014，Google Christian Szegedy 
<a href=https://arxiv.org/abs/1512.00567 title=论文 rel="noopener external nofollow noreferrer" target=_blank class=exturl>论文
<i class="fa fa-external-link-alt"></i></a></p><ul><li>使用1×1卷积块（NiN）来减少特征数量，这通常被称为“瓶颈”，可以减少深层神经网络的计算负担。</li><li>每个池化层之前，增加 feature maps，增加每一层的宽度来增多特征的组合性</li></ul><p>googlenet最大的特点就是包含若干个inception模块，所以有时候也称作 inception net googlenet虽然层数要比VGG多很多，但是由于inception的设计，计算速度方面要快很多。</p><hr><p>#　Tensorboard
安装
<code>pip install tensorboard</code>
<code>tensorboard --logdir logs</code> 即可启动，默认的端口是 6006,在浏览器中打开 <code>http://localhost:6006/ </code>即可看到web页面。</p><hr><h1 id=mnist数据集手写数字识别>MNIST数据集手写数字识别</h1><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>import argparse       # Python 命令行解析工具
</span></span><span style=display:flex><span>import torch
</span></span><span style=display:flex><span>import torch.nn as nn
</span></span><span style=display:flex><span>import torch.nn.functional as F
</span></span><span style=display:flex><span>import torch.optim as optim
</span></span><span style=display:flex><span>from torchvision import datasets, transforms
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>class Net(nn.Module):
</span></span><span style=display:flex><span>    def __init__(self):
</span></span><span style=display:flex><span>        super(Net, self).__init__()
</span></span><span style=display:flex><span>        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1,)
</span></span><span style=display:flex><span>        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1,)
</span></span><span style=display:flex><span>        self.dropout1 = nn.Dropout2d(0.25)
</span></span><span style=display:flex><span>        self.dropout2 = nn.Dropout2d(0.5)
</span></span><span style=display:flex><span>        self.fc1 = nn.Linear(9216, 128)
</span></span><span style=display:flex><span>        self.fc2 = nn.Linear(128, 10)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    def forward(self, x):
</span></span><span style=display:flex><span>        x = self.conv1(x)
</span></span><span style=display:flex><span>        x = F.relu(x)
</span></span><span style=display:flex><span>        x = self.conv2(x)
</span></span><span style=display:flex><span>        x = F.relu(x)
</span></span><span style=display:flex><span>        x = F.max_pool2d(x, 2)
</span></span><span style=display:flex><span>        x = self.dropout1(x)
</span></span><span style=display:flex><span>        x = torch.flatten(x, 1)
</span></span><span style=display:flex><span>        x = self.fc1(x)
</span></span><span style=display:flex><span>        x = F.relu(x)
</span></span><span style=display:flex><span>        x = self.dropout2(x)
</span></span><span style=display:flex><span>        x = self.fc2(x)
</span></span><span style=display:flex><span>        output = F.log_softmax(x, dim=1)
</span></span><span style=display:flex><span>        return output
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>def train(args, model, device, train_loader, optimizer, epoch):
</span></span><span style=display:flex><span>    # 如果模型中有Batch Normalization和Dropout，需要在训练时添加model.train()，在测试时添加model.eval()。
</span></span><span style=display:flex><span>    # Batch Normalization在train时不仅使用了当前batch的均值和方差，也使用了历史batch统计上的均值和方差，
</span></span><span style=display:flex><span>    # 并做一个加权平均 （momentum参数）。在test时，由于此时batchsize不一定一致，因此不再使用当前batch的
</span></span><span style=display:flex><span>    # 均值和方差，仅使用历史训练时的统计值。
</span></span><span style=display:flex><span>    # Dropout在train时随机选择神经元而predict要使用全部神经元并且要乘一个补偿系数
</span></span><span style=display:flex><span>    model.train()
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    for batch_idx, (data, target) in enumerate(train_loader):
</span></span><span style=display:flex><span>        data, target = data.to(device), target.to(device)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        optimizer.zero_grad()
</span></span><span style=display:flex><span>        output = model(data)
</span></span><span style=display:flex><span>        &#34;&#34;&#34;
</span></span><span style=display:flex><span>        pytorch中CrossEntropyLoss是通过两个步骤计算出来的:
</span></span><span style=display:flex><span>               第一步是计算log softmax，第二步是计算cross entropy（或者说是negative log likehood），
</span></span><span style=display:flex><span>               CrossEntropyLoss不需要在网络的最后一层添加softmax和log层，直接输出全连接层即可。
</span></span><span style=display:flex><span>               而NLLLoss则需要在定义网络的时候在最后一层添加log_softmax层(softmax和log层)
</span></span><span style=display:flex><span>        总而言之：CrossEntropyLoss() = log_softmax() + NLLLoss() 
</span></span><span style=display:flex><span>nn.CrossEntropyLoss()
</span></span><span style=display:flex><span>        &#34;&#34;&#34;
</span></span><span style=display:flex><span>        loss = F.nll_loss(output, target)
</span></span><span style=display:flex><span>        loss.backward()
</span></span><span style=display:flex><span>        optimizer.step()
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        if batch_idx % args.log_interval == 0:
</span></span><span style=display:flex><span>            print(&#39;Train_Epoch:{} [{}/{} ({:.2f}%)] \t loss:{:.6f}&#39;.format(epoch, 
</span></span><span style=display:flex><span>                                                                   batch_idx*len(data), len(train_loader),
</span></span><span style=display:flex><span>                                                                   100.0*batch_idx/len(train_loader),
</span></span><span style=display:flex><span>                                                                   loss.item()))
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>            if args.dry_run:
</span></span><span style=display:flex><span>                break
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>def test(model, device, test_loader):
</span></span><span style=display:flex><span>    model.eval()
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    test_loss = 0
</span></span><span style=display:flex><span>    correct = 0
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    with torch.no_grad():  #
</span></span><span style=display:flex><span>        for data, target in test_loader:
</span></span><span style=display:flex><span>            data, target = data.to(device), target.to(device)
</span></span><span style=display:flex><span>            output = model(data)
</span></span><span style=display:flex><span>            # 默认情况下size_average=False，是mini-batchloss的平均值，然而，如果size_average=False，则是mini-batchloss的总和。
</span></span><span style=display:flex><span>            test_loss += F.nll_loss(output, target,  reduction=&#39;sum&#39;).item() # sum up batch loss
</span></span><span style=display:flex><span>            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            correct += pred.eq(target.view_as(pred)).sum().item()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    test_loss /= len(test_loader.dataset)
</span></span><span style=display:flex><span>    print(&#39;\n Test: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n&#39;.format(test_loss, 
</span></span><span style=display:flex><span>                                                            correct, 
</span></span><span style=display:flex><span>                                                            len(test_loader.dataset),
</span></span><span style=display:flex><span>                                                            100. * correct / len(test_loader.dataset)))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>def main():
</span></span><span style=display:flex><span>    # Training settings
</span></span><span style=display:flex><span>    parser = argparse.ArgumentParser(description=&#39;PyTorch MNIST Example&#39;)
</span></span><span style=display:flex><span>    parser.add_argument(&#39;-batch_size&#39;, type=int, default=64, metavar=&#39;N&#39;,
</span></span><span style=display:flex><span>                        help=&#39;input batch size for training (default: 64)&#39;)
</span></span><span style=display:flex><span>    parser.add_argument(&#39;-test_batch_size&#39;, type=int, default=1000, metavar=&#39;N&#39;,
</span></span><span style=display:flex><span>                        help=&#39;input batch size for testing (default: 1000)&#39;)
</span></span><span style=display:flex><span>    parser.add_argument(&#39;-epochs&#39;, type=int, default=10, metavar=&#39;N&#39;,
</span></span><span style=display:flex><span>                        help=&#39;number of epochs to train (default: 10)&#39;)
</span></span><span style=display:flex><span>    parser.add_argument(&#39;-lr&#39;, type=float, default=0.01, metavar=&#39;LR&#39;,
</span></span><span style=display:flex><span>                        help=&#39;learning rate (default: 0.01)&#39;)
</span></span><span style=display:flex><span>    parser.add_argument(&#39;-momentum&#39;, type=float, default=0.5, metavar=&#39;M&#39;,
</span></span><span style=display:flex><span>                        help=&#39;SGD momentum (default: 0.5)&#39;)
</span></span><span style=display:flex><span>    parser.add_argument(&#39;-gamma&#39;, type=float, default=0.7, metavar=&#39;M&#39;,
</span></span><span style=display:flex><span>                        help=&#39;Learning rate step gamma (default: 0.7)&#39;)
</span></span><span style=display:flex><span>    parser.add_argument(&#39;-no_cuda&#39;, action=&#39;store_true&#39;, default=False,
</span></span><span style=display:flex><span>                        help=&#39;disables CUDA training&#39;)
</span></span><span style=display:flex><span>    parser.add_argument(&#39;-dry_run&#39;, action=&#39;store_true&#39;, default=False,
</span></span><span style=display:flex><span>                        help=&#39;quickly check a single pass&#39;)
</span></span><span style=display:flex><span>    parser.add_argument(&#39;-seed&#39;, type=int, default=1, metavar=&#39;S&#39;,
</span></span><span style=display:flex><span>                        help=&#39;random seed (default: 1)&#39;)
</span></span><span style=display:flex><span>    parser.add_argument(&#39;-log_interval&#39;, type=int, default=100, metavar=&#39;N&#39;,
</span></span><span style=display:flex><span>                        help=&#39;how many batches to wait before logging training status&#39;)
</span></span><span style=display:flex><span>    parser.add_argument(&#39;-save_model&#39;, action=&#39;store_true&#39;, default=False,
</span></span><span style=display:flex><span>                        help=&#39;For Saving the current Model&#39;)
</span></span><span style=display:flex><span>    args = parser.parse_args(args=[])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    torch.manual_seed(args.seed)  #  #为CPU设置种子用于生成随机数，以使得结果是确定的
</span></span><span style=display:flex><span>    # torch.cuda.manual_seed(args.seed)为当前GPU设置随机种子；如果使用多个GPU，应该使用torch.cuda.manual_seed_all()为所有的GPU设置种子。
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    kwargs = {&#39;batch_size&#39;: args.batch_size}
</span></span><span style=display:flex><span>    use_cuda = not args.no_cuda and torch.cuda.is_available()
</span></span><span style=display:flex><span>    if use_cuda:
</span></span><span style=display:flex><span>        kwargs.update({&#39;num_workers&#39;: 1,
</span></span><span style=display:flex><span>                       &#39;pin_memory&#39;: True,
</span></span><span style=display:flex><span>                       &#39;shuffle&#39;: True},)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>    transform = transforms.Compose([transforms.ToTensor(),
</span></span><span style=display:flex><span>                        transforms.Normalize((0.1307,), (0.3081,))])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    train_dataset = datasets.MNIST(&#39;./data&#39;, train=True, download=True, transform=transform,)                                         
</span></span><span style=display:flex><span>    test_dataset = datasets.MNIST(&#39;./data&#39;, train=False, transform=transform)
</span></span><span style=display:flex><span>    train_loader = torch.utils.data.DataLoader(train_dataset, `kwargs)
</span></span><span style=display:flex><span>    test_loader = torch.utils.data.DataLoader(test_dataset, `kwargs)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    device = torch.device(&#34;cuda&#34; if use_cuda else &#34;cpu&#34;)
</span></span><span style=display:flex><span>    model = Net().to(device)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)
</span></span><span style=display:flex><span>    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=args.gamma)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    for epoch in range(1, args.epochs+1):
</span></span><span style=display:flex><span>        train(args, model, device, train_loader, optimizer, epoch)
</span></span><span style=display:flex><span>        test(model, device, test_loader)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    # 训练完成，保存状态字典到linear.pkl
</span></span><span style=display:flex><span>    # torch.save(model.state_dict(), &#39;./linear.pkl&#39;)
</span></span><span style=display:flex><span>    # model.load_state_dict(torch.load(&#39;linear.pth&#39;))
</span></span><span style=display:flex><span>    if args.save_model:
</span></span><span style=display:flex><span>        torch.save(model.state_dict(), &#34;mnist_cnn.pt&#34;)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>if __name__ == &#39;__main__&#39;:
</span></span><span style=display:flex><span>    main()
</span></span></code></pre></div></div><footer class=post-footer><div class=addthis_inline_share_toolbox style=text-align:center></div><hr><div class=post-copyright><img src=/imgs/cc/cc.svg width=75 height=75 align=right><ul><li class=post-copyright-title><strong>文章标题：</strong>
ml-pytorch</li><li class=post-copyright-author><strong>本文作者：</strong>
Tomding</li><li class=post-copyright-link><strong>本文链接：</strong>
<a id=post-cr-link href=/post/ml-pytorch/ title=ml-pytorch>/post/ml-pytorch/</a></li><li class=post-copyright-license><strong>版权声明：</strong>
本博客所有文章除特别声明外，均采用 <i class="fab fa-fw fa-creative-commons"></i><a target=_blank href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class=followme><span>欢迎关注我的其它发布渠道</span><div class=social-list><div class=social-item><a target=_blank class=social-link href=/images/wechat_channel.jpg><span class=icon><i class="fab fa-weixin"></i></span>
<span class=label>WeChat</span></a></div><div class=social-item><a target=_blank class=social-link href=/atom.xml><span class=icon><i class="fa fa-rss"></i></span>
<span class=label>RSS</span></a></div></div></div><div class=post-nav><div class="post-nav-next post-nav-item"><a href=/post/ml-keras-utils-plot_model%E6%8A%A5%E9%94%99/ rel=next title=ml-keras-utils-plot_model报错><i class="fa fa-chevron-left"></i> ml-keras-utils-plot_model报错</a></div><div class="post-nav-prev post-nav-item"><a href=/post/ml-seq2seq-%E6%A8%A1%E5%9E%8B%E5%8F%8A-attention-%E6%9C%BA%E5%88%B6/ rel=prev title=ml-Seq2Seq-模型及-Attention-机制>ml-Seq2Seq-模型及-Attention-机制
<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div></main><footer class=footer><div class=footer-inner><div class=copyright>&copy;
<span itemprop=copyrightYear>2010 - 2022</span>
<span class=with-love><i class="fa fa-heart"></i></span>
<span class=author itemprop=copyrightHolder>Tomding</span></div></div></footer><script type=text/javascript src=https://cdn.staticfile.org/animejs/3.2.1/anime.min.js defer></script>
<script type=text/javascript src=https://cdn.staticfile.org/viewerjs/1.11.0/viewer.min.js defer></script>
<script class=next-config data-name=main type=application/json>{"bookmark":{"color":"#222","enable":false,"save":"manual"},"busuanzi":{"pageview":true},"copybtn":true,"darkmode":true,"giscus":{"cfg":{"category":"Comments","categoryid":null,"emit":false,"inputposition":"top","mapping":"title","reactions":false,"repo":"username/repo-name","repoid":null,"theme":"preferred_color_scheme"},"js":"https://giscus.app/client.js"},"hostname":"/","i18n":{"ds_day":" 天前","ds_days":" 天 ","ds_hour":" 小时前","ds_hours":" 小时 ","ds_just":"刚刚","ds_min":" 分钟前","ds_mins":" 分钟","ds_month":" 个月前","ds_years":" 年 ","empty":"没有找到任何搜索结果：${query}","hits":"","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","placeholder":"搜索..."},"lang":"zh-CN","lazyload":false,"localSearch":{"enable":true,"path":"/searchindexes.xml","preload":false,"topnperarticle":-1,"trigger":"auto","unescape":false},"motion":{"async":true,"enable":true,"transition":{"collheader":"fadeInLeft","postblock":"fadeIn","postbody":"fadeInDown","postheader":"fadeInDown","sidebar":"fadeInUp"}},"root":"/","scheme":"Gemini","sidebar":{"display":"post","offset":12,"padding":18,"position":"left","width":256},"statis":{"enable":true,"plugin":"busuanzi"},"vendor":{"plugins":"qiniu","router":"https://cdn.staticfile.org"},"version":"4.4.1","waline":{"cfg":{"comment":true,"emoji":false,"imguploader":false,"pageview":true,"placeholder":"请文明发言哟 ヾ(≧▽≦*)o","reaction":true,"reactiontext":["点赞","踩一下","得意","不屑","尴尬","睡觉"],"reactiontitle":"你认为这篇文章怎么样？","requiredmeta":["nick","mail"],"serverurl":null,"sofa":"快来发表你的意见吧 (≧∀≦)ゞ","wordlimit":200},"css":{"alias":"waline","file":"dist/waline.css","name":"@waline/client","version":"2.13.0"},"js":{"alias":"waline","file":"dist/waline.js","name":"@waline/client","version":"2.13.0"}}}</script><script type=text/javascript src=/js/main.min.e34208af37d3db3a875e6fbad04c2f1c241185af925a9c6ebf79dd1ba2730cdd.js defer></script></body></html>