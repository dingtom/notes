<!doctype html><html lang=zh-cn data-theme=dark><head><meta charset=utf-8><meta name=viewport content="width=device-width"><meta name=theme-color content="#222" media="(prefers-color-scheme: dark)"><meta name=generator content="Hugo 0.107.0"><link rel="shortcut icon" type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=/imgs/icons/favicon_16x16_next.png><link rel=icon type=image/png sizes=32x32 href=/imgs/icons/favicon_32_32_next.png><link rel=apple-touch-icon sizes=180x180 href=/imgs/icons/apple_touch_icon_next.png><meta itemprop=name content="cv-TensorRT"><meta itemprop=description content="Love and Peace"><meta itemprop=datePublished zgotmplz><meta itemprop=dateModified zgotmplz><meta itemprop=image content="/imgs/hugo_next_avatar.png"><meta itemprop=keywords content="Hugo,NexT,主题,简单,强大"><meta property="og:type" content="article"><meta property="og:title" content="cv-TensorRT"><meta property="og:description" content="Love and Peace"><meta property="og:image" content="/imgs/hugo_next_avatar.png"><meta property="og:image:width" content="312"><meta property="og:image:height" content="312"><meta property="og:image:type" content="image/jpeg/png/svg/jpg"><meta property="og:url" content="/post/cv-tensorrt/"><meta property="og:site_name" content="Tomding's Blog"><meta property="og:locale" content="zh-CN"><meta property="article:author" content="Tomding"><meta property="article:published_time" content="2022-12-01 19:59:47 +0800 CST"><meta property="article:modified_time" content="2022-12-01 19:59:47 +0800 CST"><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/font-awesome/6.1.2/css/all.min.css><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/animate.css/3.1.1/animate.min.css><link type=text/css rel=stylesheet href=https://cdn.staticfile.org/viewerjs/1.11.0/viewer.min.css><link rel=stylesheet href=/css/main.min.0ca97083b39f4eda7430d39b99194aa738d8f8db4090f00bc7e814013df699cb.css><style type=text/css>.post-footer,.flinks-list-footer hr:after{content:"~ 我可是有底线的哟 ~"}</style><script type=text/javascript>(function(){localDB={set:function(e,t,n){if(n===0)return;const s=new Date,o=n*864e5,i={value:t,expiry:s.getTime()+o};localStorage.setItem(e,JSON.stringify(i))},get:function(e){const t=localStorage.getItem(e);if(!t)return void 0;const n=JSON.parse(t),s=new Date;return s.getTime()>n.expiry?(localStorage.removeItem(e),void 0):n.value}},theme={active:function(){const e=localDB.get("theme");if(e==null)return;theme.toggle(e),window.matchMedia("(prefers-color-scheme: dark)").addListener(function(e){theme.toggle(e.matches?"dark":"light")})},toggle:function(e){document.documentElement.setAttribute("data-theme",e),localDB.set("theme",e,2);const t=document.querySelector("iframe.giscus-frame");if(t){const n={setConfig:{theme:e}};t.contentWindow.postMessage({giscus:n},"https://giscus.app")}}},theme.active()})(window)</script><script class=next-config data-name=page type=application/json>{"comments":false,"isHome":false,"isPage":true,"path":"cv-tensorrt","permalink":"/post/cv-tensorrt/","title":"cv-TensorRT","waline":{"js":[{"alias":"waline","alias_name":"@waline/client","file":"dist/pageview.js","name":"pageview","version":"2.13.0"},{"alias":"waline","alias_name":"@waline/client","file":"dist/comment.js","name":"comment","version":"2.13.0"}]}}</script><script type=text/javascript>document.addEventListener("DOMContentLoaded",()=>{var e=document.createElement("script");e.charset="UTF-8",e.src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js",e.async=!1,e.defer=!0,document.head.appendChild(e),e.onload=function(){NexT.utils.fmtBusuanzi()}})</script><title>cv-TensorRT - Tomding's Blog</title><noscript><link rel=stylesheet href=/css/noscript.css></noscript></head><body itemscope itemtype=http://schema.org/WebPage class=use-motion><div class=headband></div><main class=main><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle aria-label=切换导航栏 role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div></div><div class=site-meta><a href=/ class=brand rel=start><i class=logo-line></i><h1 class=site-title>Tomding's Blog</h1><i class=logo-line></i></a><p class=site-subtitle itemprop=description>Just do it!</p></div><div class=site-nav-right><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href=/ class=hvr-icon-pulse rel=section><i class="fa fa-home hvr-icon"></i>首页</a></li><li class="menu-item menu-item-about"><a href=/about.html class=hvr-icon-pulse rel=section><i class="fa fa-user hvr-icon"></i>关于</a></li><li class="menu-item menu-item-archives"><a href=/archives/ class=hvr-icon-pulse rel=section><i class="fa fa-archive hvr-icon"></i>归档
<span class=badge>109</span></a></li><li class="menu-item menu-item-search"><a role=button class="popup-trigger hvr-icon-pulse"><i class="fa fa-search fa-fw hvr-icon"></i>搜索</a></li></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon><i class="fa fa-search"></i></span><div class=search-input-container><input autocomplete=off autocapitalize=off maxlength=80 placeholder=搜索... spellcheck=false type=search class=search-input></div><span class=popup-btn-close role=button><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class=search-result-icon><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></div><div class="toggle sidebar-toggle" role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div><aside class=sidebar><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>文章目录</li><li class=sidebar-nav-overview>站点概览</li></ul><div class=sidebar-panel-container><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><nav id=TableOfContents><ul><li><a href=#查看cuda版本>查看CUDA版本</a></li><li><a href=#安装tensorrt>安装TensorRT</a></li><li><a href=#yolov5httpssocsdnnetsosearchqyolov5spm1001210130017020使用tensorrt加速><a href="https://so.csdn.net/so/search?q=YOLOv5&spm=1001.2101.3001.7020">YOLOv5</a>使用TensorRT加速</a></li></ul><ul><li><a href=#图片检测>图片检测</a></li><li><a href=#视频检测>视频检测</a></li></ul></nav></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author site-overview-item animated" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image alt=Tomding src=/imgs/img-lazy-loading.gif data-src=/imgs/hugo_next_avatar.png><p class=site-author-name itemprop=name>Tomding</p><div class=site-description itemprop=description>Love and Peace</div></div><div class="site-state-wrap site-overview-item animated"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/><span class=site-state-item-count>109</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>7</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>0</span>
<span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-social site-overview-item animated"><span class=links-of-social-item><a href=https://github.com/ title="Github → https://github.com/" rel=noopener class=hvr-icon-pulse target=_blank><i class="fab fa-github fa-fw hvr-icon"></i>Github</a></span>
<span class=links-of-social-item><a href=https://www.zhihu.com/hot title="知乎 → https://www.zhihu.com/hot" rel=noopener class=hvr-icon-pulse target=_blank><i class="fa fa-book fa-fw hvr-icon"></i>知乎</a></span></div><div class="cc-license animated" itemprop=license><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh class=cc-opacity rel=noopener target=_blank title=共享知识><img src=/imgs/img-lazy-loading.gif data-src=/imgs/cc/big/by_nc_sa.svg alt=共享知识></a></div><div class="links-of-blogroll site-overview-item animated"><div class=links-of-blogroll-title><i class="fa fa-globe fa-fw"></i>友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://gitee.com/hugo-next/hugo-theme-next title=https://gitee.com/hugo-next/hugo-theme-next target=_blank>Hugo-NexT</a></li><li class=links-of-blogroll-item><a href=https://lisenhui.cn title=https://lisenhui.cn target=_blank>凡梦星尘空间站</a></li></ul></div></div></div></div><div id=siteinfo-card-widget class=sidebar-card-widget><div class=item-headline><i class="fas fa-chart-line"></i>
<span>网站资讯</span></div><div class=siteinfo><div class=siteinfo-item><div class=item-name><i class="fa-solid fa-calendar-check"></i>已运行：</div><div class=item-count id=runTimes data-publishdate=2022-12-01T19:59:47+08:00></div></div><div class=siteinfo-item><div class=item-name><i class="fas fa fa-user"></i>总访客数：</div><div class=item-count id=busuanzi_value_site_uv><i class="fa fa-sync fa-spin"></i></div></div><div class=siteinfo-item><div class=item-name><i class="fas fa fa-eye"></i>页面浏览：</div><div class=item-count id=busuanzi_value_site_pv><i class="fa fa-sync fa-spin"></i></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-font"></i>总字数：</div><div class=item-count id=wordsCount data-count=412496></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-mug-hot"></i>阅读约：</div><div class=item-count id=readTimes data-times=882></div></div><div class=siteinfo-item><div class=item-name><i class="fa fa-clock-rotate-left"></i>最后更新于：</div><div class=item-count id=last-push-date data-lastpushdate=2023-01-01T14:28:53+08:00></div></div></div></div></aside><div class=sidebar-dimmer></div></header><div class=tool-buttons><div id=toggle-theme class=button title=深浅模式切换><i class="fas fa-adjust"></i></div><div class=back-to-top role=button title=返回顶部><i class="fa fa-arrow-up"></i>
<span>0%</span></div></div><div class=reading-progress-bar></div><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><div class="main-inner post posts-expand"><div class=post-block><article itemscope itemtype=http://schema.org/Article class=post-content lang><link itemprop=mainEntityOfPage href=/post/cv-tensorrt/><span hidden itemprop=author itemscope itemtype=http://schema.org/Person><meta itemprop=image content="/imgs/hugo_next_avatar.png"><meta itemprop=name content="Tomding"></span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization><meta itemprop=name content="Tomding"><meta itemprop=description content="Love and Peace"></span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork><meta itemprop=name content="cv-TensorRT"><meta itemprop=description content="TensorRT TensorRT支持几乎所有主流深度学习框架，将python框架转换成C++的TensorRT，从而可以加速推理。 算子融合(层与张量融合)"></span><header class=post-header><h1 class=post-title itemprop="name headline">cv-TensorRT
<a href=https://github.com/user-name/repo-name/tree/branch-name/subdirectory-name/post/cv-TensorRT.md rel="noopener external nofollow noreferrer" target=_blank class="exturl post-edit-link" title=编辑><i class="fa fa-pen-nib"></i></a></h1><div class=post-meta-container><div class=post-meta-items><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-calendar"></i></span>
<span class=post-meta-item-text>发表于：</span>
<time title="发表于：2022-12-01 19:59:47 +0800 CST" itemprop="dateCreated datePublished" datetime="2022-12-01 19:59:47 +0800 CST">2022-12-01</time></span>
<span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-folder-open"></i></span>
<span class=post-meta-item-text>分类于：</span>
<span itemprop=about itemscope itemtype=http://schema.org/Thing><a href=/categories/cv itemprop=url rel=index><span itemprop=name>cv</span></a></span></span></div><div class=post-meta-items><span class=post-meta-item title=字数><span class=post-meta-item-icon><i class="far fa-file-word"></i></span>
<span class=post-meta-item-text>字数：</span><span>3328</span></span>
<span class=post-meta-item title=阅读><span class=post-meta-item-icon><i class="far fa-clock"></i></span>
<span class=post-meta-item-text>阅读：&ap;</span>
<span>7分钟</span></span>
<span class=post-meta-item title=浏览><span class=post-meta-item-icon><i class="far fa-eye"></i></span>
<span class=post-meta-item-text>浏览：</span>
<span id=busuanzi_value_page_pv class=waline-pageview-count data-path=/post/cv-tensorrt/><i class="fa fa-sync fa-spin"></i></span></span></div></div></header><div class="post-body autonumber" itemprop=articleBody><h1 id=tensorrt>TensorRT</h1><p>TensorRT支持几乎所有主流深度学习框架，将python框架转换成C++的TensorRT，从而可以加速推理。</p><ul><li>算子融合(层与张量融合)：简单来说就是通过融合一些计算op或者去掉一些多余op来减少数据流通次数以及显存的频繁使用来提速</li><li>量化：量化即IN8量化或者FP16以及TF32等不同于常规FP32精度的使用，这些精度可以显著提升模型执行速度并且不会保持原先模型的精度</li><li>内核自动调整：根据不同的显卡构架、SM数量、内核频率等(例如1080TI和2080TI)，选择不同的优化策略以及计算方式，寻找最合适当前构架的计算方式</li><li>动态张量显存：我们都知道，显存的开辟和释放是比较耗时的，通过调整一些策略可以减少模型中这些操作的次数，从而可以减少模型运行的时间</li><li>多流执行：使用CUDA中的stream技术，最大化实现并行操作</li></ul><p>当然，<code>TensorRT主要缺点是与特定GPU绑定，在不同型号上转换出来的模型不能通用</code>(这一点笔者暂未去从实践证实)</p><p>TensorRT官方在其
<a href=https://github.com/NVIDIA/TensorRT/tree/master/tools title=仓库 rel="noopener external nofollow noreferrer" target=_blank class=exturl>仓库
<i class="fa fa-external-link-alt"></i>
</a>提供了三个开源工具，之后有需要可以使用。</p><p>三个工具大致用途[1]：</p><ul><li>ONNX GraphSurgeon<br>可以修改我们导出的ONNX模型，增加或者剪掉某些节点，修改名字或者维度等等</li><li>Polygraphy<br>各种小工具的集合，例如比较ONNX和trt模型的精度，观察trt模型每层的输出等等，主要用-来debug一些模型的信息</li><li>PyTorch-Quantization<br>可以在Pytorch训练或者推理的时候加入模拟量化操作，从而提升量化模型的精度和速度，并且支持量化训练后的模型导出ONNX和TensorRT</li></ul><p>Open Neural Network Exchange（ONNX，开放神经网络交换）格式，是微软和Facebook提出用来表示深度学习模型的开放格式，定义了一组和环境，平台均无关的标准格式，可使模型在不同框架之间进行转移[2]。</p><p>典型的几个线路[3]：</p><ul><li>Pytorch -> ONNX -> TensorRT</li><li>Pytorch -> ONNX -> TVM</li><li>TF -> onnx -> ncnn</li><li>Pytorch -> ONNX -> tensorflow</li></ul><p>ONNX结构是将每一个网络的每一层或者每一个算子当作节点Node，再由这些Node去构建一个Graph，最后将Graph和这个onnx模型的其他信息结合在一起，生成一个model。</p><p>可以通过在线网站
<a href=https://netron.app/ title=https://netron.app/ rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://netron.app/
<i class="fa fa-external-link-alt"></i>
</a>来查看ONNX模型结构。</p><h1 id=实践上手>实践上手</h1><ul><li>操作系统：Windows10</li><li>显卡：RTX2060</li><li>CUDA版本：11.6</li><li>Pytorch版本：1.7.1</li><li>Python版本：3.8</li></ul><h2 id=查看cuda版本>查看CUDA版本</h2><p>TensortRT非常依赖CUDA版本，在安装之前，需要先查看本机安装好的CUDA版本，查看方式有多种，第一种方式可以通过NVIDIA 控制面板查看；第二种方式可以通过在控制台输入<code>nvcc -V</code>进行查看。</p><h2 id=安装tensorrt>安装TensorRT</h2><p>首先需要到
<a href=https://developer.nvidia.com/nvidia-tensorrt-8x-download title=Nvidia官网 rel="noopener external nofollow noreferrer" target=_blank class=exturl>Nvidia官网
<i class="fa fa-external-link-alt"></i>
</a>去下载对应Cuda版本的TensorRT安装包。</p><p>我这里下载的是红框选中的这一个，这个版本支持CUDA11.0-11.7</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-c data-lang=c><span style=display:flex><span>cd TensorRT<span style=color:#f92672>-</span><span style=color:#ae81ff>8.4.3.1</span><span style=color:#960050;background-color:#1e0010>\</span>python
</span></span><span style=display:flex><span>pip install tensorrt<span style=color:#f92672>-</span><span style=color:#ae81ff>8.4.3.1</span><span style=color:#f92672>-</span>cp38<span style=color:#f92672>-</span>none<span style=color:#f92672>-</span>win_amd64.whl
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cd TensorRT<span style=color:#f92672>-</span><span style=color:#ae81ff>8.4.3.1</span><span style=color:#960050;background-color:#1e0010>\</span>graphsurgeon
</span></span><span style=display:flex><span>pip install graphsurgeon<span style=color:#f92672>-</span><span style=color:#ae81ff>0.4.6</span><span style=color:#f92672>-</span>py2.py3<span style=color:#f92672>-</span>none<span style=color:#f92672>-</span>any.whl
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cd TensorRT<span style=color:#f92672>-</span><span style=color:#ae81ff>8.4.3.1</span><span style=color:#960050;background-color:#1e0010>\</span>onnx_graphsurgeon
</span></span><span style=display:flex><span>pip install onnx_graphsurgeon<span style=color:#f92672>-</span><span style=color:#ae81ff>0.3.12</span><span style=color:#f92672>-</span>py2.py3<span style=color:#f92672>-</span>none<span style=color:#f92672>-</span>any.whl
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>cd TensorRT<span style=color:#f92672>-</span><span style=color:#ae81ff>8.4.3.1</span><span style=color:#960050;background-color:#1e0010>\</span>uff
</span></span><span style=display:flex><span>pip install uff<span style=color:#f92672>-</span><span style=color:#ae81ff>0.6.9</span><span style=color:#f92672>-</span>py2.py3<span style=color:#f92672>-</span>none<span style=color:#f92672>-</span>any.whl
</span></span></code></pre></div><p>然后需要移动安装包里的一些文件：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-fallback data-lang=fallback><span style=display:flex><span>将TensorRT-8.4.3.1\include中头文件拷贝到C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\include
</span></span><span style=display:flex><span>将TensorRT-8.4.3.1\lib中所有lib文件拷贝到C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\lib\x64
</span></span><span style=display:flex><span>将TensorRT-8.4.3.1\lib中所有dll文件拷贝到C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin
</span></span></code></pre></div><p>注：这里的v11.6根据自己的Cuda版本号即可</p><p>之后，需要手动将<code>C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.6\bin</code>路径添加到用户Path环境变量中</p><p>之后进行验证：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span>python
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> tensorrt
</span></span><span style=display:flex><span>print(tensorrt<span style=color:#f92672>.</span>__version__)
</span></span></code></pre></div><p>在<code>import</code>时发生报错，</p><blockquote><p>FileNotFoundError: Could not find: nvinfer.dll. Is it on your PATH?</p></blockquote><p>此时只需要将缺少的文件找到，然后添加到上面的<code>bin</code>目录下即可，我这里是在安装的torch中lib文件下找到的部分文件，缺什么移什么即可。</p><p>如无报错，再次验证，可以输出tensorrt版本：</p><p>下面运行安装包里面的一个sample.py文件，以确保tensorrt能够正常工作。<br>进入到下图所示的路径，运行<code>sample.py</code>，如果正常输出，则代表tensorrt安装成功。</p><p>如果提示没装pycuda，还需要再安装一下</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-c data-lang=c><span style=display:flex><span>pip install pycuda
</span></span></code></pre></div><h2 id=yolov5httpssocsdnnetsosearchqyolov5spm1001210130017020使用tensorrt加速><a href="https://so.csdn.net/so/search?q=YOLOv5&spm=1001.2101.3001.7020" title=YOLOv5 rel="noopener external nofollow noreferrer" target=_blank class=exturl>YOLOv5
<i class="fa fa-external-link-alt"></i>
</a>使用TensorRT加速</h2><p>这部分内容看到不少博客都是用Cmake编译生成yolov5的VS工程，非常繁琐麻烦，主要是这些博文写作时间较早。<br>而在YOLOv5 6.0版本更新后，官方新增了一个<code>export.py</code>文件，支持大部分框架模型的导出，包括TensorRT。</p><p>下面我所使用的是
<a href=https://github.com/ultralytics/yolov5 title=YOLOv5官方 rel="noopener external nofollow noreferrer" target=_blank class=exturl>YOLOv5官方
<i class="fa fa-external-link-alt"></i>
</a>最新的6.2版本。</p><p>下面直接导出官方提供的yolov5s模型试试，终端输入：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-c data-lang=c><span style=display:flex><span>python export.py <span style=color:#f92672>--</span>weights yolov5s.pt <span style=color:#f92672>--</span>data data<span style=color:#f92672>/</span>coco128.yaml <span style=color:#f92672>--</span>include engine <span style=color:#f92672>--</span>device <span style=color:#ae81ff>0</span> <span style=color:#f92672>--</span>half
</span></span></code></pre></div><p>注：这里的<code>--half</code>表示半精度模型，使用半精度可以加快推理速度，但会损失一定精度，直接导出可以不加</p><p>初次导出，遇到如下报错</p><blockquote><p>ONNX: export failure 0.4s: Exporting the operator silu to ONNX opset version 12 is not supported.</p></blockquote><p>这个报错需要修改pytorch的激活函数，找到该函数位置：<code>D:\anaconda\envs\pytorch\Lib\sitepackages\torch\nn\modules\activation.py</code>(此处结合自己的anaconda实际安装位置来更改)</p><p>修改代码如下：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>SiLU</span>(Module):
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    __constants__ <span style=color:#f92672>=</span> [<span style=color:#e6db74>&#39;inplace&#39;</span>]
</span></span><span style=display:flex><span>    inplace: bool
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __init__(self, inplace: bool <span style=color:#f92672>=</span> <span style=color:#66d9ef>False</span>):
</span></span><span style=display:flex><span>        super(SiLU, self)<span style=color:#f92672>.</span>__init__()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>inplace <span style=color:#f92672>=</span> inplace
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, input: Tensor) <span style=color:#f92672>-&gt;</span> Tensor:
</span></span><span style=display:flex><span>        <span style=color:#75715e># ------------------------------------- #</span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 把F.silu替换掉，修改后如下</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> input <span style=color:#f92672>*</span> torch<span style=color:#f92672>.</span>sigmoid(input)
</span></span><span style=display:flex><span> 
</span></span><span style=display:flex><span>        <span style=color:#75715e>#原来的代码</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> F<span style=color:#f92672>.</span>silu(input, inplace<span style=color:#f92672>=</span>self<span style=color:#f92672>.</span>inplace)
</span></span></code></pre></div><p>再次导出，不再报错。</p><p>值得注意的是，YOLOv5并不会直接导出TensorRT模型，而是会先导出ONNX模型，然后将ONNX模型转换成TensorRT模型，因此导出完成后，会在模型位置处生成<code>yolov5s.onnx</code>和<code>yolov5s.engine</code>，<code>yolov5s.engine</code>就是可以用来直接推理的TensorRT模型。</p><p>经过实测，不添加半精度导出yolov5s模型花费时间99.5s，添加半精度之后，导出yolov5s模型花费时间404.2s。</p><h1 id=实验结果>实验结果</h1><h2 id=图片检测>图片检测</h2><p>首先是来检测一下图片的推理速度，首先修改detect.py，统计程序花费时间。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>if</span> __name__ <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;__main__&#34;</span>:
</span></span><span style=display:flex><span>    begin_time <span style=color:#f92672>=</span> time<span style=color:#f92672>.</span>time()
</span></span><span style=display:flex><span>    opt <span style=color:#f92672>=</span> parse_opt()
</span></span><span style=display:flex><span>    main(opt)
</span></span><span style=display:flex><span>    end_time <span style=color:#f92672>=</span> time<span style=color:#f92672>.</span>time()
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;程序花费时间</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>秒&#34;</span><span style=color:#f92672>.</span>format(end_time<span style=color:#f92672>-</span>begin_time))
</span></span></code></pre></div><p>然后依次使用不同模型进行推理</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-c data-lang=c><span style=display:flex><span>python detect.py <span style=color:#f92672>--</span>weights yolov5s.pt
</span></span><span style=display:flex><span>python detect.py <span style=color:#f92672>--</span>weights yolov5s.engine
</span></span><span style=display:flex><span>python val.py <span style=color:#f92672>--</span>weights yolov5s.pt
</span></span><span style=display:flex><span>python val.py <span style=color:#f92672>--</span>weights yolov5s.engine
</span></span></code></pre></div><p>这里数据源选择的是coco128中128张图片，整体实验结果如下表所示：</p><table><thead><tr><th style=text-align:center>模型</th><th>推理花费时间(s)</th><th>AP50</th></tr></thead><tbody><tr><td style=text-align:center>原始模型</td><td>8.39</td><td>71.4%</td></tr><tr><td style=text-align:center>TensorRT(全精度)</td><td>5.45</td><td>71.1%</td></tr><tr><td style=text-align:center>TensorRT(半精度)</td><td>4.83</td><td>70.8%</td></tr></tbody></table><p>从数据可以发现，使用TensorRT加速之后，模型推理速度提升了约35%，但是模型精度并没有下降太多。coco数据集128张图片，模型训练和检测都是用同一份数据，这可能会对AP产生一定影响，于是再换用Visdrone数据集在进行实验。</p><p>下面对Visdrone数据集进行实验，使用yolov5m模型，训练100个epoch.</p><p>使用<code>VisDrone2019-DET-test-dev</code>中的1610张图片进行验证和检测：</p><p>验证命令：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span>python val<span style=color:#f92672>.</span>py <span style=color:#f92672>--</span>data data<span style=color:#f92672>/</span>VisDrone<span style=color:#f92672>.</span>yaml <span style=color:#f92672>--</span>weights runs<span style=color:#f92672>/</span>train<span style=color:#f92672>/</span>exp3<span style=color:#f92672>/</span>weights<span style=color:#f92672>/</span>best<span style=color:#f92672>.</span>engine <span style=color:#f92672>--</span>batch<span style=color:#f92672>-</span>size <span style=color:#ae81ff>4</span> <span style=color:#f92672>--</span>task test
</span></span></code></pre></div><p>使用<code>VisDrone2019-DET-test-dev</code>中的</p><p>检测命令：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span>python detect<span style=color:#f92672>.</span>py <span style=color:#f92672>--</span>weights runs<span style=color:#f92672>/</span>train<span style=color:#f92672>/</span>exp3<span style=color:#f92672>/</span>half<span style=color:#f92672>/</span>best<span style=color:#f92672>.</span>engine <span style=color:#f92672>--</span>source D:<span style=color:#f92672>/</span>Desktop<span style=color:#f92672>/</span>Work<span style=color:#f92672>/</span>Dataset<span style=color:#f92672>/</span>VisDrone<span style=color:#f92672>/</span>VisDrone2019<span style=color:#f92672>-</span>DET<span style=color:#f92672>-</span>test<span style=color:#f92672>-</span>dev<span style=color:#f92672>/</span>images <span style=color:#f92672>--</span>data data<span style=color:#f92672>/</span>VisDrone<span style=color:#f92672>.</span>yaml
</span></span></code></pre></div><p>实验结果如下表所示：</p><table><thead><tr><th style=text-align:center><code>模型</code></th><th style=text-align:center><code>验证花费时间(s)</code></th><th style=text-align:center><code>P</code></th><th style=text-align:center><code>R</code></th><th style=text-align:center><code>AP50</code></th><th style=text-align:center><code>推理花费时间(s)</code></th></tr></thead><tbody><tr><td style=text-align:center>yolov5m</td><td style=text-align:center>101.28</td><td style=text-align:center>43.1%</td><td style=text-align:center>34.9%</td><td style=text-align:center>32.0%</td><td style=text-align:center>157.51</td></tr><tr><td style=text-align:center>onnx</td><td style=text-align:center>156.16</td><td style=text-align:center>42.8%</td><td style=text-align:center>34.9%</td><td style=text-align:center>32.0%</td><td style=text-align:center>158.97</td></tr><tr><td style=text-align:center>TensorRT(全精度)</td><td style=text-align:center>124.37</td><td style=text-align:center>42.8%</td><td style=text-align:center>34.9%</td><td style=text-align:center>32.0%</td><td style=text-align:center>144.93</td></tr><tr><td style=text-align:center>TensorRT(半精度)</td><td style=text-align:center>127.85</td><td style=text-align:center>42.8%</td><td style=text-align:center>34.8%</td><td style=text-align:center>31.9%</td><td style=text-align:center>139.97</td></tr></tbody></table><p>由表可见，使用TensorRT加速之后，推理速度提升约了10%，同时精度只掉了0.3%，AP50基本上变化不大。</p><p>下面选一张图片来直观对比一下，左侧图为原始模型推理图，右侧图为TensorRT(半精度) 推理图，两者大致上差异不大，各有各的漏检对象。</p><h2 id=视频检测>视频检测</h2><p>视频检测用了王者荣耀数据集做一个实验，比较了常规检测，tensorrt和onnx推理速度和帧率。推理所花费的时间分别为：</p><ul><li>常规推理 程序花费时间20.88s</li><li>onnx推理 程序花费时间25.68s</li><li>tensorrt推理 程序花费时间16.03s</li></ul><p>视频帧率如下视频所示：</p><p>YOLOv5：使用TensorRT加速效果对比</p><p>综合比较来看，tensorrt的推理速度最快，并且帧率会比原本检测帧率提升约20%左右，而用onnx模型推理，速度和帧率反而会变慢，这一点我是存在一些疑问的，看到一些博客说onnx模型对比pytorch模型速度更快，但我的实验结果并非如此，个人猜测是pytorch对模型优化已经做得比较出色，onnx模型作为一个通用标准模型，为了翻译功能，损失了部分性能。</p></div><footer class=post-footer><div class=addthis_inline_share_toolbox style=text-align:center></div><hr><div class=post-copyright><img src=/imgs/cc/cc.svg width=75 height=75 align=right><ul><li class=post-copyright-title><strong>文章标题：</strong>
cv-TensorRT</li><li class=post-copyright-author><strong>本文作者：</strong>
Tomding</li><li class=post-copyright-link><strong>本文链接：</strong>
<a id=post-cr-link href=/post/cv-tensorrt/ title=cv-TensorRT>/post/cv-tensorrt/</a></li><li class=post-copyright-license><strong>版权声明：</strong>
本博客所有文章除特别声明外，均采用 <i class="fab fa-fw fa-creative-commons"></i><a target=_blank href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh>BY-NC-SA</a> 许可协议。转载请注明出处！</li></ul></div><div class=followme><span>欢迎关注我的其它发布渠道</span><div class=social-list><div class=social-item><a target=_blank class=social-link href=/images/wechat_channel.jpg><span class=icon><i class="fab fa-weixin"></i></span>
<span class=label>WeChat</span></a></div><div class=social-item><a target=_blank class=social-link href=/atom.xml><span class=icon><i class="fa fa-rss"></i></span>
<span class=label>RSS</span></a></div></div></div><div class=post-nav><div class="post-nav-next post-nav-item"><a href=/post/cv-swin-transformer/ rel=next title=cv-Swin-Transformer><i class="fa fa-chevron-left"></i> cv-Swin-Transformer</a></div><div class="post-nav-prev post-nav-item"><a href=/post/cv-vision-transformervit/ rel=prev title="cv-Vision Transformer(ViT)">cv-Vision Transformer(ViT)
<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div></main><footer class=footer><div class=footer-inner><div class=copyright>&copy;
<span itemprop=copyrightYear>2010 - 2023</span>
<span class=with-love><i class="fa fa-heart"></i></span>
<span class=author itemprop=copyrightHolder>Tomding</span></div></div></footer><script type=text/javascript src=https://cdn.staticfile.org/animejs/3.2.1/anime.min.js defer></script>
<script type=text/javascript src=https://cdn.staticfile.org/viewerjs/1.11.0/viewer.min.js defer></script>
<script class=next-config data-name=main type=application/json>{"bookmark":{"color":"#222","enable":false,"save":"manual"},"busuanzi":{"pageview":true},"copybtn":true,"darkmode":true,"giscus":{"cfg":{"category":"Comments","categoryid":null,"emit":false,"inputposition":"top","mapping":"title","reactions":false,"repo":"username/repo-name","repoid":null,"theme":"preferred_color_scheme"},"js":"https://giscus.app/client.js"},"hostname":"/","i18n":{"ds_day":" 天前","ds_days":" 天 ","ds_hour":" 小时前","ds_hours":" 小时 ","ds_just":"刚刚","ds_min":" 分钟前","ds_mins":" 分钟","ds_month":" 个月前","ds_years":" 年 ","empty":"没有找到任何搜索结果：${query}","hits":"","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","placeholder":"搜索..."},"lang":"zh-CN","lazyload":false,"localSearch":{"enable":true,"path":"/searchindexes.xml","preload":false,"topnperarticle":-1,"trigger":"auto","unescape":false},"motion":{"async":true,"enable":true,"transition":{"collheader":"fadeInLeft","postblock":"fadeIn","postbody":"fadeInDown","postheader":"fadeInDown","sidebar":"fadeInUp"}},"root":"/","scheme":"Gemini","sidebar":{"display":"post","offset":12,"padding":18,"position":"left","width":256},"statis":{"enable":true,"plugin":"busuanzi"},"vendor":{"plugins":"qiniu","router":"https://cdn.staticfile.org"},"version":"4.4.1","waline":{"cfg":{"comment":true,"emoji":false,"imguploader":false,"pageview":true,"placeholder":"请文明发言哟 ヾ(≧▽≦*)o","reaction":true,"reactiontext":["点赞","踩一下","得意","不屑","尴尬","睡觉"],"reactiontitle":"你认为这篇文章怎么样？","requiredmeta":["nick","mail"],"serverurl":null,"sofa":"快来发表你的意见吧 (≧∀≦)ゞ","wordlimit":200},"css":{"alias":"waline","file":"dist/waline.css","name":"@waline/client","version":"2.13.0"},"js":{"alias":"waline","file":"dist/waline.js","name":"@waline/client","version":"2.13.0"}}}</script><script type=text/javascript src=/js/main.min.e34208af37d3db3a875e6fbad04c2f1c241185af925a9c6ebf79dd1ba2730cdd.js defer></script></body></html>